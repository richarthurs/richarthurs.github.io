<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Richard Arthurs]]></title><description><![CDATA[Engineering student, tinkerer]]></description><link>https://gatsby-casper.netlify.com</link><generator>RSS for Node</generator><lastBuildDate>Sun, 20 Jan 2019 23:54:03 GMT</lastBuildDate><item><title><![CDATA[Getting Started With Image Sensors Using FPGAs]]></title><description><![CDATA[Steps add an AXI IIC block to the design and run automation run synthesis and generate the bitstream Image Sensor Bringup As a sanity check…]]></description><link>https://gatsby-casper.netlify.com/2019/01/17/getting-started-fpga-image-sensor/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/2019/01/17/getting-started-fpga-image-sensor/</guid><pubDate>Thu, 17 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;Steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;add an AXI IIC block to the design and run automation&lt;/li&gt;
&lt;li&gt;run synthesis and generate the bitstream&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Image Sensor Bringup&lt;/h2&gt;
&lt;p&gt;As a sanity check that the image sensor is working, let’s integrate an AXI i2c peripheral and make sure we can snag the camera sensor ID values. We will write some firmware to run on the PS (Zynq speak for the ARM cores). Here are the general steps to follow:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make a new block design with the Zynq PS included.&lt;/li&gt;
&lt;li&gt;Add an AXI IIC (Xilinx for I2C) block and run automation.&lt;/li&gt;
&lt;li&gt;create a quick block to generate an &lt;code class=&quot;language-text&quot;&gt;xclk&lt;/code&gt; signal for the image sensor. I just divided my main clock by 4 to hit 12.5 MHz.&lt;/li&gt;
&lt;li&gt;I tweaked the IO pins of the I2C block to use some pins on my board that are unencumbered by pullup resistors. The ArduCam module and the Cora board that I’m using both try to be helpful by including the I2C pullup resistors, but I don’t want any pull issues so I will rely on just the ones on the camera module. &lt;/li&gt;
&lt;li&gt;Ensure the I2C block is seen by the Zynq. You may need to go into the Zynq block and enable it after it’s added to the block diagram. &lt;/li&gt;
&lt;li&gt;Generate bitstream and export hardware to SDK. &lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Firmware&lt;/h3&gt;
&lt;p&gt;I created a new board support package. Assuming the block design is set up correctly, the BSP will include the Xilinx IIC (I2C) driver code. Then it’s time to look at the example code provided by the I2C driver to get the basic usage pattern down. &lt;/p&gt;
&lt;p&gt;Examples are located in &lt;code class=&quot;language-text&quot;&gt;TODO FILE PATH&lt;/code&gt; for me. &lt;/p&gt;
&lt;h3&gt;A Few Gotchas&lt;/h3&gt;
&lt;p&gt;It took a little while to get the sensor talking. Here were some of the things I overlooked. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The camera sensor needs &lt;code class=&quot;language-text&quot;&gt;xclk&lt;/code&gt; to begin replying over I2C. This became obvious after looking at the camera module pinout and wondering what &lt;code class=&quot;language-text&quot;&gt;xclk&lt;/code&gt; was for.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The device IDs in the OV2640 datasheet are in hex! And they include the read/write bit. The read/write bit part was obvious in that two addresses were given, the radix was not obvious. It seems that Omnivision uses hex by default in their datasheets, without a &lt;code class=&quot;language-text&quot;&gt;0x&lt;/code&gt; prefix or an &lt;code class=&quot;language-text&quot;&gt;h&lt;/code&gt; to be seen. &lt;/p&gt;
&lt;p&gt;I only uncovered this after blasting requests to all possible I2C addresses and using a logic analyzer to find the &lt;code class=&quot;language-text&quot;&gt;ACK&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;Note that the Xilinx I2C drivers will add a read/write bit accordingly, so only supply the 7-bit address and make sure the radix is correct. For my &lt;code class=&quot;language-text&quot;&gt;OV2640&lt;/code&gt;, this is &lt;code class=&quot;language-text&quot;&gt;0x60&lt;/code&gt; or &lt;code class=&quot;language-text&quot;&gt;96&lt;/code&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Despite what the datasheet says, the OV2640 seems to have 2 options for the product ID - &lt;code class=&quot;language-text&quot;&gt;0x42&lt;/code&gt; or &lt;code class=&quot;language-text&quot;&gt;0x41&lt;/code&gt;. I get &lt;code class=&quot;language-text&quot;&gt;0x42&lt;/code&gt; but &lt;code class=&quot;language-text&quot;&gt;0x41&lt;/code&gt; is in the datasheet. Given that I can read/write other registers and the &lt;a href=&quot;https://github.com/ArduCAM/Arduino/blob/13aacea9b01540218e9ba38259f1ffa3a16383f9/ArduCAM/examples/RaspberryPi/arducam_ov2640_capture.cpp&quot;&gt;ArduCam driver&lt;/a&gt; also lists these, it’s clearly not a problem. &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Slave addr = 60 write
61 read&lt;/p&gt;
&lt;p&gt;COM10 [4] will set the positive edge of pclk as the active edge&lt;/p&gt;
&lt;h4&gt;Register Set 1&lt;/h4&gt;
&lt;p&gt;Register FF controls which register page is accessable. When register FF is 0x00, the addresses do this:
Reg F7 = slave ID
MCU in the camera has BIST. &lt;/p&gt;
&lt;h4&gt;Register Set 2&lt;/h4&gt;
&lt;p&gt;When register FF equals 0x01
0A = product ID number (PIDH)
0B = product ID number (PIDL)&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;Set device addr = 60 write
Write 01 to FF 

Read (61) from 0x0A
Read (61) from 0x0B&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Designing the Camera Interface Core&lt;/h2&gt;
&lt;p&gt;There are several clocks in this design. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;clk - the main system clock &lt;/li&gt;
&lt;li&gt;xclk - generated by the FPGA from the main clock, fed to the image sensor&lt;/li&gt;
&lt;li&gt;vclk - output from the camera, this is what the video stream is synchronized to&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Therefore, we have some clock domain crossing to handle. First, we need to transition from the vclk domain into the clk domain. This occurs when we load in a pixel from the camera (synchronized to vclk), and need to handle it within the FPGA (the exent of the ‘handling’ changes). &lt;/p&gt;
&lt;p&gt;How can we handle this? Let’s look at &lt;a href=&quot;https://zipcpu.com/blog/2017/10/20/cdc.html&quot;&gt;some examples&lt;/a&gt;. &lt;/p&gt;
&lt;h2&gt;A few Good Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://embeddedprogrammer.blogspot.com/2012/07/hacking-ov7670-camera-module-sccb-cheat.html&quot;&gt;http://embeddedprogrammer.blogspot.com/2012/07/hacking-ov7670-camera-module-sccb-cheat.html&lt;/a&gt;
&lt;a href=&quot;http://www.arducam.com/products/camera-breakout-board/2mp-ov2640/&quot;&gt;http://www.arducam.com/products/camera-breakout-board/2mp-ov2640/&lt;/a&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Customizing AXI IP]]></title><description><![CDATA[Customizing IP RTL Now that we have an IP block that can be accessed from userspace, let’s customize it with a register that the user can…]]></description><link>https://gatsby-casper.netlify.com/2019/01/06/cora-customizing-axi-ip/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/2019/01/06/cora-customizing-axi-ip/</guid><pubDate>Sun, 06 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h3&gt;Customizing IP RTL&lt;/h3&gt;
&lt;p&gt;Now that we have an IP block that can be accessed from userspace, let’s customize it with a register that the user can read to determine the state of the LEDs. Right now, the example only has a writable register. These changes will allow the user to read data from the block using a memory-mapped register. &lt;/p&gt;
&lt;p&gt;To do this, we will edit the IP block and assign some of the counter bits to an axi-accessable register. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Right click on the block and choose &lt;code class=&quot;language-text&quot;&gt;edit in IP packager&lt;/code&gt;. This opens up a new temporary Vivado project that allows you to change the RTL, save the changes, and have them reflected in the main project that uses the IP block.
&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/fb2b0b69f655fd8687f368ca6de5b6f4/be9be/2-edit-ip.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1170px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 56.927223719676554%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAAB1UlEQVQoz42SW2+cMBCF+f+/aps+RepTVSXabkr2xh1swHdsOB2bpkqqVqqlj8EjM3N8huzTw2ccDgc8Pn7B1+cc345XHPMSL5cGP67tB/6WO51rPL8U+J7XeL33yMqiRNvUEEKgaRn4KCCVgdQWyjhMQoNPEuOsErM0FHXKK+0S2iwwdkm5rO4lGmbgPDCPHGIW+Lg2bOuK/13ZOAl0PYf3K7YtfkxssQz2SA+pFDo+J3qCjRFBSiV82Pa22x4zMc0wWmNd94IxvpEaEEppXJsR53pEfq3wdLogp/dytJDlCW4oYGMNOpuJeYaSCjFWZQXOOGZ6j0gpwWhvrIMknzh5NJGHl6JH0QkMs8Pc3MG7FoEEeO+RMcZSEWtt8i/G90rjIUnGV6TmRn4fadI9j1dd4RYP7VZwPpFVASEsyDjn6JoOy7L80+iVfI1e2WVNhf5cVTuh6uhGljw01kBrsysU5KfRcM4mrDWJZXFYg/+NJyXe7wTa9x1LKgM1zt66KCXofzyjay8YugtYf0VT55jGGtYM7+h/McDZCCfLBjpH195WZCGE5JmQNMmixb3ieL0NZDzDueAomgl1N1Ge4VYOKGqOkiYe91XDSYjCMAyI1mma9E+PCEztl8q1GwAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Edit IP&quot;
        title=&quot;&quot;
        src=&quot;/static/fb2b0b69f655fd8687f368ca6de5b6f4/a66a3/2-edit-ip.png&quot;
        srcset=&quot;/static/fb2b0b69f655fd8687f368ca6de5b6f4/65e34/2-edit-ip.png 293w,
/static/fb2b0b69f655fd8687f368ca6de5b6f4/8d594/2-edit-ip.png 585w,
/static/fb2b0b69f655fd8687f368ca6de5b6f4/a66a3/2-edit-ip.png 1170w,
/static/fb2b0b69f655fd8687f368ca6de5b6f4/59785/2-edit-ip.png 1755w,
/static/fb2b0b69f655fd8687f368ca6de5b6f4/be9be/2-edit-ip.png 1855w&quot;
        sizes=&quot;(max-width: 1170px) 100vw, 1170px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Above: Edit the IP&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add the lines to assign the counter to a user-accessible register&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;// TODO: insert code&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Save and close the Vivado window&lt;/li&gt;
&lt;li&gt;Vivado will alert you that something is out of date and needs to be updated, choose &lt;code class=&quot;language-text&quot;&gt;Refresh IP status&lt;/code&gt; and then &lt;code class=&quot;language-text&quot;&gt;Update Selected&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/8a2aa95d96a197cd8e110569cb61e225/be9be/2-upgrade-selected.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1170px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 56.927223719676554%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAAB2UlEQVQoz41S2YrcMBD0/39VhryEPAQWQsJm7lnsGUse3bIsX5VuTYbNkpcIipLkdlNVrWqz+YzN5hO+fP2Gl58HfH+94Nehwe7cYn8RBbuzwJbO21Nb9u+g855qdzX2xxbHyx1VUzcQ7Q3ee7RCQRuPEBNCP6BPGdpF3LqATkdIHaBswt30BTYMMCETE+JIdxEVF7cqIU+AMxrBB/y9lmXFOM3431UZ6yE7jWlesK4r5nkuzCgNiYxjdQ5COVLqcGeQE+NCqf/Q0FmLISUkQtd1sHRm+4wYI4x1peGbMDjdDA5vV/zYnrG/GrRmwFVqSNsjpgHTOKLiH9nmMAwY6WKapsLP/SPPjJBGaM+5JZzrDrX0UG6AVB6C8jU+PhoqpaDu6oN0dvvHcVkmjLiajEsX8XqWZUDTvCLnmfJdC/qBBSyotNboRAdHKhUNRWkF6wydLU2c98TOozOcoaVmllSGf8H/U1wVZzeQf01ZNc0JxtxwJa7rY4GUDUXSESRCkFSr4Z2grFs4Yt4z830iVE9bid6NaCVSn6g40kBG0OBJaYIQ1CTO0KTQ0atgGFKc+J3eDSQ5fEZULcvCqZUM+v4xbR5QzoyMgZjv+JsnW4/vudS8M6HUZvwG1ipLuwrIcvsAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Edit IP&quot;
        title=&quot;&quot;
        src=&quot;/static/8a2aa95d96a197cd8e110569cb61e225/a66a3/2-upgrade-selected.png&quot;
        srcset=&quot;/static/8a2aa95d96a197cd8e110569cb61e225/65e34/2-upgrade-selected.png 293w,
/static/8a2aa95d96a197cd8e110569cb61e225/8d594/2-upgrade-selected.png 585w,
/static/8a2aa95d96a197cd8e110569cb61e225/a66a3/2-upgrade-selected.png 1170w,
/static/8a2aa95d96a197cd8e110569cb61e225/59785/2-upgrade-selected.png 1755w,
/static/8a2aa95d96a197cd8e110569cb61e225/be9be/2-upgrade-selected.png 1855w&quot;
        sizes=&quot;(max-width: 1170px) 100vw, 1170px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Above: Upgrade the selected IP&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Vivado will alert you to generate the output products again
&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/8a3cd35790c9b6eba4b3736636c0752d/72fb1/2-generate-output.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1170px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 56.25%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsSAAALEgHS3X78AAAB00lEQVQoz01Ry4oUMRStH/YzdCc6uBhcyCjobNqFiJt240YUZEQQbGi7nX7NdKXyqkpu3lWp8lYXNHM5nKqc5CYnJ8Xni8vNZkcrwqRm0mrbGp9dHGIebBxcGnwaWbtO2c6GHkVzYgi5+PL0ZcmNcV0InlPWte0wDCmG379uft78QHz/9vXvcjGM1T9En3Nx9fx9XUOtXc79VLjKGLPbbgkh5bGklGx3t40yCpwG27bdMO3U98WH6ytvfNsmrbVSCtustUII/HfWTetIxf4sb1d3olKRCiW0dyGmlIp3zy5Bg3MuhBBPhWrTNFLWACaf/DDO17vyQBTXkUlDhFXGpxSL+WxeS4mHTIanwr0YZYILAEgxbg/HA6lzHlLKbdd33RBii/6L6ydvhJC1rNVoWypdWwd4T0YpitZobKaUoh6i9cGcARaK2eO3aDWERCrC2VHwsjzuN9tVVdFG1os1uSs5Ke+bhgJw0BxAIMegwKhi/vrT9AgYlmoa72OjMI6uImS9Wi2W+9W/7WG/x4NUMwalFdCKY9ap64uPFzNs7nIG48egrTuFN3rBr/dBaTCj6HHKIjs/Dr3XxhevHr1wweHDUFYTKs8oKzHxfcke6mdUTP4H1MRlM23PfyEAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Generate output products&quot;
        title=&quot;&quot;
        src=&quot;/static/8a3cd35790c9b6eba4b3736636c0752d/a66a3/2-generate-output.png&quot;
        srcset=&quot;/static/8a3cd35790c9b6eba4b3736636c0752d/65e34/2-generate-output.png 293w,
/static/8a3cd35790c9b6eba4b3736636c0752d/8d594/2-generate-output.png 585w,
/static/8a3cd35790c9b6eba4b3736636c0752d/a66a3/2-generate-output.png 1170w,
/static/8a3cd35790c9b6eba4b3736636c0752d/59785/2-generate-output.png 1755w,
/static/8a3cd35790c9b6eba4b3736636c0752d/72fb1/2-generate-output.png 1920w&quot;
        sizes=&quot;(max-width: 1170px) 100vw, 1170px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Above: Generate the output products&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Or, run synthesis and implementation again and generate bitstream if you hit cancel before. &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Customizing Application Software&lt;/h3&gt;
&lt;p&gt;Now that the RTL is coded and the bitstream has been generated, it’s time to head back into SDK and update the application software so that we can use the new hardware capabilities. &lt;/p&gt;
&lt;p&gt;// talk about the updates to the application&lt;/p&gt;
&lt;p&gt;// talk about updates to the kernel driver&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I updated the kernel driver with the new read command &lt;/li&gt;
&lt;li&gt;Rebuild the petalinux image with &lt;code class=&quot;language-text&quot;&gt;petalinux-build&lt;/code&gt;. Unlike the first time around, the build this time only takes around 4 minutes since the changes are minor. &lt;/li&gt;
&lt;li&gt;Move the petalinux files over to the SD card. &lt;/li&gt;
&lt;li&gt;Initialize the kernel module as per the tutorial. I later moved these commands into a shell script and I placed it on the &lt;code class=&quot;language-text&quot;&gt;bulk&lt;/code&gt; partition of my SD card so it sticks around between resets.&lt;/li&gt;
&lt;li&gt;Upon running the app for the first time, nothing crashed. However, I was not seeing the results I expected (this turned out to be an RTL bug, which I found later). &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Since things weren’t working at this point, I tried several things during the debug process, which are worth mentioning. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I used the &lt;code class=&quot;language-text&quot;&gt;devmem&lt;/code&gt; command to look at the memory directly, instead of interacting through the application. &lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;devmem 0x43C00000&lt;/code&gt; returns the value of the user-writable bit that starts and stops the blinking, since it is mapped to user register 0 in the HDL. &lt;/p&gt;
&lt;p&gt;When the RTL bug was fixed, &lt;code class=&quot;language-text&quot;&gt;devmem 0x43C00008&lt;/code&gt; returns the counter value. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;One of the issues was I neglected to export the new hardware from Vivado to SDK, so I was flashing the FPGA with old code that didn’t update an AXI-accessable register with the counter value. &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I also ended up adapting the C file &lt;a href=&quot;http://svenand.blogdrives.com/files/gpio-dev-mem-test.c&quot;&gt;here&lt;/a&gt;, which I found from &lt;a href=&quot;http://fpga.org/2013/05/28/how-to-design-and-access-a-memory-mapped-device-part-two/&quot;&gt;this tutorial&lt;/a&gt;. I wrote this on the board over an SSH connection and compiled it with &lt;code class=&quot;language-text&quot;&gt;gcc filename.c&lt;/code&gt;. As before, I did this on the partition of my SD card which I mounted to a directory (&lt;code class=&quot;language-text&quot;&gt;sdcard&lt;/code&gt;) with the command: &lt;code class=&quot;language-text&quot;&gt;mount /dev/mmcblk0p2 ./sdcard&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;Here is the final test C file. I played around with this and ended up solving the RTL issue. This exposed the fact that my Linux device driver had a bug since it was not able to read the register, but the test file could. &lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;sys/mman.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;

int main(void){
unsigned addr, offset;

int reg_addr = 0x43c00000;

int value;
int fd;

void *ptr;
unsigned pg_sz = sysconf(_SC_PAGESIZE);

printf(&amp;quot;Access through /dev/mem - pg_sz: %x\n&amp;quot;, pg_sz);

// Open the mem file
fd = open(&amp;quot;/dev/mem&amp;quot;, O_RDWR);
if(fd &amp;lt; 1){
        perror(&amp;quot;can&amp;#39;t open&amp;quot;);
        return -1;
}

// mmap the device into memory
addr = (reg_addr &amp;amp; (~(pg_sz - 1)));
offset = (reg_addr - addr);
ptr = mmap(NULL, pg_sz, PROT_READ|PROT_WRITE, MAP_SHARED, fd, addr);

// Read values from device registers:
for(int i = 0; i &amp;lt; 4; i +=1){
        value = *((unsigned *)(ptr + offset + i*4));
        printf(&amp;quot;Value from reg%d: %x\n&amp;quot;,i, value);
}

// Write to a reg and read it back
*((unsigned *)(ptr + offset + 12)) = 0xdeadbeef;
value = *((unsigned *) (ptr + offset + 12));
printf(&amp;quot;Reg3 after write: %x\n&amp;quot;, value);

return 0;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;SD Rootfs&lt;/h3&gt;
&lt;p&gt;So the simple test app works, the Linux driver has a bug, and by now I’m fairly annoyed with how many commands I need to enter in order to get things running. It’s time to configure the SD card rootfs, which will place the filesystem onto the SD card as opposed to it being in RAM. Therefore, it will be nonvolatile and I can copy things over to it and restart whenever I like. It’s also time to write more shell scripts. &lt;/p&gt;
&lt;p&gt;Following the instructions in the &lt;a href=&quot;https://github.com/Digilent/Petalinux-Cora-Z7-10&quot;&gt;petalinux repo for Cora&lt;/a&gt;, I made a couple of scripts to set up the SD card for me once I had the SD rootfs configured in petalinux. &lt;/p&gt;
&lt;p&gt;// todo: insert scripts or make github repo&lt;/p&gt;
&lt;p&gt;Now it’s simply a matter of &lt;code class=&quot;language-text&quot;&gt;petalinux-build&lt;/code&gt;, then running my two scripts in order to set up a new SD card. Nice! &lt;/p&gt;</content:encoded></item><item><title><![CDATA[Petalinux Bringup on Cora Z7-10 Zynq Board]]></title><description><![CDATA[This post contains notes that I generated while bringing up Petalinux on my Cora Z7-10 Zynq board. First I get Petalinux working and do a…]]></description><link>https://gatsby-casper.netlify.com/2019/01/05/cora-linux-getting-started/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/2019/01/05/cora-linux-getting-started/</guid><pubDate>Sat, 05 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;This post contains notes that I generated while bringing up Petalinux on my Cora Z7-10 Zynq board. First I get Petalinux working and do a couple of hello world examples. It can serve as a companion to the following resources: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.hackster.io/100311/estimating-pi-with-a-cora-z7-running-linux-03995b&quot;&gt;Hackster.io article&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Digilent/Petalinux-Cora-Z7-10&quot;&gt;github repo for Cora Z7-10 Petalinux&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the second section, Petalinux is built from scratch, and I implement custom AXI-compliant IP on the FPGA fabric. A Xilinx tutorial is followed (with extra notes) to write a Linux device driver and an app to leverage the driver. The result? AXI-controlled blinky LEDs from Linux. &lt;/p&gt;
&lt;p&gt;Topics covered:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SSH connections to the board&lt;/li&gt;
&lt;li&gt;Adapting Xilinx tutorials for different target dev boards&lt;/li&gt;
&lt;li&gt;Cross-compiling apps on the desktop and copying them to the board&lt;/li&gt;
&lt;li&gt;Petalinux build and installation notes &lt;/li&gt;
&lt;li&gt;Notes where existing tutorials weren’t correct (for my particular setup, anyway)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As usual, this article is not a standalone tutorial. It’s a supplement to the linked resources.&lt;/p&gt;
&lt;p&gt;Note: some links are to Cora Z7-10 specific resources. If you have a different board, be sure to poke around and see if a similar resource exists for your platform.&lt;/p&gt;
&lt;h2&gt;Section 1 - Petalinux Bringup&lt;/h2&gt;
&lt;h3&gt;Petalinux Install&lt;/h3&gt;
&lt;p&gt;I started by following the readme instructions in the repo linked below. I was not able to execute the petalinux installer from my root account, I had to make a new user, chmod +w the installation directory from the new user, and then run the installation script.  &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/Digilent/Petalinux-Cora-Z7-10&quot;&gt;github repo for Cora Z7-10&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I also added the source petalinux script call to the bottom of my .cshrc file so it will be sourced every time I make a new terminal. You could also make it an alias, since the command takes a couple of seconds to run, which is annoying when you want to bring up a new terminal quickly.  &lt;/p&gt;
&lt;h3&gt;SD Card Partitioning&lt;/h3&gt;
&lt;p&gt;I partitioned my SD card with the following partitions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Name: fpga, format: FAT, size: 1 GB&lt;/li&gt;
&lt;li&gt;Name: bulk, format: EXT4, size: 7 GB&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Go App&lt;/h3&gt;
&lt;p&gt;These notes accompany the &lt;a href=&quot;https://www.hackster.io/100311/estimating-pi-with-a-cora-z7-running-linux-03995b&quot;&gt;Hackster.io article&lt;/a&gt;. I thought it would be interesting to write the first example in go, so I tried it out. Once I understood the flow, I went back to writing things in C. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make a new folder with &lt;code class=&quot;language-text&quot;&gt;main.go&lt;/code&gt; inside it. Note that the final executable will have the same name as this directory. &lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;cd&lt;/code&gt; into the directory you placed &lt;code class=&quot;language-text&quot;&gt;main.go&lt;/code&gt; in. &lt;/li&gt;
&lt;li&gt;Run this command to compile: &lt;code class=&quot;language-text&quot;&gt;GOARCH=arm go build&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;An executable will be generated with the name of the current directory. &lt;/li&gt;
&lt;li&gt;Copy it into the “bulk” partition on the SD card. &lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Petalinux Bringup&lt;/h3&gt;
&lt;p&gt;I used a pre-built Petalinux image from Digilent. As I learned later, this was a good call. Building Petalinux takes about an hour for me, so using the pre-compiled package made the process much quicker for an initial bringup. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download the &lt;a href=&quot;https://github.com/Digilent/Petalinux-Cora-Z7-10/releases/&quot;&gt;board support package from github&lt;/a&gt;, then place it in a directory called bsp somewhere. &lt;/li&gt;
&lt;li&gt;Make a new directory to contain the petalinux project and cd into it. &lt;/li&gt;
&lt;li&gt;Run the following command to generate the project: &lt;code class=&quot;language-text&quot;&gt;petalinux-create -t project -s &amp;lt;path to .bsp file&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;As per the instructions, I copied the boot files onto the first partition of my microSD card and made the MAC address file. The MAC address on the board sticker needs a colon between every set of 2 characters in the file.  &lt;/li&gt;
&lt;li&gt;Plug in the SD card to the Cora, short jumper JP2.&lt;/li&gt;
&lt;li&gt;Connected a terminal to /dev/ttyUSB1 at 115200 baud, 8-N-1. &lt;/li&gt;
&lt;li&gt;Press SRST. I was soon greeted with a &lt;code class=&quot;language-text&quot;&gt;Zynq:&lt;/code&gt; prompt, which has several low-level commands that you can see by entering &lt;code class=&quot;language-text&quot;&gt;help&lt;/code&gt;. It was proving difficult to navigate and enter commands in this mode. I was getting filesystem configuration errors. So I cycled power and SRST. I was greeted with a &lt;code class=&quot;language-text&quot;&gt;root@Cora-Z7-10:&lt;/code&gt; prompt. Great, it’s working! In this mode, commands like &lt;code class=&quot;language-text&quot;&gt;ls&lt;/code&gt; work without error. &lt;/li&gt;
&lt;li&gt;The bulk of my filesystem is on a 2nd partition of the SD card, which is also where I placed the demo go app executable. &lt;/li&gt;
&lt;li&gt;Enter the following commands to mount to the partition:
&lt;code class=&quot;language-text&quot;&gt;mkdir SDFS&lt;/code&gt;
&lt;code class=&quot;language-text&quot;&gt;mount /dev/mmcblk0p2 ./SDFS&lt;/code&gt;&lt;br&gt;
&lt;code class=&quot;language-text&quot;&gt;cd SDFS&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Now you can run the go app executable as usual: &lt;code class=&quot;language-text&quot;&gt;./test-app&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;There was an issue with the demo app where it was set to run a &lt;em&gt;huge&lt;/em&gt; number of iterations, so the app appears to do nothing after the initial print. Whoops. Don’t believe everything you see on the internet. However, the print worked, so at least we know the app worked. &lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;C Hello World&lt;/h3&gt;
&lt;p&gt;GCC is installed under petalinux, so may as well make an app in C and check that it works too. &lt;/p&gt;
&lt;p&gt;Still in the SDFS directory, I wrote a hello world file in c:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;// hello.c
#include &amp;lt;stdio.h&amp;gt;

int main(){
    printf(&amp;quot;Hello, world!\n&amp;quot;);
    return 0;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that you’ll need to use vim to write the code since the only interface is a command prompt over a UART. I discuss writing apps on the PC and transferring them over a couple sections down in this article. &lt;/p&gt;
&lt;p&gt;Compile it with: &lt;code class=&quot;language-text&quot;&gt;gcc hello.c&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Run it with: &lt;code class=&quot;language-text&quot;&gt;./a.out&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;SSH&lt;/h3&gt;
&lt;p&gt;Let’s SSH into the board so that files can be edited and compiled on the desktop, and then executables copied over over Ethernet. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Plug the board into your router with an Ethernet cable. &lt;/li&gt;
&lt;li&gt;You should see a “link up” message soonafter&lt;/li&gt;
&lt;li&gt;On the terminal connected over the UART, run &lt;code class=&quot;language-text&quot;&gt;ifconfig&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;The first &lt;code class=&quot;language-text&quot;&gt;inet addr&lt;/code&gt; is the ip address of the board, 192.168.1.69 for me. I will use this address throughout this article. If you’re following along, always replace it with the IP address your board is given. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/1b4f7e4c7293d172ee38c958bb7df956/fa7b5/ifconfig.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 830px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 60.48192771084337%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAAsSAAALEgHS3X78AAABSElEQVQoz31Si0oDMRDM5XWXd67xM6zQq6BIrbalgv//Q85uhINSHcLebHLJ7E4ivg/Px+Pb9fJx+jx8XU+X8/F8ekd8fVmW3eN+edov29+x2y7rwNJWaDsOYgCMseM4TtPkvNdaI0WOSMQSV1IJwrBGJSWiMSaEkGL0DHDnXIwhxgiCFHOYzynxqk8pQUYoRecprekn71nZdfieMkFRlLoJRZEuQ3Sgrlrnh9ZqraWUea4Zn1paaxABKbWC1HkmwRsYo0OIKJsr9BHlBR8iuDPcNJShOY5EerErYBD1h73cWz+iR7aNoBkg6+bOpJQ4nYftUmgVS1JJMYg/Ibvb1lJLpZKfgYAuu/k4S/wPXGfOuW02ZA/5U2BBa5tOUopola/b3ttsDCsXVg25ZIo5TwzwfoUgt26xYdrx8+iPjB+a6w4rxt16fwClCx2oSIjQRAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;ifconfig output&quot;
        title=&quot;&quot;
        src=&quot;/static/1b4f7e4c7293d172ee38c958bb7df956/fa7b5/ifconfig.png&quot;
        srcset=&quot;/static/1b4f7e4c7293d172ee38c958bb7df956/60c5b/ifconfig.png 293w,
/static/1b4f7e4c7293d172ee38c958bb7df956/7c836/ifconfig.png 585w,
/static/1b4f7e4c7293d172ee38c958bb7df956/fa7b5/ifconfig.png 830w&quot;
        sizes=&quot;(max-width: 830px) 100vw, 830px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Above: output from &lt;code class=&quot;language-text&quot;&gt;ifconfig&lt;/code&gt; command&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On the PC in a new terminal, SSH into the board using the following command: &lt;code class=&quot;language-text&quot;&gt;ssh root@192.168.1.69&lt;/code&gt; (replacing with the IP address you just determined).&lt;/li&gt;
&lt;li&gt;You will be prompted for a password, it was &lt;code class=&quot;language-text&quot;&gt;root&lt;/code&gt; for me. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By now, you should see a command prompt appear for the board. SSH success! Use the &lt;code class=&quot;language-text&quot;&gt;logout&lt;/code&gt; command to close the SSH connection when you’re done.&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;SSH and Cross-compile Flow&lt;/h3&gt;
&lt;p&gt;Now let’s test out a more reasonable development flow where we write an app on the PC, cross-compile it there, then copy the executable to the device over ssh. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Make a new directory on your PC called &lt;code class=&quot;language-text&quot;&gt;zynq-apps&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Inside, make an app project directory &lt;code class=&quot;language-text&quot;&gt;hello-world&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Inside the &lt;code class=&quot;language-text&quot;&gt;hello-world&lt;/code&gt; directory, add the following makefile:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;make&quot;&gt;&lt;pre class=&quot;language-make&quot;&gt;&lt;code class=&quot;language-make&quot;&gt;# Cross compiler prefix: https://xilinx-wiki.atlassian.net/wiki/spaces/A/pages/18842547/Install+Xilinx+Tools#InstallXilinxTools-XilinxVivadoandPetaLinuxTools 
# many existing tutorials are not updated for Vivado

CC = arm-linux-gnueabihf-gcc
CFLAGS = -lm

all : hello-world

hello-world : hello-world.o
    ${CC} ${CFLAGS} $^ -o $@

clean :
    rm -rfv *.o
    rm -rf hello-world

uplink:
    # this target will upload the executable to the board. Change to an IP address assigned to your board. 
    scp hello-world root@192.168.1.69:
    

.PHONY : clean&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol start=&quot;4&quot;&gt;
&lt;li&gt;Add the hello-world.c code from above, or add something more complex. &lt;/li&gt;
&lt;li&gt;Make the app with &lt;code class=&quot;language-text&quot;&gt;make&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Upload the app to the board using the &lt;code class=&quot;language-text&quot;&gt;uplink&lt;/code&gt; target with this command: &lt;code class=&quot;language-text&quot;&gt;make uplink&lt;/code&gt;. This will use &lt;code class=&quot;language-text&quot;&gt;scp&lt;/code&gt; to copy the executable over to the board. You will need to enter the password &lt;code class=&quot;language-text&quot;&gt;root&lt;/code&gt; when you run this command. &lt;/li&gt;
&lt;li&gt;SSH into the board again: &lt;code class=&quot;language-text&quot;&gt;ssh root@192.168.1.69&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;The hello-world app was copied into the root directory, so it can be executed with the following command: &lt;code class=&quot;language-text&quot;&gt;./hello-world&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;Section 2: Connecting the ARM Cores and FPGA&lt;/h2&gt;
&lt;p&gt;The best tutorial I found for connecting the ARM cores and FPGA is &lt;a href=&quot;https://www.xilinx.com/support/documentation/sw_manuals/xilinx2018_2/ug1165-zynq-embedded-design-tutorial.pdf&quot;&gt;this one&lt;/a&gt; from Xilinx. In this section, I include some notes for section 7 of the linked document, as I had to modify the process slightly to work with the Cora board. &lt;/p&gt;
&lt;p&gt;The tutorial walks you through building an AXI-controlled IP block, adding a device driver to the petalinux build, and writing and running an application that uses the petalinux device driver. &lt;/p&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/8ae1fb7bfb6f1258af7261de8063b118/5cf5b/block-diagram.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1170px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 42.72727272727273%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAAsSAAALEgHS3X78AAABLElEQVQoz41Q127DMAz0/39bgQAZTRo5w7bioeEhUVu2K6OP6UMOBEEceMTxMuOCVIb24yBAu2B98BsiKNUPo9bGh7gsy/ofsiMqUEWa0eaYHXJc1kRIfUB1SSQRjspoXViWedt9O5GhokGYlVTuUXW6vS7oefq5777v96YnMlRMsVEr4/mk+ARCe22cUtpaG2PMQohSOwF2Aps8xnk+nPPjtbwUXScChTlp0LPe5zgdKpkifAQAY8wmdnGdwLBB9FPiPGiPHnVDhqrti5q/yEDZYKyfwI3CpB7ibH3KIWy207fNZAsiKq4Rpl8XvDvXr3bsmEzVUtEQkQbC4a8aKm9lzTlPKWaYa8xN0Qncm/Oz3V8rPsj1M2RhXsEEMFGozbPzcf0Y2Tu1fCz+BUvyAwPI2PmWAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Block Diagram&quot;
        title=&quot;&quot;
        src=&quot;/static/8ae1fb7bfb6f1258af7261de8063b118/a66a3/block-diagram.png&quot;
        srcset=&quot;/static/8ae1fb7bfb6f1258af7261de8063b118/65e34/block-diagram.png 293w,
/static/8ae1fb7bfb6f1258af7261de8063b118/8d594/block-diagram.png 585w,
/static/8ae1fb7bfb6f1258af7261de8063b118/a66a3/block-diagram.png 1170w,
/static/8ae1fb7bfb6f1258af7261de8063b118/5cf5b/block-diagram.png 1210w&quot;
        sizes=&quot;(max-width: 1170px) 100vw, 1170px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Above: the block diagram for the system that will be created.&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;Prerequisites&lt;/h3&gt;
&lt;p&gt;You should already have the Digilent board files installed, and you should be able to create a simple RTL project and load the bitstream on to the Cora board from Vivado. You should also be familiar with the Petalinux procedure discussed above, as it is used in this part too. &lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;Writing HW Drivers&lt;/h3&gt;
&lt;p&gt;These notes correspond to the &lt;strong&gt;Creating Peripheral IP section of the tutorial linked above&lt;/strong&gt;. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create a new vivado project and select the Cora board. This assumes that you’ve got the Digilent board descriptions installed. &lt;/li&gt;
&lt;li&gt;In the IP integrator, create a new block design. Add the Zynq PS IP to it. &lt;/li&gt;
&lt;li&gt;Double click the Zynq block, in the re-customize IP window, click Import XPS settings. &lt;/li&gt;
&lt;li&gt;Navigate to &lt;code class=&quot;language-text&quot;&gt;vivado-boards-master/new/board_files/cora-z7-10/B.0&lt;/code&gt; and select &lt;code class=&quot;language-text&quot;&gt;preset.xml&lt;/code&gt;. Click OK. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/884d2ea11bafd8336c6fbbb83e7ef962/cc7d9/specify-file.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1170px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 65.65096952908587%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAAsSAAALEgHS3X78AAAB2klEQVQoz31S2W6jMBTl/39jpMmo2clGlr7M80ijVpq0gbKGJEBsMGAwxixzSzTLQ9OjY+vo+l77LpZede9gBpqDX4zgYKG97h+sKwigat+I/6d5Thw/u1FCGBcsd2xjJk/XynK5kNfK4nG33m2V7Wa5Wa+2GwX0brt63CrLxcTU1bZtm6Zq21pKUxqFhMRpFEYYR2EY5VmOcQiac942oqoE52Vd103bVhXnRd6A6iCxotDVN9MwVVW1Ldt2zP3+1+nkepeL73vff1gv2tF14MByju6b7rjuOSIkDMOMUgldr5vlbDGXh8P+eDzqj3oP/d58NpvDmsnf+uPReCLLk+l0PJ/Lo9FgMOwPBg+9r19WykoyDEMzT1dERNXwsirLRoh3caMQdQlGUdOce56PriiKIoxQEifniycdHcc5R5RV7R00XYk0Y5qqk4iwPM+yrCiKIAggbZxS1jl9GkzZ089n27SPjpskiRCiC8Y46YI/fznLC9OwYCIlFNZZEEKSZVlxQv863QPUX/9x+BdsmHacZre04fhDAhgXpYCZvwNyBv8ubYR9HxGSxjFlrGTFx8wZp5SmaZokKctp21S+70uEELgDhg5/CjpB7wOaDFvJ8ycNPWvB6Wj/BnGpy/uT8Rj+AAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;XPS settings&quot;
        title=&quot;&quot;
        src=&quot;/static/884d2ea11bafd8336c6fbbb83e7ef962/a66a3/specify-file.png&quot;
        srcset=&quot;/static/884d2ea11bafd8336c6fbbb83e7ef962/65e34/specify-file.png 293w,
/static/884d2ea11bafd8336c6fbbb83e7ef962/8d594/specify-file.png 585w,
/static/884d2ea11bafd8336c6fbbb83e7ef962/a66a3/specify-file.png 1170w,
/static/884d2ea11bafd8336c6fbbb83e7ef962/cc7d9/specify-file.png 1444w&quot;
        sizes=&quot;(max-width: 1170px) 100vw, 1170px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Above: setting up the XPS settings for the ARM processing subsystem.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This file comes from the &lt;code class=&quot;language-text&quot;&gt;vivado-boards&lt;/code&gt; repo from Digilent and allows the Zynq to be configured with all of the other hardware on the board. &lt;/p&gt;
&lt;ol start=&quot;5&quot;&gt;
&lt;li&gt;Run block automation. &lt;/li&gt;
&lt;li&gt;Connect the clocks (fig 2-8 in the tutorial). I get some warnings about negative clock skew. This is a known issue and can be ignored, apparently. &lt;/li&gt;
&lt;li&gt;Continue until step 10 of the &lt;strong&gt;Integrating Peripheral IP with PS GP Master Port&lt;/strong&gt; section where the LED port settings are configured. &lt;/li&gt;
&lt;li&gt;Search for “leds” in the port list of the elaborated design. Refer to the Cora reference manual and set the Package pin for each bit of the led port. Set the IO standard to &lt;code class=&quot;language-text&quot;&gt;LVCMOS33&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/d768e6edc3e53e3dea91b398fe71032b/be9be/led-config.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1170px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 56.927223719676554%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAABR0lEQVQoz6WS62rDMAyF8/4P1VEYDAaDwe6k69qtzVLHcXzPpUnOZKejfzZ2qeDDkq0oR7aS+fwcs9kZLi6vcHWb4vruBTePa6SrHRavBRZr9i0p8bDY4j7d4mmZY7kRSErOwfJ3ZLsSz6sMRalQVgY5q8C4AhcGnGIu9LQeKKWlPBtzo0+EnIQLC+P2FCgwxmGMg6+buAas9THW2kBKHffynFFsIZWGUiYSzqpKIQkq3jYMeSFR6RamHmCbEa7FRBMYYesR0vXQdC5NCx1839P+EL8JviZhifceXdPA1S3GccRk4xf8zhKtNZx10NRa3w9TOSr8XxIhBLJNhoruYTgoPCr9uyU1XXixY+ClxGedkwp6X0OUApJebRjGk9qNLTvnYWgknG9wgrCjQqUUdJgnUhhmy9IDhZ84/wMuzGeNbr9H1x35APOJVZWonVqsAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;XPS settings&quot;
        title=&quot;&quot;
        src=&quot;/static/d768e6edc3e53e3dea91b398fe71032b/a66a3/led-config.png&quot;
        srcset=&quot;/static/d768e6edc3e53e3dea91b398fe71032b/65e34/led-config.png 293w,
/static/d768e6edc3e53e3dea91b398fe71032b/8d594/led-config.png 585w,
/static/d768e6edc3e53e3dea91b398fe71032b/a66a3/led-config.png 1170w,
/static/d768e6edc3e53e3dea91b398fe71032b/59785/led-config.png 1755w,
/static/d768e6edc3e53e3dea91b398fe71032b/be9be/led-config.png 1855w&quot;
        sizes=&quot;(max-width: 1170px) 100vw, 1170px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;&lt;/p&gt;
&lt;ol start=&quot;9&quot;&gt;
&lt;li&gt;As per the tutorial, open up SDK. &lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Petalinux Driver Setup&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Execute the petalinux module creation commands in the &lt;strong&gt;Device Driver Development&lt;/strong&gt; section. &lt;/li&gt;
&lt;li&gt;Copy the provided blink.c and blink.h files into project-spec/meta-user/recipes-modules/blink/files and update the .bb file. Don’t forget the trailing slash in the bb file, or the build process will throw an error. &lt;/li&gt;
&lt;li&gt;Run the command &lt;code class=&quot;language-text&quot;&gt;petalinux-build&lt;/code&gt;, not &lt;code class=&quot;language-text&quot;&gt;petalinux build&lt;/code&gt; as stated in the tutorial. &lt;/li&gt;
&lt;li&gt;Time for coffee! The build process took quite a while on my i5 machine, approximately an hour. It includes some very large file downloads - I guess this is where the 100 GB (!) free space requirement comes from. &lt;/li&gt;
&lt;li&gt;Generate the boot image from the command in the cora &lt;a href=&quot;https://github.com/Digilent/Petalinux-Cora-Z7-10&quot;&gt;petalinux repo&lt;/a&gt;: &lt;code class=&quot;language-text&quot;&gt;petalinux-package --boot --force --fsbl images/linux/zynq_fsbl.elf --fpga images/linux/cora_z7_10_wrapper.bit --u-boot&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;As described in the repo readme above, copy the newly generated image on to the SD card in the correct location. &lt;/li&gt;
&lt;li&gt;Insert the SD card into the board. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/4e253fa7ec14a20600342f42723808e4/7989f/blinky-1.jpg&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1170px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 58.80000000000001%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAwACBP/EABUBAQEAAAAAAAAAAAAAAAAAAAID/9oADAMBAAIQAxAAAAHhIHVAsxP/xAAaEAACAgMAAAAAAAAAAAAAAAABAgADEBEh/9oACAEBAAEFAjYGRmwDqOez/8QAFxEBAAMAAAAAAAAAAAAAAAAAAAERMf/aAAgBAwEBPwGMW//EABYRAQEBAAAAAAAAAAAAAAAAAAARQf/aAAgBAgEBPwHKr//EABsQAAEEAwAAAAAAAAAAAAAAAAEAAxARITFB/9oACAEBAAY/AmxmwKXZ0I//xAAZEAADAQEBAAAAAAAAAAAAAAAAAREhMVH/2gAIAQEAAT8hTfphHNT0o5k0ZoiqjP/aAAwDAQACAAMAAAAQ6/8A/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAERMf/aAAgBAwEBPxBtUs//xAAXEQEBAQEAAAAAAAAAAAAAAAABABFR/9oACAECAQE/EAVcWr//xAAZEAEAAwEBAAAAAAAAAAAAAAABABExIYH/2gAIAQEAAT8QCM8wG25LFhtcMe8gsC50uECaKod9YrbTrP/Z&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;LED App&quot;
        title=&quot;&quot;
        src=&quot;/static/4e253fa7ec14a20600342f42723808e4/27561/blinky-1.jpg&quot;
        srcset=&quot;/static/4e253fa7ec14a20600342f42723808e4/06456/blinky-1.jpg 293w,
/static/4e253fa7ec14a20600342f42723808e4/4b3e4/blinky-1.jpg 585w,
/static/4e253fa7ec14a20600342f42723808e4/27561/blinky-1.jpg 1170w,
/static/4e253fa7ec14a20600342f42723808e4/278c2/blinky-1.jpg 1755w,
/static/4e253fa7ec14a20600342f42723808e4/7989f/blinky-1.jpg 2000w&quot;
        sizes=&quot;(max-width: 1170px) 100vw, 1170px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Above: a preview of the working blinky app&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;SDK and FPGA Programming&lt;/h4&gt;
&lt;p&gt;These notes are for the &lt;strong&gt;Example Project: Loading a Module into Kernel and Executing
the Application&lt;/strong&gt; section. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Open SDK, skip the TCF agent on the host machine step. I won’t be using the debugger right now. &lt;/li&gt;
&lt;li&gt;Make a new SDK project, set Linux as the OS in the wizard. I skipped the toolchain and system root configurations because the directories in the tooltips were not present on my system.  &lt;/li&gt;
&lt;li&gt;Import the &lt;code class=&quot;language-text&quot;&gt;blink.h&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;linux_blinkled_app.c&lt;/code&gt; file from the &lt;code class=&quot;language-text&quot;&gt;LKM_App&lt;/code&gt; directory in the example code download from the Xilinx tutorial. Delete the &lt;code class=&quot;language-text&quot;&gt;helloworld.c&lt;/code&gt; file that’s included by default. It should automatically build without errors. The .elf file generated by SDK will be copied over to the board in a later step. &lt;/li&gt;
&lt;li&gt;Program the FPGA with &lt;code class=&quot;language-text&quot;&gt;Xilinx &amp;gt; Program FPGA&lt;/code&gt;. The board was auto-detected for me. &lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Testing out the Device&lt;/h4&gt;
&lt;p&gt;Now that everything is built and programmed, let’s try to run the app and communicate to custom hardware from a Linux device driver!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;With the new linux image set, cycle power and connect up to the serial port. &lt;/li&gt;
&lt;li&gt;Run the &lt;code class=&quot;language-text&quot;&gt;mknod&lt;/code&gt; commands on the board as described in the tutorial. &lt;/li&gt;
&lt;li&gt;Create a directory &lt;code class=&quot;language-text&quot;&gt;/Apps&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I decided to skip using the Xilinx tools for navigating on the device, and do it through SSH/the UART connection instead. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;scp the &lt;code class=&quot;language-text&quot;&gt;.elf&lt;/code&gt; file from &lt;code class=&quot;language-text&quot;&gt;.sdk/linux-blinkled-app/Debug/linux-blinkled-app.elf&lt;/code&gt; from the PC onto the board in the &lt;code class=&quot;language-text&quot;&gt;/Apps&lt;/code&gt; directory using the following command on the PC: &lt;code class=&quot;language-text&quot;&gt;scp &amp;lt;path to elf file&amp;gt; root@192.168.1.69:&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I had to remove the old SSH key stored for this IP address, since it changed when petalinux was rebuilt. Then I SSH’d into the board again.&lt;/p&gt;
&lt;p&gt;I moved the .elf file into the Apps directory I made earlier, chmod +777’d it as is done in the tutorial, and executed. To my great surprise, the example fired right up and lights started blinking!&lt;/p&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/9372cc92bbf5a88c049d7549f7f9443f/7989f/blinky-2.jpg&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1170px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 75.64999999999999%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIDBP/EABYBAQEBAAAAAAAAAAAAAAAAAAMCBP/aAAwDAQACEAMQAAABzyi2lYihT//EABsQAAMAAgMAAAAAAAAAAAAAAAACAwEEEBES/9oACAEBAAEFAsbFKDWY7Jv5GfDcf//EABcRAAMBAAAAAAAAAAAAAAAAAAABESH/2gAIAQMBAT8ByFZ//8QAFxEAAwEAAAAAAAAAAAAAAAAAAAEREv/aAAgBAgEBPwGRU2z/xAAcEAABBAMBAAAAAAAAAAAAAAABAAIQUREhgTL/2gAIAQEABj8CyQzoXlvBFiloR//EABsQAQACAgMAAAAAAAAAAAAAAAEAESFhEDFR/9oACAEBAAE/IUlSiLOzrRwv5NiKoB4TE//aAAwDAQACAAMAAAAQlD//xAAYEQACAwAAAAAAAAAAAAAAAAAAASExYf/aAAgBAwEBPxBJLSbH/8QAFhEBAQEAAAAAAAAAAAAAAAAAAEFh/9oACAECAQE/EKTR/8QAHxABAAIBAwUAAAAAAAAAAAAAAQARITFBUWFxgcHh/9oACAEBAAE/EBIFCij0mGzAv0Yp4jDVbbofIyF1BcG+d/MUNAvdn//Z&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Blinking LEDs&quot;
        title=&quot;&quot;
        src=&quot;/static/9372cc92bbf5a88c049d7549f7f9443f/27561/blinky-2.jpg&quot;
        srcset=&quot;/static/9372cc92bbf5a88c049d7549f7f9443f/06456/blinky-2.jpg 293w,
/static/9372cc92bbf5a88c049d7549f7f9443f/4b3e4/blinky-2.jpg 585w,
/static/9372cc92bbf5a88c049d7549f7f9443f/27561/blinky-2.jpg 1170w,
/static/9372cc92bbf5a88c049d7549f7f9443f/278c2/blinky-2.jpg 1755w,
/static/9372cc92bbf5a88c049d7549f7f9443f/7989f/blinky-2.jpg 2000w&quot;
        sizes=&quot;(max-width: 1170px) 100vw, 1170px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Above: blinking LEDs controlled by an AXI-enabled peripheral from a Petalinux device driver.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;To recap, from scratch, we did the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;built Petalinux&lt;/li&gt;
&lt;li&gt;installed a custom device driver&lt;/li&gt;
&lt;li&gt;implemented an AXI-compliant IP block and hooked it up to the Zynq processing system&lt;/li&gt;
&lt;li&gt;implemented and built an app to use the driver to interface to the custom IP&lt;/li&gt;
&lt;li&gt;learned the build flows, practiced communicating with the target board&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That’s pretty good! All of the building blocks of a really interesting project are in place now. It’s time to look at the example code and examine how it can be used to bootstrap a more complex application and more complex custom IP. &lt;/p&gt;
&lt;h2&gt;Custom AXI IP [WIP]&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;make folder for IP in project directory&lt;/li&gt;
&lt;li&gt;tools &gt; create and package IP&lt;/li&gt;
&lt;li&gt;setup the IP settings&lt;/li&gt;
&lt;li&gt;If you don’t choose edit now, you can just click “add IP” in the block diagram and search for the IP name you just created. It will show up and then you can edit it.&lt;/li&gt;
&lt;li&gt;Add it to the diagram&lt;/li&gt;
&lt;li&gt;Edit in IP packager&lt;/li&gt;
&lt;li&gt;Make the changes to the IP&lt;/li&gt;
&lt;li&gt;In the IP packager flow, update the ports (should be an auto thing to do this). This occurs in the &lt;code class=&quot;language-text&quot;&gt;Package IP &amp;lt;IP Name&amp;gt;&lt;/code&gt; tab. Make your way down the left hand bar with all of the steps in it. &lt;/li&gt;
&lt;li&gt;Re-Package IP&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now go back to the main design and re-sync with the IP. Now is also a good time to run connection and block automation. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Right click at the top of the &lt;code class=&quot;language-text&quot;&gt;sources&lt;/code&gt; tab and choose &lt;code class=&quot;language-text&quot;&gt;generate HDL wrapper&lt;/code&gt;. &lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Hook up IO Ports&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;RTL Analysis &gt; Open Elabrorated Design
// hookup-io picture&lt;/li&gt;
&lt;li&gt;At the top, click the IO Ports&lt;/li&gt;
&lt;li&gt;Near the bottom there is a search icon&lt;/li&gt;
&lt;li&gt;Search for &lt;code class=&quot;language-text&quot;&gt;led&lt;/code&gt; and the pins will show up&lt;/li&gt;
&lt;li&gt;Set the package pins to &lt;code class=&quot;language-text&quot;&gt;N15&lt;/code&gt;, &lt;code class=&quot;language-text&quot;&gt;G17&lt;/code&gt;, &lt;code class=&quot;language-text&quot;&gt;L15&lt;/code&gt;, &lt;code class=&quot;language-text&quot;&gt;M15&lt;/code&gt; and LVCMOS33. Which LED is assigned which pin doesn’t really matter. &lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Using a Project From Git&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Open up the project in Vivado&lt;/li&gt;
&lt;li&gt;Generate bitstream&lt;/li&gt;
&lt;li&gt;When that’s done, &lt;code class=&quot;language-text&quot;&gt;File &amp;gt; Export Hardware&lt;/code&gt; to send the design to SDK&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;File &amp;gt; Launch SDK&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;When SDK opens, &lt;code class=&quot;language-text&quot;&gt;File &amp;gt; Import Projects From Filesystem&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Navigate to repo&lt;em&gt;base/project&lt;/em&gt;name.sdk/sdk&lt;em&gt;project&lt;/em&gt;name and select it. SDK should automatically detect that a project is present. Click OK to open up the project. &lt;/p&gt;
&lt;ol start=&quot;6&quot;&gt;
&lt;li&gt;Right click on the SDK project in the sidebar and choose &lt;code class=&quot;language-text&quot;&gt;Debug As &amp;gt; Debug Configurations...&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Select a Xilinx System Debugger type&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the target setup tab, make sure the following settings are there:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Debug Type: &lt;strong&gt;Linux Application Debug&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Connection: click the new button and enter the IP address of the board in the &lt;code class=&quot;language-text&quot;&gt;Host&lt;/code&gt; field. &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Press the &lt;code class=&quot;language-text&quot;&gt;Test Connection&lt;/code&gt; button. It should succeed. &lt;/li&gt;
&lt;li&gt;All good, time to flash the bitstream! Click the &lt;code class=&quot;language-text&quot;&gt;Program FPGA&lt;/code&gt; button. &lt;/li&gt;
&lt;li&gt;Once that’s done, you can debug the software application. Simply hit the &lt;code class=&quot;language-text&quot;&gt;Debug&lt;/code&gt; button and the debugger perspective should open up. Click the &lt;code class=&quot;language-text&quot;&gt;Start&lt;/code&gt; button when you are ready to run the code. &lt;/li&gt;
&lt;/ol&gt;</content:encoded></item><item><title><![CDATA[Drone Guidance System]]></title><description><![CDATA[For the past few years, I’ve been working on a guidance system for drones with  SFU Team Guardian . This is truly a system, which…]]></description><link>https://gatsby-casper.netlify.com/projects/drone-guidance-system/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/projects/drone-guidance-system/</guid><pubDate>Thu, 03 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;For the past few years, I’ve been working on a guidance system for drones with &lt;a href=&quot;teamguardian.ca&quot;&gt;SFU Team Guardian&lt;/a&gt;. This is truly a system, which encompasses simulator (APM SITL) or real drone support, path planning, mission creation, drone control, and a web-based ground control app. I started the project for the team to meet the requirements of the AUVSI competition, where a drone must complete objectives while avoiding stationary and moving objects. &lt;/p&gt;
&lt;h2&gt;Tech Stack&lt;/h2&gt;
&lt;p&gt;The guidance system is executed on a laptop computer in the field, and continuously sends velocity vectors and other commands over the telemetry radio connection. The drone itself is a multicopter, running stock APM firmware and sending back telemetry at roughly 10 Hz. Running the guidance system on a laptop provides flexibility of developing in a high-level language (Python) and facilitates much easier testing when the simulator is involved. For the task at hand (avoiding large obstacles), the communication latency and potential for dropped packets is not a significant concern. &lt;/p&gt;
&lt;p&gt;The DroneKit library provides an application layer that allows high-level commands to be sent to the drone via MAVProxy, and hides the details about the connection. During development, the APM SITL simulator is hooked up identically to a real drone by connecting to its provided telemetry stream. When we tune the real copter PID paramaters, we set them in the SITL drone as well, allowing the simulated drone to have similar flight characteristics to the real drone. This makes it easier to tune paramaters of the guidance system. &lt;/p&gt;
&lt;h2&gt;Control Loop&lt;/h2&gt;
&lt;p&gt;Control of drone movement is provided by the velocity vector commands exposed by DroneKit. You need to continuously feed velocity vectors to a drone running APM firmware otherwise it will quickly stop and hover. This turns out to be a &lt;em&gt;really&lt;/em&gt; nice safety feature, and apparently wasn’t present in the earliest versions of APM. Yikes!&lt;/p&gt;
&lt;p&gt;The guidance system calculates a velocity vector at a user-settable frequency, usually 5-10 Hz. Velocities are specified in NED coordinates - North, East, Down, which makes navigation quite easy using standard equations for navigation on the Earth. To generate a velocity vector, the following things are considered:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;maximum velocity setting&lt;/li&gt;
&lt;li&gt;current and desired location, driven by the path planning algorithm and mission itself&lt;/li&gt;
&lt;li&gt;PID values from the navigation PID controller (internal to the guidance system, separate from the APM PID controllers)&lt;/li&gt;
&lt;li&gt;a few safety checks for altitude limits and overshoot detection&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once the velocity vector is calculated, it is sent up to the drone. It turns out that packet loss is not a significant concern - most of the velocity commands make it up to the copter. The velocity vector needs to be recalculated continuously to account for dynamic effects such as wind, and so the drone won’t stop as mentioned before. &lt;/p&gt;
&lt;h2&gt;Mission Modules&lt;/h2&gt;
&lt;p&gt;Similar to how missions are planned on standard ground control apps like APM Planner, I introduced the concept of a mission module to the guidance system. Each mission module is a representation of a few things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a set of coordinates (multiple coordinates are used to define a search pattern, for example)&lt;/li&gt;
&lt;li&gt;a particular action to perform when the final coordinte is reached&lt;/li&gt;
&lt;li&gt;an altitude&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The simplest mission module is a waypoint - it contains a single set of coordinates, an altitude, and tells the drone to hover at the location for a few seconds. An example of an extension to the waypoint module is the drop location module, which sends a few servo commands to release something from the drone as it hovers over a particular location. There are also search pattern modules, where the corners of an area are defined by the user, as well as a swath width, allowing a set of coordinates to be generated in a lawnmower-style zigzag search. &lt;/p&gt;
&lt;p&gt;Initially, missions (a collection of mission modules) were defined in a .CSV file. In the future, users will be able to graphically create them using the GCS GUI. &lt;/p&gt;
&lt;p&gt;To execute a mission, the guidance system essentially loops through all of the locations in a mission module, one mission module at a time. &lt;/p&gt;
&lt;h2&gt;Path Planning&lt;/h2&gt;
&lt;p&gt;The path planning system uses the A* algorithm, which allows a route to be calculated between a particular location and the target location from the current mission module. Along the way, any “obstacles” will be avoided. A* operates on a grid representation of the flight area, and obstacles are simply nodes on the grid that the path is not allowed to use. In practice, I use a circle generation algorithm from computer graphics to find grid nodes around a central coordinate to mark off as the edges of an obstacle. &lt;/p&gt;
&lt;p&gt;The real-world resolution of the grid is customizable, and I usually use 1 metre. So, the flight area is broken up into a set of geographical coordinates along a 1m grid. A* operates on the indices of the geographical coordinates to calculate the path. In various places, a KD tree is used to quickly determine the closest grid coordinate to another coordinate (such as a mission module target location). Since the grid resolution is fine compared to the accuracy of the drone’s GPS navigation (3m roughly), this approximation doesn’t result in significant navigation issues in practice. &lt;/p&gt;
&lt;p&gt;Upon reaching a target location, A* is executed to find the path to the next location. &lt;/p&gt;
&lt;h2&gt;Navigation&lt;/h2&gt;
&lt;p&gt;… this post is a work in progress. &lt;/p&gt;
&lt;h2&gt;Obstacle Avoidance &amp;#x26; Path Planning&lt;/h2&gt;</content:encoded></item><item><title><![CDATA[Goodbye Wordpress, Hello Gatsby]]></title><description><![CDATA[I’ve maintained a Wordpress blog for years now, and I always did like Wordpress. Creating Wordpress themes was one of the first significant…]]></description><link>https://gatsby-casper.netlify.com/2019/01/02/byebye-wordpress/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/2019/01/02/byebye-wordpress/</guid><pubDate>Wed, 02 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I’ve maintained a Wordpress blog for years now, and I always did like Wordpress. Creating Wordpress themes was one of the first significant software development
projects I did as a kid. However, as my hosting account expired recently and I got hit with renewal fees that were 3x the original cost (this is &lt;em&gt;extremely common&lt;/em&gt; across web hosts), I decided to take a second look at how I could maintain a personal site with less technical and financial overhead. &lt;/p&gt;
&lt;p&gt;I’ve also been thinking a lot about how I’d like to lay out my site. I really wanted to keep blog posts and projects separate. Wordpress could do this, but the off-the-shelf themes didn’t exactly support what I wanted to do. Of course, I could extend an existing theme, but I didn’t really want to write PHP and deal with Wordpress any more.&lt;/p&gt;
&lt;p&gt;Enter Gatsby - the static site generator. As opposed to Wordpress which generates pages on the fly by pulling post data from a database, Gatsby takes markdown files (for pages, posts, etc.) and generates an entirely static site. The content can then be hosted inexpensively, with zero server-side dependencies. The pages are constructed using typical modern web technologies, like React. I’ve been having a great time with React recently, so I decided to give it a shot. &lt;/p&gt;
&lt;h2&gt;The Old Host&lt;/h2&gt;
&lt;p&gt;First I had to deal with the old web host. Once my account expired, they locked me out of cpanel, and I also couldn’t use an FTP connection. I totally understand the site going down (since I was behind on payment), but I was not thrilled that the admin panel was closed and my data was held hostage by the host. &lt;/p&gt;
&lt;p&gt;Not wanting to pay 3x the original hosting cost, I converted to monthly billing and paid my final month. This let me login to the sites and export the wordpress data. Ten bucks was easily worth it to get away from them. &lt;/p&gt;
&lt;h2&gt;Gatsby Bringup&lt;/h2&gt;
&lt;p&gt;Gatsby has starter templates, so I chose &lt;a href=&quot;https://github.com/scttcper/gatsby-casper&quot;&gt;this one&lt;/a&gt; to serve as a base template for the new site. &lt;/p&gt;
&lt;p&gt;Next I had to install Gatsby, and it was here that I encountered my first issues. After running &lt;code class=&quot;language-text&quot;&gt;npm install -g gatsby&lt;/code&gt;, the &lt;code class=&quot;language-text&quot;&gt;gatsby&lt;/code&gt; command did nothing, as if Gatsby were never installed. &lt;/p&gt;
&lt;p&gt;The solution came from &lt;a href=&quot;https://github.com/gatsbyjs/gatsby/issues/4967&quot;&gt;this Github issue&lt;/a&gt;, in the form of the following commands:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;`npm config set prefix /usr/local`
`npm i -g gatsby-cli`
`npm i -g gatsby`&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Adjusting the Theme&lt;/h2&gt;
&lt;p&gt;Gatsby development was very smooth once the install issue was worked out, so I set about stripping down some elements of the theme that I didn’t want, such as the social media hooks and buttons. For the most part, I commented these out since I may want them later.&lt;/p&gt;
&lt;p&gt;It didn’t take too long to understand how pages and posts are created. The content folder structure is very similar to Wordpress, too. &lt;/p&gt;
&lt;h2&gt;Future Considerations&lt;/h2&gt;
&lt;p&gt;Since sites generated using Gatsby are static, adding comments involves using a 3rd party service. Relying on another service of course brings its own security and integration concerns, so it depends on how much you want comments. &lt;/p&gt;</content:encoded></item><item><title><![CDATA[CubeSat Onboard Computer Design]]></title><description><![CDATA[Over the past year and a half, I have been working on the SFU Satellite Design Team as the computing subsystem lead. The team and I have…]]></description><link>https://gatsby-casper.netlify.com/projects/cubesat-onboard-computer-design/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/projects/cubesat-onboard-computer-design/</guid><pubDate>Wed, 06 Jun 2018 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Over the past year and a half, I have been working on the SFU Satellite Design Team as the computing subsystem lead. The team and I have been developing a low-cost, reliable, custom onboard computer (OBC) to meet the current and future mission requirements. This post features quite a few details about the project.&lt;/p&gt;
&lt;p&gt;The original mission the OBC was designed for was calibration of the CHIME experiment, which was SFUSat’s first CubeSat mission developed during the Canadian Satellite Design Challenge.&lt;/p&gt;
&lt;h2&gt;Features&lt;/h2&gt;
&lt;p&gt;The SFUSat OBC is an inexpensive command and data handling system designed to be flexible across CubeSat missions. It features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automotive and extended temperature range hardware wherever possible&lt;/li&gt;
&lt;li&gt;Cortex R4 processor with lockstep architecture&lt;/li&gt;
&lt;li&gt;Extensive self-tests, error handling, SECDED&lt;/li&gt;
&lt;li&gt;RTC with minimum 7-day supercapacitor backup&lt;/li&gt;
&lt;li&gt;Nonvolatile storage of mission data&lt;/li&gt;
&lt;li&gt;Optional triple-redundant data storage&lt;/li&gt;
&lt;li&gt;Flexible bus architecture with PC/104 form factor&lt;/li&gt;
&lt;li&gt;2x SPI, I2C, ADC pins broken out to bus connector&lt;/li&gt;
&lt;li&gt;Multiple interrupt-capable GPIO on bus connector&lt;/li&gt;
&lt;li&gt;Simple-to-integrate 3.3 V power supply requirement&lt;/li&gt;
&lt;li&gt;External USB power for development purposes&lt;/li&gt;
&lt;li&gt;External watchdog timer&lt;/li&gt;
&lt;li&gt;Current monitoring and auto reset for SEL protection&lt;/li&gt;
&lt;li&gt;Onboard temperature sensor&lt;/li&gt;
&lt;li&gt;FreeRTOS-based software stack ensuring priority and multi-tasking&lt;/li&gt;
&lt;li&gt;Immediate and time-tagged commands&lt;/li&gt;
&lt;li&gt;Automatic logging and timestamp of any data with friendly API&lt;/li&gt;
&lt;li&gt;Minimum 7-day file history capacity&lt;/li&gt;
&lt;li&gt;File downlink capability&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The TMS570 microcontroller used in the design has flight heritage with Robonaut, several satellites, and was confirmed to function correctly to 2.5 KRad by SFUSat. [1]&lt;/p&gt;
&lt;h2&gt;File Handling &amp;#x26; Telemetry&lt;/h2&gt;
&lt;p&gt;The satellite is intended to be frequently transmitting its most up-to-date telemetry packet, called standard telemetry. Telemetry points are also saved to a file onboard the satellite. One file is created per sensor, per day, and after 7 days have passed (or no room remains), the oldest set of log files are deleted. Log files can be downloaded at any time by a remote command. Standard telemetry sending can be suspended for a defined period of time for power saving purposes.&lt;/p&gt;
&lt;p&gt;The filesystem chosen for the project is SPIFFS, an open-source and lightweight filesystem designed for SPI NOR flash devices. It proved simple to integrate and performed well in all of our tests.&lt;/p&gt;
&lt;p&gt;The ring buffer style file architecture was simple and worked well overall. I developed an easy-to-use API to log data to files, where arbitrary text could be formatted and written into a file with a single function call using printf-style format specifiers. All writes to files were automatically timestamped. Developing easy-to-use APIs is a common theme of this project, and helps immensely when getting new members up to speed.&lt;/p&gt;
&lt;p&gt;Files are named with a simple prefix-suffix methodology. The prefix ‘a’, ‘b’, and so on, represents the current “day” or time step. Over the course of a week, files with prefixes ‘a’ to ‘g’ will be created, and once ‘g’ files are finished, the ‘a’ will be deleted and replaced with new ‘a’-prefixed files. The suffix is another letter, ‘A’, corresponding to the file’s function, such as OBC temperature logs or general error logs. This naming methodology was chosen to make finding files quick, and to exploit the batch delete feature of SPIFFS.&lt;/p&gt;
&lt;p&gt;We also have a “flag file” capability, which is used for storing and retrieving short, non-volatile flags from external flash memory. At startup, the system looks for the presence of this file, creates it if it doesn’t exist (and populates sensible defaults), or uses the existing flags.&lt;/p&gt;
&lt;h2&gt;Self-Tests&lt;/h2&gt;
&lt;p&gt;Upon startup, the OBC executes self tests to verify core functionality and connection to peripherals. Self-tested features include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU and all peripherals&lt;/li&gt;
&lt;li&gt;Battery management system&lt;/li&gt;
&lt;li&gt;External non-volatile memory&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Since the TMS570 self-tests wipe RAM, we save the results of self tests into a spare CAN data register that is not used by our application. The data in this register survives the self test, allowing us to determine which (if any) self tests have failed.&lt;/p&gt;
&lt;h2&gt;OBC Epoch&lt;/h2&gt;
&lt;p&gt;The OBC epoch is the real-time clock (RTC) based timestamp used throughout the system. Upon deployment, once the satellite has enough power to turn on the OBC, the real-time clock will start ticking from time 0. With a large super capacitor backup on the RTC, it is able to keep time for weeks without main system power. This capability can be used to determine how long the satellite had lost power, and it is used to timestamp files and coordinate antenna deployments.&lt;/p&gt;
&lt;p&gt;The RTC chip is the Abracon AB-RTCMC-EA09-S3-D-B-T. It was chosen for low power, wide temperature range, and temperature compensated crystal features. It also has an alarm feature connected to a GPIO, which can be used to wake up the OBC from extended deep sleep periods. The time is represented in a human-readable date format which is converted to an absolute zero-based seconds format, with time 0 being the time the satellite first powered on.&lt;/p&gt;
&lt;h2&gt;Command System&lt;/h2&gt;
&lt;p&gt;The OBC software features a command system designed to be flexible. Commands have a main command, optional subcommand, and optional arguments (represented as hex data). The command system is linked to the UART for tethered development, and it’s linked to the radio so commands can be sent wirelessly.&lt;/p&gt;
&lt;p&gt;Some of the commands include:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;- state get, set, and previous state
- log file dump by prefix and file name
- schedule a command to run in the future
- get OBC epoch, minimum heap
- get RTOS task snapshot (running tasks, task priorities)
- suspend and enable RTOS tasks
- execute CHIME calibration sequence
- external reset
- file system erase&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;FreeRTOS&lt;/h2&gt;
&lt;p&gt;FreeRTOS is used as the real-time operating system solution. Now on version 10, version 9 is used on the OBC. It was chosen for its ease of use, excellent documentation, and vendor support with the TMS570. We rely heavily on the following RTOS features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;task priorities&lt;/li&gt;
&lt;li&gt;task suspension and deletion&lt;/li&gt;
&lt;li&gt;mutexes and queues
We have found that many features that might be otherwise difficult to implement, have become straightforward by placing the functionality into a task that can be suspended. Good examples are external reset capability, and automatic SAFE mode entry if no signals are received over a long period of time. Task stack usage values are determined through experimentation, aided immensely by the command system’s task snapshot command, which can show tasks that are not running because of insufficient stack.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Radiation Effects Mitigation&lt;/h2&gt;
&lt;p&gt;The OBC has been tested to 3.0 KRad at the TRIUMF facility. Tests were successful with zero occurrences of permanent data corruption, zero software lockups, and zero detected hardware latchups.&lt;/p&gt;
&lt;p&gt;Single event upset effects are mitigated in the following ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TMS570 internal SECDED ECC&lt;/li&gt;
&lt;li&gt;External watchdog triggered reset and self-test upon software lockup&lt;/li&gt;
&lt;li&gt;Reset initiates TMS570 self tests which validate ECC and exercise on-chip peripherals&lt;/li&gt;
&lt;li&gt;Important configuration data and logs stored in flash memory&lt;/li&gt;
&lt;li&gt;Single event latchup events are detected by an OBC-wide current monitor. In the event of an overcurrent event, a full power reset is triggered.&lt;/li&gt;
&lt;li&gt;Fast reset prevents damage from overcurrent condition&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Startup procedures are run, including on-chip self-tests which can clear invalid bits
Resets are logged and can be analyzed on the ground.&lt;/p&gt;
&lt;h2&gt;Watchdog&lt;/h2&gt;
&lt;p&gt;An external watchdog is used to mitigate the effects of a software lockup. With an approximately 0.5 second timeout period, the watchdog will execute a power-on reset of the MCU if not ‘pet’ within the timeout period. The watchdog ‘pet’ feature is implemented in an RTOS task. By suspending the watchdog task from the command system, external hard reset capability is provided.&lt;/p&gt;
&lt;h2&gt;Technical Specifications&lt;/h2&gt;
&lt;p&gt;Nominal Power Draw:                        313 mW
Maximum Power Draw:                     380 mW
Voltage Supply:                                   3.3 V
Tested Radiation Tolerance:              3.0 KRAD
Mechanical Form Factor:                   PC/104
Nonvolatile Memory:                          8 MB
RTC Backup Time:                               1 week
Clock Speed:                                        60 MHz&lt;/p&gt;
&lt;h2&gt;Ground Segment&lt;/h2&gt;
&lt;p&gt;SFUSat has developed a custom ground segment application called Houston. Huston provides the following functionality:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Live monitoring of all debug messages transmitted by the satellite&lt;/li&gt;
&lt;li&gt;Compatibility with RF or wired connections&lt;/li&gt;
&lt;li&gt;Command sequence creator&lt;/li&gt;
&lt;li&gt;Load and save of command sequences&lt;/li&gt;
&lt;li&gt;Uplink of command sequences&lt;/li&gt;
&lt;li&gt;Validation of uplinked commands&lt;/li&gt;
&lt;li&gt;Parsing of downloaded files and save to .csv&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Project Management&lt;/h2&gt;
&lt;p&gt;The project was managed with google docs as the document storage solution, and GitHub issues as the primary task tracking tool. I also experimented with Trello and Asana. A spreadsheet-based task tracker was adopted in the last phase of the project when the development team ballooned to 8 people under my management.&lt;/p&gt;
&lt;p&gt;We preferred to use the GitHub wiki for software documentation.&lt;/p&gt;
&lt;h2&gt;Versioning&lt;/h2&gt;
&lt;p&gt;The hardware versions are outlined below:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0.1&lt;/strong&gt; – experiments on LaunchPad&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0.2&lt;/strong&gt; – “DemoBoard” PCB built to prototype individual circuit designs for core features: latchup protection, flash memory, RTC, etc.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0.3&lt;/strong&gt; – First full revision, fully functional once reset circuit was bodged. 2-layer white PCB.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0.4&lt;/strong&gt; – Second revision, minor bug fixes from 0.3 version. 2-layer black PCB.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0.5&lt;/strong&gt; – Version used at CSDC final testing, black + ENIG 4-layer PCB. Minor bug fixes from 0.4, remove before flight programming jumper, full PC/104 connector layout.
The software operated on a continuous release schedule.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://www.academia.edu/11992711/On-board_data_handling_for_ambitious_nanosatellite_missions_using_automotive-grade_lockstep_microcontrollers&quot;&gt;1- On-board data handling for ambitious nanosatellite missions&lt;/a&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Getting Started With Deep Learning – Classifying Images From a Drone]]></title><description><![CDATA[Being as wrapped up in the tech industry as I am, I knew it would only be a matter of time until I would try my hand at some deep learning…]]></description><link>https://gatsby-casper.netlify.com/2018/04/06/deep-learning-drone-getting-started/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/2018/04/06/deep-learning-drone-getting-started/</guid><pubDate>Fri, 06 Apr 2018 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Being as wrapped up in the tech industry as I am, I knew it would only be a matter of time until I would try my hand at some deep learning. For me, the motivation to get stated came from two things; the realization that deep learning and ML are just another tool in the modelling toolbox, and the availability of a top-down and free course called FastAI.&lt;/p&gt;
&lt;p&gt;As I tend to do, this article will be part tutorial (I’ll share the steps and interesting things I’ve found), and part observational in nature. Let’s start learning!&lt;/p&gt;
&lt;h3&gt;My Interest in ML and Deep Learning&lt;/h3&gt;
&lt;p&gt;I’m interested in applying machine learning to the following areas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;analysis of satellite and drone data (telemetry and imagery)&lt;/li&gt;
&lt;li&gt;robotics applications, such as path planning and obstacle avoidance&lt;/li&gt;
&lt;li&gt;stock and forex training (deep earning)&lt;/li&gt;
&lt;li&gt;ML in embedded systems&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’m not as interested in algorithm development – at least the low level stuff. To me, machine learning approaches are a tool. Combining tools together in interesting ways is great and fun, and looks like making different function calls. Digging into the guts of TensorFlow is something I’ll leave to the researchers. What’s great about this area is that the bleeding-edge research is quickly being implemented in various ML toolkits, making the state of the art approaches available to us so we can tinker with them. The pace at which this is all happening is absolutely blistering – and it’s great that us (aspiring) practitioners who want to use it to get things done have (essentially free) access to the world’s best knowledge.&lt;/p&gt;
&lt;p&gt;Over the past little while, I’ve watched many hours of deep learning video and courses. However, none of them really helped the concepts click, until I stumbled across fast.ai. This is a relatively short course that revolves their PyTorch-based library of the same name. The explanations are clear, the code works out of the box, and the instructor mentions the tips and tricks for how to apply the techniques and have them work better. The last point is the key for me – you can get the basics anywhere, but it’s the tricks that’ll get you out of a hole. Fast.ai includes these, and I really appreciate it.&lt;/p&gt;
&lt;h3&gt;Deep Learning Without a GPU&lt;/h3&gt;
&lt;p&gt;Fast.ai starts off with details about a few ways to get GPU access. I decided to see how far I could get without a GPU using just my macbook pro (early 2015 with Intel Iris 6100 graphics). It turns out, that with my small test data set, training times were quite acceptable to me – a few minutes or less for 20 epochs of 100 or so 224px images. Given that for my test set, I don’t actually have any more data, this was totally fine. In the future, I’ll get everything running on my desktop which has a GTX650 and we’ll benchmark the difference.&lt;/p&gt;
&lt;p&gt;One free way to get GPU access is through Google Collab, which can run Jupyter notebooks and has a GPU accelerator option. Details are here. However, I found it a bit tricky to deal with my own files in Collab, and there were long delays while I’m assuming I was queued for GPU access. It was much smoother to run on my local machine, at least for me. Still though, it’s free GPU access, which is pretty amazing. Thanks Google!&lt;/p&gt;
&lt;h3&gt;Setting up FastAI&lt;/h3&gt;
&lt;p&gt;The FastAI videos go through some installation, but I decided to go it on my own. Here are the steps I took:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Install anaconda&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;git clone https://github.com/fastai/fastai.git
cd fastai&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;run the CPU-only install option:
&lt;code class=&quot;language-text&quot;&gt;conda env update -f environment-cpu.yml&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You can enter the environment with:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;conda activate fastai-cpu
cd courses/dl1&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In the course directory, you can open up lesson 1 by launching jupyter and browsing for the lesson 1 notebook. I made a copy of it too.&lt;/p&gt;
&lt;p&gt; &lt;code class=&quot;language-text&quot;&gt;jupyter notebook&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Now you can work your way through by running the cells with shift+enter. Hopefully you’re watching the videos too. I ended up having to reinstall opencv as it wasn’t playing nice with MacOS. There’s lots of information out there about how to fix any errors that may come up, but it’ll probably be much smoother overall if you install under Ubuntu. That’s what I’ll do when I spin it up on my desktop.&lt;/p&gt;
&lt;h3&gt;Working With Drone Images&lt;/h3&gt;
&lt;p&gt;Initially I wasn’t quite sure about the data I wanted to work with. Then I remembered that I have a set of images taken at the Unmanned Systems Canada 2016 competition. Most of these images are of the dry grass surrounding the Southport, Manitoba airfield. However, there are some large arrow shapes and QR codes in some of the images. Our task at the competition was to geo-locate these features, find their enclosed area (for the arrows), or decode them (for the QR code).&lt;/p&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/7e1439f0b567385c52f9eedee4787ec6/1e6f3/drone-ml-1.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1024px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 36.62109375%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAABE0lEQVQoz0WRWXLDMAxDfZg01r7Q8pLm/udiAcpNPjj0WNAjQC3Ssr7OTa+96y/66xDdpejWWUlLDppRbn1oCE/NyWuvUWsJmuKq0f9oZscZa+Eh6xpF36fo++h6jqoXwANgAbijnMPF5LTVgEEZZ1lr9h9QAJi1FIg4iZ1gwYUDYtaAQ8HlVhPET7jycOxVWtRjmwkanNLhF5inqCKWNAAIRe8A0w3/F8T0EDOmAELQLrOkTWCCyxQRmTsxGJxQTMgERnxzV9H2OB1+49L9gFMm8+7xSblQ3AHYICLI3Bb+izPuDeQFG3Y7ZOxuCby54+PYo7SaASs2mRDupN5D6LBY5ADxaju0R2zx3qczV/+PwxR/MfvWGnC/+jsAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Left: image with ground features, Right: uninteresting image&quot;
        title=&quot;&quot;
        src=&quot;/static/7e1439f0b567385c52f9eedee4787ec6/1e6f3/drone-ml-1.png&quot;
        srcset=&quot;/static/7e1439f0b567385c52f9eedee4787ec6/28404/drone-ml-1.png 293w,
/static/7e1439f0b567385c52f9eedee4787ec6/d7dd0/drone-ml-1.png 585w,
/static/7e1439f0b567385c52f9eedee4787ec6/1e6f3/drone-ml-1.png 1024w&quot;
        sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Left: image with ground features, Right: uninteresting image&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Since our image downlink wasn’t working during the flight, as soon as we landed the drone, we grabbed the SD card from the vision computer and rapidly did a manual screen of the images. I remember it being really difficult to see the images in the brightly-lit tent, and I definitely hid under a jacket to reduce the glare. Our task was to sort out all of the images with an arrow or QR code so we could process them further. The question is, can we instead do this with deep learning?&lt;/p&gt;
&lt;h3&gt;Yes we Can&lt;/h3&gt;
&lt;p&gt;Part of what’s neat about finally experimenting with something after observing it for a while is finally answering your questions. One of those was how data should be organized to feed it into a model. That brings me to the file structure, which looked like this.&lt;/p&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/68053c944baa97dc89eabc505f9d9b2d/e0e1a/drone-ml-2.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 664px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 80.72289156626505%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAABYlAAAWJQFJUiTwAAABdElEQVQ4y51U2Y6CQBDk/39qgcS43CReUZGIL2IEBI/IXdvDLmhYQWInTTrDUF1TXQNXliXaURQF2Hr97rfGoODYI/A9fPE8FEWFqqoIgqDZUA5FegbMshSe5+F0OsH3fSRJgjRNEcdxw/Q5+xpx7Rd5lkEUBIzH33B2u5cf9bHmHho9krEri5KYZ7hczgjDiDKk+oL7/d6pcwPY1fl6vWI6mUCWFeiahuVySU3yXsZce7GtVSNFnsPduzgcDnApt9stdiQJO00nwy5wFrfbDbIkwbIsrFZrmKaJ9dr6t68TsCZY13meYbOxYdt2BTqfz7EnxnGcvGfYNUnHcSqw2XSGxWJRHX0wQxZsoqqiwDCMyvC6bpBm2bChvNrArMHswjKKIgRk/JSsxAaU0TDYBWD1R0eOie1oNIJJbHVKgReItUZNy8+mzOzhuu6f0UMcj0difW4keMuwDc7uu0bmliQZoiiCp5+JZW2GH7mPMdO2vV7HD82Z3ysLywc4AAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Folder structure&quot;
        title=&quot;&quot;
        src=&quot;/static/68053c944baa97dc89eabc505f9d9b2d/e0e1a/drone-ml-2.png&quot;
        srcset=&quot;/static/68053c944baa97dc89eabc505f9d9b2d/9dd49/drone-ml-2.png 293w,
/static/68053c944baa97dc89eabc505f9d9b2d/45184/drone-ml-2.png 585w,
/static/68053c944baa97dc89eabc505f9d9b2d/e0e1a/drone-ml-2.png 664w&quot;
        sizes=&quot;(max-width: 664px) 100vw, 664px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;File structure&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;Data folder structure&lt;/h3&gt;
&lt;p&gt;So it’s straightforward – just a training and validation set, and the two classes of images are split manually into each directory. I ended up with 50 examples of each class, so 25 for each class in the training and validation sets. This is a very small amount of data by DL standards, but it’s workable when we’re just using a CPU to train the model.&lt;/p&gt;
&lt;p&gt;To start, I kept the same setup as the lesson. The model is a pre-trained Resnet34, said to be useful for image classification purposes. This is a convolutional neural network, meaning it performs convolutions to extract features. Basically this means it will “wipe” a matrix (kernel) across an image, and perform a matrix operation at each step of the wipe. This has the effect of consolidating data in a specific area, and it can, for example, effectively outline edges of shapes in an image. That’s just one part of this, and as I said, I’m not a low level algorithm guy – the details are better found elsewhere. Back to the results for us!&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;arch &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; resnet34
sz &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;224&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;# images will be resized to this size&lt;/span&gt;
data &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; ImageClassifierData&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;from_paths&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;PATH&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; tfms&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;tfms_from_model&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;arch&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; sz&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
learn &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; ConvLearner&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;pretrained&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;arch&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; data&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; precompute&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
learn&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fit&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/259de9be2147e20f6a596ea9d7a12e98/1e6f3/drone-ml-3.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1024px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 58.984375%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsSAAALEgHS3X78AAABxklEQVQoz4VT626iQBT2zTfZpN1t32SzT9HGgIkiqy1UCiLKTSzDiCveUL/OORv85dpJDjmE4ZvvcqYFtc7nM5IwwUv0ivvOA+50VdpPrnvV/9Af8a39Hb/s35inGbIsQxiGCKZTzGYzxHGCJEmQpilaVVVhuVxit9uh2lbIygxJkSL/m2Ox+uB+LucQlUBWZBC5wGazQV3X2O/3XIfDgYv61mq1YnRa9aGG7/kYmgOUsoQUEs6bgziMUe9ruI6L0WjEgP9bLXoQy+PxyCc4jgNd15HnOYQQMAwDvu8zSBRFvK+x6Vox4Hq95o0kg7yxbRvEnKygPgwjlsS+BQG22+0F9CpDKeXFkzcFoGkaiqLAYrFghiSTQGzbQqfTUQeVtwEbhg0LAiB2ZVnCUT0lSd+CYILh8IUtuglI8k6nEzMcj8fo9/uKoWSWf0zzAmhZFoyewftvAhIbMp1+8jwP3W5XhSIY0Oj14LoeH2ZZrzD7Jiv6UnIjmyS/q6TL8l8oruuqwY0ZkAKh9y8BKRSp2BBDCuX56YllUSi6rnHSNPiDwQDtdptH6iYgJUhFPtK1mkwmbAExmarrRVeKpoC+kZ/NYF8D/ATrjomkqmlqdQAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;First run of the model&quot;
        title=&quot;&quot;
        src=&quot;/static/259de9be2147e20f6a596ea9d7a12e98/1e6f3/drone-ml-3.png&quot;
        srcset=&quot;/static/259de9be2147e20f6a596ea9d7a12e98/28404/drone-ml-3.png 293w,
/static/259de9be2147e20f6a596ea9d7a12e98/d7dd0/drone-ml-3.png 585w,
/static/259de9be2147e20f6a596ea9d7a12e98/1e6f3/drone-ml-3.png 1024w&quot;
        sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;First run of the model&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This was a pre-trained model, so we just updated the last layers in the model to recognize our particular problem. Each iteration took about 1 second on my CPU, with images of size 224 px. We ended up at 94.2% accuracy.&lt;/p&gt;
&lt;p&gt;A classifier will create a prediction for the class of an image. Like weather, 50% means we don’t have a preference either way as to which class it is. For me, 1 (100%) is target and 0 is bare ground.&lt;/p&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/ad1b23fe8d90aadbb2fad938e246116f/1e6f3/drone-ml-4.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1024px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 23.4375%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsSAAALEgHS3X78AAABi0lEQVQY0x2OzUuaAQDGvXcoaEHQh5lzflS+e62sVXQYBEHQDoMgYoP+g0W0jTLL8tIkWOUkoh02zIqg7bRRUbqXnGWnPrT19pYYFoadLMzbL9fpx3N4fs+jisXOOTjYRzk95SaVIpPJkEgkiEQiHEejXF1dks1mub5OIssnHB0dchGPc3d3y/19hmQyiaIoj0yn06iMugqa6kXEaj29b3sI+LewCNXUi2bEGhPWOpG9cJjOjvZcNtLSWEeNUceiz0sg4Mc5Pob7i4eJTy58Cz5UT9UltDZYEAxa3nR34d/aRKgy0FgrUGs2IeSk4d0d2tte8rxKT7PVgq6iFO/3bwSDQaampvEtr+D2zLL64yeqooI8zHot6uJCXr/qYGN9DX1lOQatmmeaMrSa8lxxm5YXVjSlxZh0Gp7k5/F1fg5Jkphxe1hYWsE1+Rnv/4fv+9/hdNgZ+jjA3KyHf8dRxkZsOOxDjxy12zg7U5h0TWAb/IBjZJiB/j7+5kZkWUb6IxHaCfPr9xqhUIgHBcIBkBZGDrcAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;A selection of images and their class prediction (100 is target, 0 is ground).&quot;
        title=&quot;&quot;
        src=&quot;/static/ad1b23fe8d90aadbb2fad938e246116f/1e6f3/drone-ml-4.png&quot;
        srcset=&quot;/static/ad1b23fe8d90aadbb2fad938e246116f/28404/drone-ml-4.png 293w,
/static/ad1b23fe8d90aadbb2fad938e246116f/d7dd0/drone-ml-4.png 585w,
/static/ad1b23fe8d90aadbb2fad938e246116f/1e6f3/drone-ml-4.png 1024w&quot;
        sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;A selection of images and their class prediction (100 is target, 0 is ground).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;From the images above you can see that larger, more obvious features get picked up as a stronger target prediction (images 2 and 4). The first image only has faint arrows in it, and therefore a less confident (closer to 50%) prediction that it’s a target. Pretty neat!&lt;/p&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/0a68c8297e55bf5578f1d7bf95d3fdfa/1e6f3/drone-ml-5.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1024px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 23.925781249999996%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsSAAALEgHS3X78AAABVElEQVQY0x2QSU/CYBiE+eOauNQSrUWrLEUjtYCtLEVxw4gLeCaYaEJlUcFewAiEBEjg8Pjh6U1mJrO8vm63S7PZZHHH4zGz2YzBYEC7/YXneYxGI+bzOcPhkE6nI/A2/X7/XzeZTPjp9QQusN9fptMpPml9DU3bY2lpmaOjGG+vr4SDe5imgSxvoChb1N9dlE2ZQEAlHAkhb0i4rstZzsEwYsQMA0mSKBaL+CK6jpk8YTuwi2WdUqvVhJnJaTpNWI9ycHBIo15H3VZIJuNYtoWuh/n8+MDJZoknEqQyGXShK5efF4ZRDDPBjraPbaeoVCrIfj+hSAQtGBKNdFwRsrqywuaWwq5Yo6oqrVYL8zhOYEcjKswW3P39A76bmwKPT2Xy+QuRUKbRaIqmNmfnebKOw+Xl1f/vbMvCcXJcXxfIiPbet0epVOJC8IXbO1LpDNXqC3/qtTnC7q4YpQAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Most confident target predictions&quot;
        title=&quot;&quot;
        src=&quot;/static/0a68c8297e55bf5578f1d7bf95d3fdfa/1e6f3/drone-ml-5.png&quot;
        srcset=&quot;/static/0a68c8297e55bf5578f1d7bf95d3fdfa/28404/drone-ml-5.png 293w,
/static/0a68c8297e55bf5578f1d7bf95d3fdfa/d7dd0/drone-ml-5.png 585w,
/static/0a68c8297e55bf5578f1d7bf95d3fdfa/1e6f3/drone-ml-5.png 1024w&quot;
        sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Most confident target predictions.&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;This was an interesting experiment, and it’s encouraging to see how straightforward it is to get a model running, and how good the results were. Looking at the mis-classified data, there appear to only be one or two images (I tweaked my image sets a bit since taking the screenshots). The misses are shadowy pieces of arrows, and are even difficult for me to classify. Given the small amount of data, I’m impressed.&lt;/p&gt;
&lt;p&gt;I did not find that data augmentation helped with these images. It makes sense, as the arrows appear in all different orientations in the data anyway, so the net is exposed to a variety of versions of the same thing. Tweaking contrast and brightness would likely help for these images, as they’re quite dull and flat even for a human to process.&lt;/p&gt;
&lt;p&gt;Currently I plan to write some more friendly wrapper functions for this library. Ones that don’t error out when there are no incorrectly classified images, for example. Beyond that, I plan to experiment with the course content a bit more, get more of a feel for deep learning, and then tackle a couple of projects I’ve had in mind.&lt;/p&gt;
&lt;p&gt;If you’re interested in giving deep learning a go, don’t hesitate. There are many resources out there, and it’s easy to get going on small data sets with a mainstream computing setup.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Digitizing Player Piano Scrolls With OpenCV]]></title><description><![CDATA[At NWHacks in 2018 my team and I made a system to digitize player piano music scrolls using openCV. Using a camera, the location of the…]]></description><link>https://gatsby-casper.netlify.com/2018/02/27/digitize-player-piano-scroll-opencv/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/2018/02/27/digitize-player-piano-scroll-opencv/</guid><pubDate>Tue, 27 Feb 2018 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;At NWHacks in 2018 my team and I made a system to digitize player piano music scrolls using openCV. Using a camera, the location of the holes in the piano scroll is detected. The presence of a hole in a particular column corresponds to the press of a key on a piano. Once the location of the notes is known, the data is turned into a MIDI file and can be played back. &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ZIfG2oer17E&quot;&gt;Video&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Hardware&lt;/h2&gt;
&lt;p&gt;A Raspberry Pi 3 and camera are used, which allowed for quick prototyping in the fast-paced hackathon environment. &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://devpost.com/software/piano-men&quot;&gt;https://devpost.com/software/piano-men&lt;/a&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Radiation Testing a CubeSat Computer]]></title><description><![CDATA[At the SFU Satellite Design Team, we are taking part in the Canadian Satellite Design Challenge. As part of the challenge, we were offered…]]></description><link>https://gatsby-casper.netlify.com/2017/09/23/radiation-testing-cubesat-computer/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/2017/09/23/radiation-testing-cubesat-computer/</guid><pubDate>Sat, 23 Sep 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;At the SFU Satellite Design Team, we are taking part in the Canadian Satellite Design Challenge. As part of the challenge, we were offered the chance to put some of our hardware in a proton beam at the TRIUMF facility, Canada’s national lab for nuclear and particle physics. This was a really unique opportunity, and one we were excited to use to the best of our ability.&lt;/p&gt;
&lt;p&gt;We designed a test for our onboard computer (OBC), which has the following features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TMS570 microcontroller (ECC flash &amp;#x26; RAM, lockstep architecture)&lt;/li&gt;
&lt;li&gt;external flash memory&lt;/li&gt;
&lt;li&gt;real time clock&lt;/li&gt;
&lt;li&gt;external watchdog&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Primarily, we were interested in a qualitative understanding of how the system performed under the proton beam. The test software we developed had the following functions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MCU self-tests (RAM, self-test controller, various peripherals)&lt;/li&gt;
&lt;li&gt;initialization routine and RTOS control&lt;/li&gt;
&lt;li&gt;reason for reset reporting&lt;/li&gt;
&lt;li&gt;external flash reads and writes&lt;/li&gt;
&lt;li&gt;time stamping of all data in flash&lt;/li&gt;
&lt;li&gt;serial communication of all flash reads/writes for logging on computer&lt;/li&gt;
&lt;li&gt;frequent watchdog kicks&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Radiation Effects&lt;/h2&gt;
&lt;p&gt;Radiation can effect hardware in two different ways. First, single event upsets (SEU) are simple bit flips caused by a high energy particle. They don’t typically cause permanent damage, but do result in corrupted data. They are fixed by resetting the appropriate bit. ECC memory, for example, is an appropriate way to deal with SEU effects.&lt;/p&gt;
&lt;p&gt;Single event latchups are a more serious issue. In these cases, a high energy particle will alter the silicon in such a way that a P-N-P-N junction will be created. This is known as a parasitic thyristor. Thyristors can’t be turned off by any means except removing power to the thyristor (there’s no gate). In practice, this means that a chip that has SEL’d needs a power-on (hard) reset. If this reset happens fast enough, damage can be avoided. SEL events essentially create a short inside the chip, meaning current consumption will increase significantly. Therefore, we can attempt to protect against latchup by monitoring the current draw and toggling the power if the current suddenly spikes drastically. On the SFUSat OBC, we use the INA301 current sense amplifier and a FET to do this.&lt;/p&gt;
&lt;h2&gt;Test Design&lt;/h2&gt;
&lt;p&gt;The main idea is that the computer will be running fairly standard functionality (reading and writing to flash). We write, then read flash to determine if any upsets have happened due to radiation, and we print the values (at time of read) to the serial port for logging. All writes to flash are time tagged in the flash itself, and writes happen at a reliable frequency. This allows us to determine whether the RTC is still operational.&lt;/p&gt;
&lt;p&gt;The watchdog is external, although there is an internal one on the MCU. Should the system lock up due to an SEU or a latchup, the watchdog will power-on reset the MCU. This triggers the self-tests, which utilize the diagnostic structures for testing the chip at the fab, but allow us to access them with software. The idea is that these self-tests are a very fast and efficient way to toggle nearly all of the transistors on the chip, hopefully clearing any temporary upsets that may have triggered the reset in the first place. Since the reason for reset is saved and reported at startup, we can see when this happens on the monitoring computer.&lt;/p&gt;
&lt;p&gt;Overall, it was a simple test, but one that was representative of the typical types of things that the OBC will need to do. There were a few limitations, which were not implemented due to time constraints:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;no checking of number of errors automatically corrected&lt;/li&gt;
&lt;li&gt;no self-test of CPU core compare module&lt;/li&gt;
&lt;li&gt;no verification of flash integrity before writing&lt;/li&gt;
&lt;li&gt;no use of internal watchdog&lt;/li&gt;
&lt;li&gt;no test of command/response from the host computer&lt;/li&gt;
&lt;li&gt;no monitoring of power consumption for silicon degradation effects&lt;/li&gt;
&lt;li&gt;no dedicated latchup detection or mitigation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It would have been great to get to these features. Particularly, seeing how many errors (in RAM, for example) had been automatically corrected by the chip’s ECC would have been very interesting. Overall, the intent was to test macro functionality, to determine that our OBC design could operate in a radiation rich environment, not to determine what exactly the effects are. The good news is that we can functionally test most of these items without the need for a cyclotron. For example, TI provides an API to inject errors into ECC, which will allow us to test the ECC mechanism itself. Silicon degradation is very interesting to me, and it was suggested that the power consumption will increase with the total dose of radiation received. It would be very interesting and valuable to study this, and I hope we can in the future!&lt;/p&gt;
&lt;p&gt;Despite the limitations on the scope of our test, it will give us valuable information. Primarily, we aim to establish whether the OBC can perform in low Earth orbit for a period of 1 year, and correct any errors that should arise from radiation effects. Since the reliability features used during the test are only a subset of those to be used on the actual satellite, we can reasonably expect higher reliability under the same test conditions once those features are implemented.&lt;/p&gt;
&lt;h2&gt;Test Script&lt;/h2&gt;
&lt;p&gt;To monitor the data coming back from the OBC as it was under test, I developed a simple test script in Python to take in the serial stream and time-tag each message with the UNIX epoch. This allowed us to view the data coming back in real time to determine if anything had happened to the OBC as it was under test. Time-tagging with a very accurate epoch might allow us to see if the RTC clock drifted significantly. However, the system is not deterministic, so we would most likely only be able to detect very large drifts.&lt;/p&gt;
&lt;p&gt;Of course, all of the incoming data was saved into a file as well. I will do a tutorial on writing a script like this one, as it’s a pretty quick and easy way to do a comprehensive test of an embedded system like our OBC. Also, it featured automatic reconnection, which was done in a clever way thanks to Python.&lt;/p&gt;
&lt;h2&gt;Test Setup&lt;/h2&gt;
&lt;p&gt;Going in to the test, I really did not know what to expect. To a piece of plastic, I mounted a TMS570Ls043 LaunchPad, the OBC demo board (for the RTC and watchdog), and an external breakout I made for some new flash memory, since the chips on the demo board had been EOL’d by Cypress.&lt;/p&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/7553ddb242ebbe11492ccd13ba8055cf/3afc2/triumf-2.jpg&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1170px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 56.22263914946842%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAwQA/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAARYqoi0mr//EABoQAAMBAAMAAAAAAAAAAAAAAAECAwARIiP/2gAIAQEAAQUCLFtOvet/SYDWKKNccU//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAgEBPwFH/8QAGhAAAwEAAwAAAAAAAAAAAAAAAAERITFhof/aAAgBAQAGPwJkXHo0rnZGOJGH/8QAGxAAAwADAQEAAAAAAAAAAAAAAAERITFBYYH/2gAIAQEAAT8hTJvs+i2uJXqYMhsKXoWE1QYyp4KesKqf/9oADAMBAAIAAwAAABAfP//EABcRAQADAAAAAAAAAAAAAAAAAAABITH/2gAIAQMBAT8QjVv/xAAXEQEAAwAAAAAAAAAAAAAAAAAAAREx/9oACAECAQE/EJxR/8QAHBABAQADAAMBAAAAAAAAAAAAAREAITFRYXHR/9oACAEBAAE/ENm9BF0h4YmTAFckZv1hwkRBF3qXv5ncp4/cpOoBBfPfuDjALdq9z//Z&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Inside proton beam facility&quot;
        title=&quot;&quot;
        src=&quot;/static/7553ddb242ebbe11492ccd13ba8055cf/27561/triumf-2.jpg&quot;
        srcset=&quot;/static/7553ddb242ebbe11492ccd13ba8055cf/06456/triumf-2.jpg 293w,
/static/7553ddb242ebbe11492ccd13ba8055cf/4b3e4/triumf-2.jpg 585w,
/static/7553ddb242ebbe11492ccd13ba8055cf/27561/triumf-2.jpg 1170w,
/static/7553ddb242ebbe11492ccd13ba8055cf/3afc2/triumf-2.jpg 1599w&quot;
        sizes=&quot;(max-width: 1170px) 100vw, 1170px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Proton beam facility with our test setup&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It turned out that we were testing in TRIUMF’s proton therapy facility, which is typically used to treat eye cancer. They had removed the patient chair, and there was an X-Y stage that we could mount our boards to. After selecting an appropriately sized collimator, we aimed the beam at the MCU onboard. We decided to primarily irradiate the MCU since we were mostly interested in its reliability features. If we had more time, it would have been interesting to test the RTC and flash more specifically.&lt;/p&gt;
&lt;h2&gt;Successful Test&lt;/h2&gt;
&lt;p&gt;I really got the sense that the cyclotron is a living being - and one that straddles the line between being under our control, and out of it. Earlier that day, they had to shut the system down because of a power supply failure. And as they were bringing the beam up to start our test, I watched the numbers in 4 quadrants change, as an operator steered the beam to centre it. You can almost imagine someone driving this beam around, pulling levers and things. It’s not really like that, but all of the older looking control consoles give that kind of vibe. It’s interesting, having cutting edge research (and our simple test), and very well engineered (though old) equipment working together.&lt;/p&gt;
&lt;p&gt;Digression aside, watching the beam come up to energy was really cool. When they opened the shutter, I was initially nervous that the OBC would kick the bucket very early on in the test. That didn’t happen, and it kept going, and going, and going, as more protons were channeled towards it. About 2/3 the way into the 20 minute test, we had what looked like an SEU event, as we got back some garbled data. More on this in another post after I analyze things further.&lt;/p&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/1371d1c09d07c56cf1eb9ed9cd604f1f/3afc2/triumf-3.jpg&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1170px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 56.22263914946842%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIDBP/EABUBAQEAAAAAAAAAAAAAAAAAAAIB/9oADAMBAAIQAxAAAAFnhiNuYxH/xAAZEAACAwEAAAAAAAAAAAAAAAABAgADETH/2gAIAQEAAQUCSwazLGLbZ2xQDP/EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAEDAQE/AVf/xAAXEQEAAwAAAAAAAAAAAAAAAAAAARES/9oACAECAQE/AaYh/8QAGxAAAQQDAAAAAAAAAAAAAAAAAAECEEERITH/2gAIAQEABj8Co7kpB5qP/8QAHBABAAICAwEAAAAAAAAAAAAAAQARIXExQWGx/9oACAEBAAE/IQ1KnZUeXnfZ8Mu4nQgTAFanK7n/2gAMAwEAAgADAAAAEHjf/8QAFhEBAQEAAAAAAAAAAAAAAAAAAQAR/9oACAEDAQE/EFdt3//EABURAQEAAAAAAAAAAAAAAAAAAAEQ/9oACAECAQE/EAJD/8QAHBABAAIDAQEBAAAAAAAAAAAAAQARIUFRMXGB/9oACAEBAAE/EAbGKWqBvyGOCDb8hFbixRh9WOBcEOD6TFHM40RW2rSC+T//2Q==&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;TRIUMF Cyclotron&quot;
        title=&quot;&quot;
        src=&quot;/static/1371d1c09d07c56cf1eb9ed9cd604f1f/27561/triumf-3.jpg&quot;
        srcset=&quot;/static/1371d1c09d07c56cf1eb9ed9cd604f1f/06456/triumf-3.jpg 293w,
/static/1371d1c09d07c56cf1eb9ed9cd604f1f/4b3e4/triumf-3.jpg 585w,
/static/1371d1c09d07c56cf1eb9ed9cd604f1f/27561/triumf-3.jpg 1170w,
/static/1371d1c09d07c56cf1eb9ed9cd604f1f/3afc2/triumf-3.jpg 1599w&quot;
        sizes=&quot;(max-width: 1170px) 100vw, 1170px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Inside TRIUMF&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Aside from the SEU event though, the system performed flawlessly, and we noticed no data corruption and no resets during the test. It was also interesting to note the difference in capability between our TMS570, and a standard STM32 part. The initial dose is measured in an arbitrary calibration unit they call MC. Our test finished around 351,000 MC (3 krads), and the system was still going strong. The STM32 tested by another team only was able to handle 6,000 MC (0.05128 krads).&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This test was an extremely valuable opportunity for the team, and I’m very happy with how it went. Clearly, there are more things we should implement for the next time a radiation test rolls around, which would make it that much more valuable. I’d also like to extend thanks to the CSDC management team, and the folks at TRIUMF who stayed up late and volunteered to help us run our tests.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Raspberry Pi & OpenCV - UART Communication (Part 2)]]></title><description><![CDATA[In this second post regarding my experiments with OpenCV on the Raspberry pi, I will go over interfacing the OpenCV code with the Pi’s UART…]]></description><link>https://gatsby-casper.netlify.com/2017/08/23/raspberry-pi-opencv-uart-communication-part-2/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/2017/08/23/raspberry-pi-opencv-uart-communication-part-2/</guid><pubDate>Wed, 23 Aug 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;In this second post regarding my experiments with OpenCV on the Raspberry pi, I will go over interfacing the OpenCV code with the Pi’s UART, so that I can send image centroids to the auxiliary MCU that will be used for motor control. These posts will be somewhere between a tutorial and a build log - all steps will be mentioned, but not in great detail.&lt;/p&gt;
&lt;p&gt;Part 1: &lt;a href=&quot;http://richarthurs.com/2017/08/20/getting-started-with-opencv-and-raspberry-pi/&quot;&gt;http://richarthurs.com/2017/08/20/getting-started-with-opencv-and-raspberry-pi/&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Configuring UART&lt;/h2&gt;
&lt;p&gt;First, follow the instructions here: &lt;a href=&quot;https://spellfoundry.com/2016/05/29/configuring-gpio-serial-port-raspbian-jessie-including-pi-3/&quot;&gt;https://spellfoundry.com/2016/05/29/configuring-gpio-serial-port-raspbian-jessie-including-pi-3/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I disabled the UART&gt;console connection using the raspi-config (sudo raspi-config), meaning that I didn’t need to manually remove it from the cmdline.txt file.&lt;/p&gt;
&lt;h2&gt;Testing UART&lt;/h2&gt;
&lt;p&gt;On my Pi 3, the UART connected to GPIO 14 and 15 is available at /dev/serial0. On the Pi, run the following commands to install the screen utility and get an instance running.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;sudo apt-get install screen
screen /dev/serial0 115200&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you short GPIO 14 and 15, you should see the entered characters echoed back on your display. To quit a screen instance on the pi, press escape, then ctrl+a, then \&lt;/p&gt;
&lt;h2&gt;Laptop Test&lt;/h2&gt;
&lt;p&gt;I wanted to test out communication to my laptop, so I grabbed a package to install screen. After installing, I connected a 3.3V USB-UART converter, being sure to connect Pi Rx to converter TX, and vice-versa. Also connect a GND line between the Pi and the converter, since they aren’t likely connected to the same power source.&lt;/p&gt;
&lt;p&gt;To find the location of your serial converter on mac or linux, run ls /dev and look for something along the lines of “tty.usbserial-A50285BI.” This is the equivalent of serial0 on the Pi.  Run the following command to start a screen instance:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;screen /dev/_your_adapter_address_here 115200&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Assuming you have screen instances running on the Pi and computer simultaneously, you should see characters echoed between the two as you type on either keyboard. I initially forgot to connect a common GND between the two devices, which caused me to only receive on my computer from the Pi, but not from my computer.&lt;/p&gt;
&lt;p&gt;To quit screen on mac or linux, ctrl + a, then :, then “quit” (no quotes).&lt;/p&gt;
&lt;h2&gt;PySerial&lt;/h2&gt;
&lt;p&gt;PySerial is an excellent and easy to use serial communication library that I’ve used before. We’ll bring it into this project on the Pi, and it can be installed with pip install pyserial. &lt;/p&gt;
&lt;p&gt;I wrote up the following test script and ran it with python serialtest.py.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;import serial 
ser = serial.Serial(&amp;#39;/dev/serial0&amp;#39;, 115200, timeout = 1) 
print ser.name 

for i in range(0,5,1):
    ser.write(str(i))
ser.close()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After confirming that everything worked as expected, we are now ready to test integration with the rest of the OpenCV code and confirm that the centroid locations are being sent over correctly.&lt;/p&gt;
&lt;h2&gt;OpenCV Integration&lt;/h2&gt;
&lt;p&gt;Since I was already printing the centroid locations to the terminal, I just needed to replace the print() commands with ser.write() and some internal string formatting to include a return and newline. Running the code and looking at the UART output from the Pi, we can see that it is correctly sending the x,y coordinates of the centroid as I move the camera around.&lt;/p&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/58108b854078b32a2642bb26955dc92d/c8408/raspi-opencv-2-2.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1170px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 82.69794721407625%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAABYlAAAWJQFJUiTwAAABT0lEQVQ4y62UO07DQBCGbaWI4vj9XJx1CAUV3IWeM8QFQnSWQLIcnBSIM3ARUnAEDoBANIguuAE7w2+TRAjRxNmVPq1mLH+aWe9YkrCIqEv0toe9LSFwpfXKLpLT2/S8vLq5XMzy2Uee58Wa6XRapGlaJElSTCbXTfz7OVggV2ZZ9ghVtxGatj322YB0Vae64Ja8AqcR+r4fH4xGZFlWibCSZXn5F+SX/+VBCQg816pGqGlazBgj7FX94paVVav9BXg/LZtmzIKAFEURIzQMM0bb1Ov1xAhd14s556Sqqhhh/VH2h0MydF2M0HGcOAxDsm1bVMsuhAOyTEuQ0HGbCnEPhZ3hOIqiuuVPhOWWfK2ETxuh53pnnEeE1ncZvffNpOBCn2iaPu8r/TnCbbkHD+CumWUWMLkeFnAIjsFRS/jmb4M5lnkUdQLf7yDcBekbwJJOKf9U1IgAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Screenshot of the screen tool showing output from the pi&quot;
        title=&quot;&quot;
        src=&quot;/static/58108b854078b32a2642bb26955dc92d/a66a3/raspi-opencv-2-2.png&quot;
        srcset=&quot;/static/58108b854078b32a2642bb26955dc92d/65e34/raspi-opencv-2-2.png 293w,
/static/58108b854078b32a2642bb26955dc92d/8d594/raspi-opencv-2-2.png 585w,
/static/58108b854078b32a2642bb26955dc92d/a66a3/raspi-opencv-2-2.png 1170w,
/static/58108b854078b32a2642bb26955dc92d/c8408/raspi-opencv-2-2.png 1364w&quot;
        sizes=&quot;(max-width: 1170px) 100vw, 1170px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Screen output showing centroid locations coming from the Pi over UART&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Next Steps&lt;/h2&gt;
&lt;p&gt;Now that serial communication is working and it can be easily integrated with the rest of the OpenCV code, I need to determine if I want to use any sort of protocol between the auxiliary MCU and the Pi. Since I will likely need to send data back and forth, it is probably a good idea to keep everything well defined. More on that in the next post!&lt;/p&gt;
&lt;p&gt;Reviewing the task list in the first post, I’d say I’m about half way through part 3.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install and compile OpenCV on the pi&lt;/li&gt;
&lt;li&gt;Track and find centroid of an object&lt;/li&gt;
&lt;li&gt;Send out obstacle centroid over UART&lt;/li&gt;
&lt;li&gt;Integrate OpenCV and pySerial&lt;/li&gt;
&lt;li&gt;Determine message protocol&lt;/li&gt;
&lt;li&gt;Get a simple motor control system on the auxiliary MCU working&lt;/li&gt;
&lt;li&gt;Start developing obstacle avoidance functionality&lt;/li&gt;
&lt;/ol&gt;</content:encoded></item><item><title><![CDATA[CubeSat Computing Boards]]></title><description><![CDATA[At the  SFU Satellite Design Team , we’re building a CubeSat from scratch. One of my main roles is designing the onboard computer hardware…]]></description><link>https://gatsby-casper.netlify.com/2017/08/20/cubesat-computing-boards/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/2017/08/20/cubesat-computing-boards/</guid><pubDate>Sun, 20 Aug 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;At the &lt;a href=&quot;sfusat.org&quot;&gt;SFU Satellite Design Team&lt;/a&gt;, we’re building a CubeSat from scratch. One of my main roles is designing the onboard computer hardware, as well as developing a lot of the onboard software. This post is a brief overview of the two boards that I designed and the team have assembled thus far.&lt;/p&gt;
&lt;p&gt;Both of these boards were designed and laid out by me using KiCad. The repositories for the board files can be found here.&lt;/p&gt;
&lt;h2&gt;OBC Prototype Rev. A&lt;/h2&gt;
&lt;p&gt;This board was completed in August, 2017. The design process began about 3 months before the prototype was assembled. It is a prototype of the entire computing system, including the following features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Real time clock with built-in capacitor backup&lt;/li&gt;
&lt;li&gt;Triple redundant nonvolatile memory (flash)&lt;/li&gt;
&lt;li&gt;External watchdog timer&lt;/li&gt;
&lt;li&gt;Single event latchup protection&lt;/li&gt;
&lt;li&gt;TMS570LS0714 microcontroller&lt;/li&gt;
&lt;li&gt;FTDI USB-UART converter&lt;/li&gt;
&lt;li&gt;PC-104 form factor&lt;/li&gt;
&lt;li&gt;Onboard voltage regulation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/a91715c3f6028f390dd4c49f5ede7097/4c221/cubesat-boards-2.jpg&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 700px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 72%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAMBAgQF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAABq/Mw4xAf/8QAGxAAAQUBAQAAAAAAAAAAAAAAAwECEhMyBBH/2gAIAQEAAQUC5sEjU/YXLWQkhEX0n//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABoQAAICAwAAAAAAAAAAAAAAAAACAXEREjH/2gAIAQEABj8CbbhlYGsgmhrP/8QAGhAAAgMBAQAAAAAAAAAAAAAAAREAITFRYf/aAAgBAQABPyEACY3kdgG89i1Y0ASULdQKbhg6U//aAAwDAQACAAMAAAAQpB//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAcEAEBAAMBAAMAAAAAAAAAAAABEQAhMVFBcYH/2gAIAQEAAT8QK9ZDR52X8yjqRSBAHZjbdoTyuaNx+UpazCoC6CHvtwASCA+3P//Z&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;OBC Revision A&quot;
        title=&quot;&quot;
        src=&quot;/static/a91715c3f6028f390dd4c49f5ede7097/4c221/cubesat-boards-2.jpg&quot;
        srcset=&quot;/static/a91715c3f6028f390dd4c49f5ede7097/610c7/cubesat-boards-2.jpg 293w,
/static/a91715c3f6028f390dd4c49f5ede7097/a8060/cubesat-boards-2.jpg 585w,
/static/a91715c3f6028f390dd4c49f5ede7097/4c221/cubesat-boards-2.jpg 700w&quot;
        sizes=&quot;(max-width: 700px) 100vw, 700px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;OBC Revision A&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This board will be used by the team to develop the flight software, as it represents a good approximation of the final flight hardware, and includes all of the core features. Crucial to this purpose is the inclusion of the JTAG header and FTDI adapter, meaning that only a standalone debugger is required to debug/program the device. Power and UART out can come over the integrated USB port.&lt;/p&gt;
&lt;p&gt;Unfortunately, a couple of layout errors were discovered. The resistors surrounding the oscillator are slightly too close, and the edge of the JTAG connector covers one set of pin headers, used to enable and disable the watchdog.&lt;/p&gt;
&lt;p&gt;Further testing of the board is underway at the time of this writing. Currently, we’re working to diagnose some JTAG connection issues regarding software support for the chip.&lt;/p&gt;
&lt;p&gt;A key design decision made with this board was to make most functionality modular, in case something else doesn’t work. It is possible to enable and disable most of the auxiliary features such as the watchdog and SEL monitor. This helps isolate errors, and was important in diagnosing the JTAG issue, as it allowed us to ensure that the chip had no power or reset problems.&lt;/p&gt;
&lt;p&gt;Additionally, communication headers for all peripheral devices are provided, allowing for easy logic analyzer connection, and the ability to interface peripherals with existing development boards that are used by the team.&lt;/p&gt;
&lt;h2&gt;PC-104&lt;/h2&gt;
&lt;p&gt;Since the team’s development happens in separate sub teams, we have adopted a set of standards to ensure our hardware will all work together. Our form factor standard is PC-104, which just happens to fit inside a CubeSat. The standard defines the PCB size and connector layout, as well as the pinout of the connector. We have elected not to follow the standard pinout, but have instead created our own which is more modern and suited to our project.&lt;/p&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/09f31c497f74ca89c71c019b9a9daf83/3afc2/cubesat-boards-3.jpg&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1170px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 56.22263914946842%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAMCBAX/xAAVAQEBAAAAAAAAAAAAAAAAAAABAP/aAAwDAQACEAMQAAABzX1kiskR/8QAGRAAAwEBAQAAAAAAAAAAAAAAAAEDAhAS/9oACAEBAAEFApS9FY5WBj5//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGhAAAgIDAAAAAAAAAAAAAAAAAhEAICExcf/aAAgBAQAGPwJlqMSz2v8A/8QAGRAAAwEBAQAAAAAAAAAAAAAAAAEhETEQ/9oACAEBAAE/IV0d5HRNWeOWYImS55//2gAMAwEAAgADAAAAECs//8QAFREBAQAAAAAAAAAAAAAAAAAAARD/2gAIAQMBAT8QSf/EABURAQEAAAAAAAAAAAAAAAAAAAEQ/9oACAECAQE/EBn/xAAdEAEBAAIBBQAAAAAAAAAAAAABEQAxQRAhYXHB/9oACAEBAAE/EElgBICU334OcXzKdBl+TPPBIlB1hFKD30//2Q==&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;PC-104 Stacked OBCs&quot;
        title=&quot;&quot;
        src=&quot;/static/09f31c497f74ca89c71c019b9a9daf83/27561/cubesat-boards-3.jpg&quot;
        srcset=&quot;/static/09f31c497f74ca89c71c019b9a9daf83/06456/cubesat-boards-3.jpg 293w,
/static/09f31c497f74ca89c71c019b9a9daf83/4b3e4/cubesat-boards-3.jpg 585w,
/static/09f31c497f74ca89c71c019b9a9daf83/27561/cubesat-boards-3.jpg 1170w,
/static/09f31c497f74ca89c71c019b9a9daf83/3afc2/cubesat-boards-3.jpg 1599w&quot;
        sizes=&quot;(max-width: 1170px) 100vw, 1170px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;PC-104 Stacked OBCs&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;OBC Demo Board&lt;/h2&gt;
&lt;p&gt;The demo board came first in the lineage of SFUSat computing hardware. Designed and assembled in May and June of 2017, it served as a test platform for the MCU external peripherals and our more custom circuitry. Its peripherals were connected to the TMS570LS03x-04x LaunchPad, which has served as our development platform so far. The demo board has the following features:&lt;/p&gt;
&lt;p&gt;Prototype of SEL protection circuitry with external load connector
Watchdog chip with all important pins broken out
Real time clock and capacitor backup
Triple redundant nonvolatile memory
The testing regime for this board included verification of the SEL mitigation circuitry. Based on the INA301, this circuit detects an over current condition and toggles the power supply accordingly. To test, power resistors were connected to simulate the load of the entire OBC. Then, the frequency of switching was measured. Under light current loads, DC was fed to the circuit. In an over current condition, the power supply was being toggled by the chip at around 60Hz, which matches the spec for chip response time. This meant that since the heavy load was never removed, the protection circuit was repeatedly toggling power to attempt to reset the system.&lt;/p&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/621120090bc1c740ed7d2ee61719971f/4c221/cubesat-boards-1.jpg&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 700px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 56.285714285714285%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAQBAgX/xAAVAQEBAAAAAAAAAAAAAAAAAAABAv/aAAwDAQACEAMQAAABzGLpyrklH//EABoQAQACAwEAAAAAAAAAAAAAAAECEgMQESH/2gAIAQEAAQUCp5HAMU4q1ZOv/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGxAAAgEFAAAAAAAAAAAAAAAAABABERIxQWH/2gAIAQEABj8CO0VujMr/xAAaEAADAQEBAQAAAAAAAAAAAAAAARExIWFx/9oACAEBAAE/Iapxww723hQQ1Z/Jl5L0en//2gAMAwEAAgADAAAAEI8f/8QAFhEBAQEAAAAAAAAAAAAAAAAAARAR/9oACAEDAQE/EEyf/8QAFhEAAwAAAAAAAAAAAAAAAAAAAAER/9oACAECAQE/EE6Q/8QAGhABAAMBAQEAAAAAAAAAAAAAAQARITFBUf/aAAgBAQABPxBJtT2shrV88r5ndIyJSPsZJ9fMv0DABlRqlVfq3P/Z&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Demo board and rev A&quot;
        title=&quot;&quot;
        src=&quot;/static/621120090bc1c740ed7d2ee61719971f/4c221/cubesat-boards-1.jpg&quot;
        srcset=&quot;/static/621120090bc1c740ed7d2ee61719971f/610c7/cubesat-boards-1.jpg 293w,
/static/621120090bc1c740ed7d2ee61719971f/a8060/cubesat-boards-1.jpg 585w,
/static/621120090bc1c740ed7d2ee61719971f/4c221/cubesat-boards-1.jpg 700w&quot;
        sizes=&quot;(max-width: 700px) 100vw, 700px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Demo board and OBC rev A&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Issues uncovered using this board include an incorrect RTC footprint (hence the blue bodge wires), as the data sheet provided an unlabelled and improperly placed bottom view, instead of the standard footprint top view. However, the repair was successful and this board was used in development of the RTC driver software. Additionally, the flash memory onboard was EOL’d by the manufacturer shortly after we’d ordered it, so memory driver implementation was delayed.&lt;/p&gt;
&lt;p&gt;The demo board was very helpful for the team’s design process, and will certainly be used in the future to bring members up to speed with peripheral driver development, and the overall architecture of the system. Since these boards were inexpensive to make, they are an excellent experimentation and learning platform for the higher risk scenarios, and they allow us to leverage a lot of the development hardware already acquired by the team.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Getting Started With OpenCV and Raspberry Pi]]></title><description><![CDATA[I bought a Raspberry Pi nearly a year ago, always intending to use it in OpenCV experiments. Just recently, I got around to starting the…]]></description><link>https://gatsby-casper.netlify.com/2017/08/20/getting-started-with-opencv-and-raspberry-pi/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/2017/08/20/getting-started-with-opencv-and-raspberry-pi/</guid><pubDate>Sun, 20 Aug 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I bought a Raspberry Pi nearly a year ago, always intending to use it in OpenCV experiments. Just recently, I got around to starting the project. The current plan is to make a small robot that first, uses computer vision to track and follow an object. The next phase will be obstacle avoidance, and is where the project becomes more of an OpenCV experiment.&lt;/p&gt;
&lt;p&gt;The main tasks are as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install and compile OpenCV on the pi&lt;/li&gt;
&lt;li&gt;Track and find centroid of an object&lt;/li&gt;
&lt;li&gt;Send out obstacle centroid over UART&lt;/li&gt;
&lt;li&gt;Get a simple motor control system on the auxiliary MCU working&lt;/li&gt;
&lt;li&gt;Start developing obstacle avoidance functionality&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;As of this post, the first two tasks are complete and the 3rd is underway. I’m doing the Pi-side software in Python, and the auxiliary MCU (used primarily for motor control) in C, and I’ll probably use a TI Hercules LaunchPad, since I’ve got one sitting around.&lt;/p&gt;
&lt;p&gt;What follows are my notes on getting the Pi up and running. I haven’t used one of these for about 2 years, so I was rusty. Hopefully these notes and linked resources will be helpful to others looking to get OpenCV going on their devices.&lt;/p&gt;
&lt;h2&gt;Pi Bringup&lt;/h2&gt;
&lt;p&gt;First, the Pi needs to get started up and we need to verify that we can SSH into it. I’m going to assume that you can boot into Raspbian reliably.&lt;/p&gt;
&lt;p&gt;While trying to set up my WiFi connection, I realized that my keyboard layout was not correct. I didn’t have the tilde and pipe characters, for example, and they’re pretty important for CLI’ing around the device.&lt;/p&gt;
&lt;p&gt;Keyboard Layout: To fix it, you need to modify the keyboard layout. This link had the right instructions for me: &lt;a href=&quot;https://www.raspberrypi.org/forums/viewtopic.php?f=26&amp;#x26;t=39806&amp;#x26;p=331516#p331516&quot;&gt;https://www.raspberrypi.org/forums/viewtopic.php?f=26&amp;#x26;t=39806&amp;#x26;p=331516#p331516&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In short, run the following commands:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;cd /etc/default

sudo nano keyboard
In nano, edit the config file to show the following:

XKBMODEL =“ pc105”

XKBLAYOUT =“ US”

To save and exit,

ctrl + x
ctrl + y&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To shut down, run: &lt;code class=&quot;language-text&quot;&gt;sudo shutdown -r now&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Scroll CLI:&lt;/strong&gt; To scroll in your CLI, you can run commands and pipe the output to the “less” utility, using the following syntax: &lt;code class=&quot;language-text&quot;&gt;command | less&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;WiFi:&lt;/strong&gt; I followed this tutorial to get WiFi going. I had to use the tip above to see all the details: &lt;a href=&quot;https://www.raspberrypi.org/documentation/configuration/wireless/wireless-cli.md&quot;&gt;https://www.raspberrypi.org/documentation/configuration/wireless/wireless-cli.md&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SSH:&lt;/strong&gt; Finally, you can set up SSH access by following these instructions: &lt;a href=&quot;https://www.raspberrypi.org/documentation/remote-access/ssh/&quot;&gt;https://www.raspberrypi.org/documentation/remote-access/ssh/&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;OpenCV Install&lt;/h2&gt;
&lt;p&gt;Now that the Pi is ready to go, we can install OpenCV and all of the relevant utilities for developing with it. The de facto standard OpenCV tutorials are by Adrian over at pyimagesearch.com,  and I followed his instructions for getting OpenCV going. Total install and compile time was about 4 hours. The tutorial is here: &lt;a href=&quot;http://www.pyimagesearch.com/2016/04/18/install-guide-raspberry-pi-3-raspbian-jessie-opencv-3/&quot;&gt;http://www.pyimagesearch.com/2016/04/18/install-guide-raspberry-pi-3-raspbian-jessie-opencv-3/&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Testing OpenCV&lt;/h2&gt;
&lt;p&gt;To try out OpenCV, I first wrote up the class to access the Pi Camera. The instructions are here: &lt;a href=&quot;http://www.pyimagesearch.com/2015/03/30/accessing-the-raspberry-pi-camera-with-opencv-and-python/&quot;&gt;http://www.pyimagesearch.com/2015/03/30/accessing-the-raspberry-pi-camera-with-opencv-and-python/&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Object Tracking&lt;/h2&gt;
&lt;p&gt;As a simple intro, I again followed one of Adrian’s tutorials. This time, it was for ball tracking, which is based on colour. &lt;a href=&quot;http://www.pyimagesearch.com/2015/09/14/ball-tracking-with-opencv/&quot;&gt;http://www.pyimagesearch.com/2015/09/14/ball-tracking-with-opencv/&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Project Development&lt;/h2&gt;
&lt;p&gt;With those experiments and introductions complete, I started on the tasks for my project. First, I integrated the Pi camera access code with the object tracking. Next, I cleaned up a lot of the code. Some of the pyimagesearch tutorials do things which I view as unnecessary, such as resizing the image before processing. I chose to bring in images from the Pi at 640x480, and found that the code ran faster when processing that initial size, and slower when I scaled the images down to a width of 600px. Also, I removed all of the image overlays except for the centroid location and the bounding box, since those are the only parts that are necessary for my project.&lt;/p&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/1ec9b8bb3ad9a2d90a5ddca469d6d9d6/4c221/raspi-opencv-1-2.jpg&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 700px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 54.42857142857142%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIFA//EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHN5SxRJgv/xAAaEAACAgMAAAAAAAAAAAAAAAAAAgESBBAT/9oACAEBAAEFAk6OPdCcpi7wWadf/8QAFREBAQAAAAAAAAAAAAAAAAAAABH/2gAIAQMBAT8BiP/EABYRAQEBAAAAAAAAAAAAAAAAAAABEf/aAAgBAgEBPwGNf//EABwQAAEEAwEAAAAAAAAAAAAAAAABAiFREBKRQf/aAAgBAQAGPwLaZo2qzzhDl6S5cf/EABsQAQACAgMAAAAAAAAAAAAAAAEAESFxEEFR/9oACAEBAAE/IWQhD0lto14YgnEqlDDohxE7eP/aAAwDAQACAAMAAAAQD9//xAAWEQADAAAAAAAAAAAAAAAAAAABECH/2gAIAQMBAT8QNJ//xAAWEQADAAAAAAAAAAAAAAAAAAABECH/2gAIAQIBAT8QKJ//xAAbEAEBAQACAwAAAAAAAAAAAAABEQAhgTFRYf/aAAgBAQABPxCsuBBB7+GTrgK1V470IOgyUToIAMOgXyKmu//Z&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Screenshot of openCV detecting an object&quot;
        title=&quot;&quot;
        src=&quot;/static/1ec9b8bb3ad9a2d90a5ddca469d6d9d6/4c221/raspi-opencv-1-2.jpg&quot;
        srcset=&quot;/static/1ec9b8bb3ad9a2d90a5ddca469d6d9d6/610c7/raspi-opencv-1-2.jpg 293w,
/static/1ec9b8bb3ad9a2d90a5ddca469d6d9d6/a8060/raspi-opencv-1-2.jpg 585w,
/static/1ec9b8bb3ad9a2d90a5ddca469d6d9d6/4c221/raspi-opencv-1-2.jpg 700w&quot;
        sizes=&quot;(max-width: 700px) 100vw, 700px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Object centroid detected&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Next, I examined the example ball tracking code and looked at how the centroids were calculated. It’s pretty simple, and the units are in pixels. It’ll be really straightforward to send these values out to the auxiliary MCU, and I’ll probably only need to use a P controller to have the robot follow an object of the correct colour. Pretty neat! So far, thanks to the great documentation available for the Pi and for OpenCV, and the ease of use of Python, it has been very straightforward to get this project rolling. I can’t wait to dig more into the processing capabilities of OpenCV more and keep experimenting.&lt;/p&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/42e51baab06b30034fdad640413ae272/17e8f/raspi-opencv-1-3.jpg&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1024px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 54.39453125%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIFA//EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHN5SxRJgv/xAAbEAACAgMBAAAAAAAAAAAAAAAAAgESAwQTEP/aAAgBAQABBQJOrj9MZO0xdoLNPn//xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAwEBPwGI/8QAFhEBAQEAAAAAAAAAAAAAAAAAAAER/9oACAECAQE/AY1//8QAHRAAAgIBBQAAAAAAAAAAAAAAAAEhUZECEBIyQf/aAAgBAQAGPwJapmjlVo8wdnklvb//xAAcEAEAAgIDAQAAAAAAAAAAAAABABEhcRAxQYH/2gAIAQEAAT8hYII+UyKNaEC4lSoEPCHsLbx//9oADAMBAAIAAwAAABCM3//EABcRAQADAAAAAAAAAAAAAAAAAAABESH/2gAIAQMBAT8QnSj/xAAWEQADAAAAAAAAAAAAAAAAAAABECH/2gAIAQIBAT8QKJ//xAAbEAEBAQACAwAAAAAAAAAAAAABEQAhYTFRgf/aAAgBAQABPxBCWUjge+jNGCFaK8fdECOhkg4QQAYxB3yKmu//2Q==&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Test subjects&quot;
        title=&quot;&quot;
        src=&quot;/static/42e51baab06b30034fdad640413ae272/17e8f/raspi-opencv-1-3.jpg&quot;
        srcset=&quot;/static/42e51baab06b30034fdad640413ae272/2fb5f/raspi-opencv-1-3.jpg 293w,
/static/42e51baab06b30034fdad640413ae272/06d94/raspi-opencv-1-3.jpg 585w,
/static/42e51baab06b30034fdad640413ae272/17e8f/raspi-opencv-1-3.jpg 1024w&quot;
        sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Test subjects: squishy promotional things from industry events.&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Useful Raspberry Pi Commands&lt;/h2&gt;
&lt;p&gt;Here’s a list of commands that I use frequently when interfacing with the Pi:&lt;/p&gt;
&lt;p&gt;Start desktop from CLI: &lt;code class=&quot;language-text&quot;&gt;startx&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Leave Python virtual environment: &lt;code class=&quot;language-text&quot;&gt;deactivate&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Enter Python virtual environment: &lt;code class=&quot;language-text&quot;&gt;workon &amp;lt;name of environment&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;SSH into Pi with X window forwarding: &lt;code class=&quot;language-text&quot;&gt;ssh -X &amp;lt;IP address of Rpi&amp;gt; -l &amp;lt;username on Rpi&amp;gt;&lt;/code&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Multiple Application Trapezoidal Rule in MATLAB]]></title><description><![CDATA[I recently had to implement multi-application trapezoidal rule for some work I was doing. I decided to implement the algorithm in MATLAB…]]></description><link>https://gatsby-casper.netlify.com/2017/03/21/multiple-application-trapezoidal-rule-in-matlab/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/2017/03/21/multiple-application-trapezoidal-rule-in-matlab/</guid><pubDate>Tue, 21 Mar 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I recently had to implement multi-application trapezoidal rule for some work I was doing. I decided to implement the algorithm in MATLAB, and figured I’d post a tutorial for it, since I know many people struggle with implementing algorithms in code.&lt;/p&gt;
&lt;p&gt;This implementation takes advantage of MATLAB’s built in functions, and as such, requires no loop. This technique is referred to as ‘vectorization’ and in many cases, can speed up your code significantly, as it lets MATLAB take advantage of its built in matrix features, which rely on LAPACK and LINPACK - matrix math libraries that have been hand-optimized for various processor architectures. Pretty cool!&lt;/p&gt;
&lt;p&gt;We’ll build this up in a script so it’s easy to see all of the variables. I often play around with scripts as I’m developing in MATLAB, and encapsulate the code in a function later.&lt;/p&gt;
&lt;h2&gt;Step 1: Define Function&lt;/h2&gt;
&lt;p&gt;Trapezoidal rule is a method of numerical integration. It’s not a great one, but it is easy to understand. I’ll assume the reader already has an understanding of how to do it.&lt;/p&gt;
&lt;p&gt;Let’s use an &lt;a href=&quot;https://www.mathworks.com/help/matlab/matlab_prog/anonymous-functions.html&quot;&gt;anonymous function&lt;/a&gt; to contain the specific function we’d like to integrate. This lets us use standard math notation F(x) to fun the function in our code.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;F = @(x) x^3 + 2*x +5;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Step 2: Setup Integration Variables&lt;/h2&gt;
&lt;p&gt;Now we need some variables to contain the start and end points of the integral, and the number of sections we’d like to use in our trap rule.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;start = 0;
endpt = 5;
n = 3;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We’ll also generate the points to evaluate the function at using the &lt;code class=&quot;language-text&quot;&gt;linspace&lt;/code&gt; function, which generates a set of n evenly spaced points between start and endpt.&lt;/p&gt;
&lt;p&gt;Also, we’ll generate &lt;code class=&quot;language-text&quot;&gt;h&lt;/code&gt;, our step width using the points we just calculated.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;points = linspace(start, endpt, n+1);
h = abs(points(2) - points(1));&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Step 3: Implement Algorithm&lt;/h2&gt;
&lt;p&gt;The algorithm for multi application trapezoidal rule is the following:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/matlab-trap-2-30b0f301cb418b5a0d014583823c3e18.gif&quot; alt=&quot;Multiple application trapezoidal rule&quot;&gt;
&lt;em&gt;Multiple application trapezoidal rule&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We can implement this in MATLAB, using the &lt;a href=&quot;https://www.mathworks.com/help/matlab/ref/sum.html&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;sum()&lt;/code&gt;&lt;/a&gt; function as well as the &lt;a href=&quot;https://www.mathworks.com/help/matlab/ref/arrayfun.html&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;arrayfun()&lt;/code&gt;&lt;/a&gt; function, which will apply each element of the points array to our anonymous function &lt;code class=&quot;language-text&quot;&gt;F&lt;/code&gt;. One important note is that the algorithm above has the points zero-indexed. MATLAB arrays use 1-indexing, so we need to add 1 to each subscript of &lt;code class=&quot;language-text&quot;&gt;x&lt;/code&gt; in the image above.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;int = (h/2) * (F(points(1)) + 2*sum(arrayfun(F, points(2:n))) + F(points(n+1)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Step 4: Vectorize&lt;/h2&gt;
&lt;p&gt;Right now, we have &lt;code class=&quot;language-text&quot;&gt;arrayfun()&lt;/code&gt;, which is (likely) one step better than using a loop. Even better would be using full vectorization. To do this, we need to reformat the f function to take vectors. So, we’ll use the much-misunderstood dot operator &lt;code class=&quot;language-text&quot;&gt;.&lt;/code&gt; ahead of our caret &lt;code class=&quot;language-text&quot;&gt;^&lt;/code&gt; to make the power element-wise. This means the power will be applied to each element of the input vector, which is what we want. It’s not needed in this application, but using the . before multiplication will result in a more robust function as well, so let’s do it to demonstrate.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;f = @(x) x.^3 + 2*x +5;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The trap expression will now look like this:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;int = (h/2) * (f(points(1)) + 2*sum(f(points(2:n))) + f(points(n+1)));&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Plotting&lt;/h2&gt;
&lt;p&gt;Let’s plot the original function at a higher resolution, and plot the trap points we evaluated. I’ll take advantage of linspace again, to plot our “base” function with 30 times more points than n. For small values of &lt;code class=&quot;language-text&quot;&gt;n&lt;/code&gt;, this will clearly show the points we use in trap rule. For higher n values, it’ll all smush together.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;% plot a high resolution curve of the function and superimpose the trap
% points
plot(linspace(start,endpt,n*30),f(linspace(start,endpt,n*30)))
hold on
plot(points, f(points))
title(sprintf(&amp;#39;Trap Rule n = %i&amp;#39;, n))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Notice that I used &lt;a href=&quot;https://www.mathworks.com/help/matlab/ref/sprintf.html&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;sprintf&lt;/code&gt;&lt;/a&gt; to display &lt;code class=&quot;language-text&quot;&gt;n&lt;/code&gt; in the title of the plot. Sprintf is used for formatting data into strings, which is what the &lt;code class=&quot;language-text&quot;&gt;title()&lt;/code&gt; function takes.&lt;/p&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/51b119f8702c088968b5290a8e434baa/4c221/matlab-trap-1.jpg&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 700px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 67.57142857142857%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAG+AD//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAE/IV//2gAMAwEAAgADAAAAEPPP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGBAAAwEBAAAAAAAAAAAAAAAAAAEhEGH/2gAIAQEAAT8QREIvN//Z&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Plot of our test function&quot;
        title=&quot;&quot;
        src=&quot;/static/51b119f8702c088968b5290a8e434baa/4c221/matlab-trap-1.jpg&quot;
        srcset=&quot;/static/51b119f8702c088968b5290a8e434baa/610c7/matlab-trap-1.jpg 293w,
/static/51b119f8702c088968b5290a8e434baa/a8060/matlab-trap-1.jpg 585w,
/static/51b119f8702c088968b5290a8e434baa/4c221/matlab-trap-1.jpg 700w&quot;
        sizes=&quot;(max-width: 700px) 100vw, 700px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Plot of our test function&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;The Entire Thing&lt;/h2&gt;
&lt;p&gt;Here’s the entire script.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;%% Multi application trap rule
% Richard Arthurs, March 20, 2017
% Richarthurs.com

f = @(x) x.^3 + 2*x +5; % Function to integrate

start = 0;
endpt = 5;
n = 3; % number of sections of trap rule
points = linspace(start, endpt, n+1);
h = abs(points(2) - points(1));

int = (h/2) * (f(points(1)) + 2*sum(f(points(2:n))) + f(points(n+1))) % the integral approximation

% plot a high resolution curve of the function and superimpose the trap points
plot(linspace(start,endpt,n*30),f(linspace(start,endpt,n*30)))
hold on
plot(points, f(points))
title(sprintf(&amp;#39;Trap Rule n = %i&amp;#39;, n))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Running HALCoGen on Mac or Linux With WINE]]></title><description><![CDATA[This tutorial covers installing and running HALCoGen for TI Hercules/TMS570 MCUs on a mac or Linux machine using WINE. I first started using…]]></description><link>https://gatsby-casper.netlify.com/2017/02/01/running-halcogen-on-mac-or-linux-with-wine/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/2017/02/01/running-halcogen-on-mac-or-linux-with-wine/</guid><pubDate>Wed, 01 Feb 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;This tutorial covers installing and running HALCoGen for TI Hercules/TMS570 MCUs on a mac or Linux machine using WINE. I first started using HALCoGen for the &lt;a href=&quot;sfusat.org&quot;&gt;SFU Satellite Design Team&lt;/a&gt;, where we’re developing an onboard computer using the TI Hercules/TMS570 microcontrollers. These are really interesting industrial lockstep MCUs, with ECC memory and all kinds of neat reliability features.&lt;/p&gt;
&lt;p&gt;WINE is a layer that translates Windows API calls to POSIX calls, which are used on macOS, Linux, etc. It’s free, and quite easy to set up.&lt;/p&gt;
&lt;h2&gt;Step 1: Get HALCoGen&lt;/h2&gt;
&lt;p&gt;Download HALCoGen from the TI site &lt;a href=&quot;http://www.ti.com/tool/HALCOGEN&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Step 2: Get WINE&lt;/h2&gt;
&lt;p&gt;Download WINE for your system, and any dependencies you may require. I downloaded the “staging” binary package of WINE from &lt;a href=&quot;https://wiki.winehq.org/Download&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I also needed XQuartz, and be sure to download from the XQuartz.org site &lt;a href=&quot;https://www.xquartz.org&quot;&gt;here&lt;/a&gt;, not something like “xquartz.soft32.com,” which came up in the Google search but tries to install a bunch of crapware, and probably malware too.&lt;/p&gt;
&lt;h2&gt;Step 3: Install WINE&lt;/h2&gt;
&lt;p&gt;Open up and install the WINE package.&lt;/p&gt;
&lt;h2&gt;Step 4: Install HALCoGEN With WINE&lt;/h2&gt;
&lt;p&gt;Unzip the HALCoGen installer. Something along the lines of “HALCoGen-04.06.00-installer.exe” should appear.&lt;/p&gt;
&lt;p&gt;Launch the WINE application, it will bring up a terminal. Now you need to &lt;code class=&quot;language-text&quot;&gt;cd&lt;/code&gt; to the directory that has the HALCoGen installer you downloaded in step 1.&lt;/p&gt;
&lt;p&gt;For me, this looked like: &lt;code class=&quot;language-text&quot;&gt;cd Desktop&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Now, run WINE on the installer by typing &lt;code class=&quot;language-text&quot;&gt;wine HALCoGen-04.06.00-installer.exe&lt;/code&gt; (but replace with the full name of your particular HALCoGen installer). Note: the WINE terminal will autocomplete with the tab key.&lt;/p&gt;
&lt;p&gt;WINE may ask you to automatically install a few things. It installed .NET and Gecko after detecting that they weren’t on my system.&lt;/p&gt;
&lt;h3&gt;Important: select your installation directory&lt;/h3&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/af26e09b6c9d954e72415f58110405b9/e0b92/halcogen-2.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 700px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 69.57142857142857%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsSAAALEgHS3X78AAADc0lEQVQ4y2WSW2gcZRiG59ILQVB7URR70YogFCqiYrAVbdSLEmJjsVZTEimWikGpbSKlTWqa2gZTag6NpUmxoqlaakzcmhoiiTnuObvZQ3Z3ZnZ39pDd2UNCjLTghfbx281FLQ68vN///zPv//AySsN7J2hs+JSWox00N33BqRPdtDR3c7btSzpae+hqlflkD58cPcvxli5OnfuW06f7aG3p5ePDn9N4+DwfHWzjeGM71767gbJ5QwWjI2O43D7mZp3MTluZnbFhtzmZmZzFJrN1ziFnNqblzO70kjCSdF64ypbH97Bt8xs8/OBOHtlYicvuRXl6aw0Oh4t8PodpZsnlzLJns1nS6TQ52S8U8qysLFPIr3vpsYzN8cRTe9n5zDtUbz9C1atN7Kv+EOWVlxsk2Y2qqYTDETRNQ1VVEokEhmGQTCbXXdapVEouzHP71hoDP/zKA49WsenJfWzbWk/lC++zq2I/Ss3rTditDgkwyGQyZZVCTCE0TZNicZm1tT/5Y3WVYqFYXt/5+y/6B35Duf9NHtp0gPs2vMXGx2rZVXkM5dmXjjAjPRnxOLquC2UYXSg1odRkbUTC5IwIGbmgRJ1OL5EzM0xZvXT23qC//xf6Lg3T032dcx0DKNsPDmGVovPS28rKivRVKKs0l2hTQlso91jg1q3b5f7+ucP/n2WT9Ad1KBUn7dg8QVQh8fmDhKTHQHBRaKMExT0eN7FohJgeJhGLkE5oZddVeUcNkTR00imDeCSI96YFZUfbvASEMZMxMsm4KEYunaCYTbNaNPG6rNjmfsfjmmV8YpLvfxplQn4nLRJADQdIxDUiix6ZF4gbGsprfRrtQ256b87TaXHS9bOLLouLziEXZwasXB2eQAt5CAc9BPwLuOa9hEJBMqmY0OqkhDCq+tEjPvSwH6XqxywvXtGpuLzI86LnLvnX1RtgS7OTY19NkTUWy0QxLYChi0uAJkRa2FeWLmdRNSAugbtHstRYTHYPm1QPZqm6vkTVoOhamh19OmcG7SxFAxLoL3+wrvWAu/ITlf3SrNR6MrztNtlvzVM3WaR2vMDe0Tx7RnJUfpOkfdBBSvNJR/8NvBt8r4TwUIeFQxfGOHBxnLrL09RfsfJu3wz1F6eo+WyU81+PkowG7g0UEjW0gM/rIOhz419wsuifx+dx8C9W5XsmCve2NAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Selecting installation directory&quot;
        title=&quot;&quot;
        src=&quot;/static/af26e09b6c9d954e72415f58110405b9/e0b92/halcogen-2.png&quot;
        srcset=&quot;/static/af26e09b6c9d954e72415f58110405b9/ded24/halcogen-2.png 293w,
/static/af26e09b6c9d954e72415f58110405b9/099d6/halcogen-2.png 585w,
/static/af26e09b6c9d954e72415f58110405b9/e0b92/halcogen-2.png 700w&quot;
        sizes=&quot;(max-width: 700px) 100vw, 700px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Selecting installation directory&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In the installer, be sure to select your installation directory correctly by clicking the folder icon. Since things are being translated, the old windows-style defaults location won’t work.&lt;/p&gt;
&lt;p&gt;Keep moving through the installer, clicking “yes” to any dependencies WINE wants to install, and the process should go smoothly!&lt;/p&gt;
&lt;h2&gt;Step 5: Run HALCoGen&lt;/h2&gt;
&lt;p&gt;Now that your installation has succeeded, it’s time to exit the installer and launch WINE again. When it comes up, &lt;code class=&quot;language-text&quot;&gt;cd&lt;/code&gt; to the directory with your HALCoGen.exe file in it.&lt;/p&gt;
&lt;p&gt;For me, I had to go back out of my desktop and into my ti directory, so this looked like: &lt;code class=&quot;language-text&quot;&gt;cd ../ti&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You can use &lt;code class=&quot;language-text&quot;&gt;ls&lt;/code&gt; to list the files in the directory to see if the HALCoGen executable is there. If it is, you’re in the right place.&lt;/p&gt;
&lt;p&gt;Now type: &lt;code class=&quot;language-text&quot;&gt;wine HALCOGEN.exe&lt;/code&gt; Note: it doesn’t need to be capitalized, and the tab key will autocomplete.&lt;/p&gt;
&lt;h2&gt;Step 6: You’re done!&lt;/h2&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/cda9e672fb53e780203805dace344506/e0b92/halcogen-3.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 700px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 55.85714285714286%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAACk0lEQVQoz21R30tTYRg+f0IUEd0oaoGRQj/0IpAVWCIpYkh1YzkcJG5nc7iNaU6XRWllN3ZhYQTlhZdlpSlUzmA3UmltoQ5LGeJ07sc5nu3s5zlP7zlDsej9eHje7z3f93zP+x6mXFOF5lYTWJuD0A3W3qPCqHCHEwa7Ey3tnbA9eALbwDCMjrsw9fTD5LgHU9cdOkdnLF1o1rdDc74WzIH8Y3jzaRZv3Ut47/JgasZL/AOTru+YmFnCuGsR76YXVJ747MO4UtsB1aa+BuD2Cfgwv4H84jNgDhaWoKaxDdrrTXDd6sDSfSc8fd342d+DBcpXHt3G8sNe/CL8HtgDqvv6HPDPzUECwHE8TmjqcoI6gxVmsxlejwfRcBiRrSAEnoMYE5BOJiBllSv/CVlClISUEAQBRacrwBwqKgFr0MNqteCb14fVYAyRbRHpTEZFVpIgK0uWIe2BTCLK91A0J7i9LaCgtJwcFhyH3sDCarFg3ruI1QCH9WAUCTEOkZAkh6oZWf4LSmT3CAqxGErP1ed+Cms0wmazwT07h5W1ILYiPKLkMsLHEBNTu45yYtgVzGSzCEV2BOM4WX0NzP68Yuh0OrCsAe4vHqyHRQQ5ESE+iVgig0QqA0lSZij/A3KYJYcRTs15avnIqbNgDheX4fnoa4y+moRneZ1mGIef5rgWiqsIcEls8GnitMqbfEblDWJ/KAH/Zk4wrrRcpQVztKwSZCT3otIGPZ6WclBzKqZpk6JETKSptSTiNIZUKkvzzWAzLECk+4FoCtX942D25ZVCU3MFFxoaUX1VhzqtGQ1sL5qcQ7jUYsfFG52odwzjctcQ9AMjuPlsDB0jH9H2YhrawTHUdr9EZftTVLQOorD5Mf4AWAm/zkBKouEAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;HALCoGEN on Mac&quot;
        title=&quot;&quot;
        src=&quot;/static/cda9e672fb53e780203805dace344506/e0b92/halcogen-3.png&quot;
        srcset=&quot;/static/cda9e672fb53e780203805dace344506/ded24/halcogen-3.png 293w,
/static/cda9e672fb53e780203805dace344506/099d6/halcogen-3.png 585w,
/static/cda9e672fb53e780203805dace344506/e0b92/halcogen-3.png 700w&quot;
        sizes=&quot;(max-width: 700px) 100vw, 700px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;HALCoGEN on Mac&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Hopefully HALCoGen has popped up and is working! If it does, you’re good to go! I have confirmed that HALCoGen can correctly generate code from an existing project file, so it seems to work quite well under WINE. To launch HALCoGen in the future, just open up WINE, &lt;code class=&quot;language-text&quot;&gt;cd&lt;/code&gt; to the directory with &lt;code class=&quot;language-text&quot;&gt;HALCOGEN.exe&lt;/code&gt;, and type &lt;code class=&quot;language-text&quot;&gt;wine HALCOGEN.exe&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now consider installing Code Composer Studio for &lt;a href=&quot;http://processors.wiki.ti.com/index.php/Download_CCS&quot;&gt;mac or Linux&lt;/a&gt; to get a full TMS570/Hercules toolchain going on your system of choice.&lt;/p&gt;
&lt;h2&gt;Step 7: Other Apps&lt;/h2&gt;
&lt;p&gt;I’ve successfully used this procedure with other TI installers for packages such as the flash driver and the safety library.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[WiFI Smart Lock]]></title><description><![CDATA[For a class project, my team and I were lucky enough to be able to build a smart lock. The prototypes were constructed of 3D printed parts…]]></description><link>https://gatsby-casper.netlify.com/2015/09/16/smartlock/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/2015/09/16/smartlock/</guid><pubDate>Wed, 16 Sep 2015 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;For a class project, my team and I were lucky enough to be able to build a smart lock. The prototypes were constructed of 3D printed parts for the mechanicals, and all of the electronics and software were designed by me.&lt;/p&gt;
&lt;h2&gt;Video&lt;/h2&gt;
&lt;p&gt;I made a video of the project &lt;a href=&quot;https://www.youtube.com/embed/2Xc9gXyf2G4&quot;&gt;here&lt;/a&gt;, which goes into detail about a lot of the design decisions.&lt;/p&gt;
&lt;h2&gt;Electrical Hardware&lt;/h2&gt;
&lt;p&gt;MCU: ATmega 328&lt;/p&gt;
&lt;p&gt;WiFi: ESP8266 module&lt;/p&gt;
&lt;p&gt;Motor driver: L298&lt;/p&gt;
&lt;p&gt;A custom designed optical encoder to determine whether the door was locked or unlocked.&lt;/p&gt;
&lt;p&gt;The motor driver chip was chosen because of my familiarity with it, as well as the fact that I had multiple on hand. Throughout the entire electronics design process, components we already owned were picked to keep the project under budget.&lt;/p&gt;
&lt;p&gt;Control of the system was handled by the ‘328, which communicated with the WiFi module over serial, and took inputs from the pushbutton and optical encoder. Feedback was provided to the user through an LED, a beeper, and through the web interface itself. Power came from a wall adaptor, as none of the components for the prototype were optimized for low power operation. In the future, the firmware should put the WiFi module to sleep, which would result in considerable power savings. And given that the ESP8266 has an internal ARM microcontroller, we could do all of the control from the module, negating the need for the ATmega 328.&lt;/p&gt;
&lt;h2&gt;Software&lt;/h2&gt;
&lt;p&gt;The lock was controlled by a web interface. When buttons on the interface were pressed, the lock would open or close depending on its current state. The state of the lock was checked before every movement and always kept up to date in a  MySQL database that the interface had access to. The backend was written in PHP, and database entries were also updated when the physical button on the lock was pressed. States were saved with a timestamp so users could see when the lock was last actuated. Live user feedback was mostly implemented, using AJAX.&lt;/p&gt;
&lt;h2&gt;Mechanicals&lt;/h2&gt;
&lt;p&gt;All of the mechanical components for the lock were designed in SolidWorks and 3D printed. Two prototypes were created, and parts were carried over between prototypes to keep the project under budget. Here are the main components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Coupler between motor and lock lever&lt;/li&gt;
&lt;li&gt;Optical encoder wheel&lt;/li&gt;
&lt;li&gt;Encoder mount&lt;/li&gt;
&lt;li&gt;Main case with integrated PCB and motor mounts&lt;/li&gt;
&lt;li&gt;Pushbutton extender (prototype #2 only)&lt;/li&gt;
&lt;li&gt;Case lid/front panel (prototype #2 only)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/f1e7f572cee27122ea250939dfde1493/03eee/smartlock-2.jpg&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1170px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 66.650390625%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAMF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAL/2gAMAwEAAhADEAAAAVq5ZsLqn//EABsQAAMAAgMAAAAAAAAAAAAAAAACAwQTFDEy/9oACAEBAAEFAks6kck5kRel96Zn/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAERMf/aAAgBAwEBPwFYyn//xAAWEQEBAQAAAAAAAAAAAAAAAAABACH/2gAIAQIBAT8BTSy//8QAHhAAAQMEAwAAAAAAAAAAAAAAAAEREhAhIjJBUZH/2gAIAQEABj8CaFjKSnPlI9qxqh//xAAcEAACAgIDAAAAAAAAAAAAAAAAAREhMUFRYeH/2gAIAQEAAT8hWvbzJGnidHM1EE9GjSsbH4R//9oADAMBAAIAAwAAABDPH//EABcRAAMBAAAAAAAAAAAAAAAAAAARUQH/2gAIAQMBAT8Q2qDQ/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAERUf/aAAgBAgEBPxBTCaP/xAAdEAEBAAICAwEAAAAAAAAAAAABEQAxIVFBYZHB/9oACAEBAAE/ECRSHYcT9x40cQF3h5k6XmiNXIsoL9xb9xby2P/Z&apos;); background-size: cover; display: block;&quot;
    &gt;&lt;/span&gt;
    &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Prototype&quot;
        title=&quot;&quot;
        src=&quot;/static/f1e7f572cee27122ea250939dfde1493/27561/smartlock-2.jpg&quot;
        srcset=&quot;/static/f1e7f572cee27122ea250939dfde1493/06456/smartlock-2.jpg 293w,
/static/f1e7f572cee27122ea250939dfde1493/4b3e4/smartlock-2.jpg 585w,
/static/f1e7f572cee27122ea250939dfde1493/27561/smartlock-2.jpg 1170w,
/static/f1e7f572cee27122ea250939dfde1493/278c2/smartlock-2.jpg 1755w,
/static/f1e7f572cee27122ea250939dfde1493/03eee/smartlock-2.jpg 2048w&quot;
        sizes=&quot;(max-width: 1170px) 100vw, 1170px&quot;
      /&gt;
  &lt;/span&gt;
  &lt;/a&gt;
&lt;em&gt;Smart Lock Prototype&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I designed everything but the main case for prototype #2, though I did modify it with my own motor and PCB mounting bosses. The entirety of the lock was assembled in CAD to check fit before printing, and 3D printing constraints were considered throughout the entire process. By creating two prototypes, we were able to nail the tolerances for the final prototype, enabling us to create very reliable friction fits for some parts, reducing BOM cost.&lt;/p&gt;
&lt;h2&gt;Verdict&lt;/h2&gt;
&lt;p&gt;This was a very rewarding project to complete. I got the opportunity to utilize many sub-modules that I’d had experience with from previous projects (motor driver, power supply, etc), but also the chance to use new modules, like the ESP8266 WiFi board. Programming the web interface was an interesting challenge as I’d never communicated with a MySQL database through PHP before, or set up databases and handled GET requests.&lt;/p&gt;
&lt;p&gt;In the future, it’d be fun to revisit the project and take more time to design it for low power and make it physically smaller. There are many approaches to this - sleeping the WiFi module, getting rid of the external MCU, or communicating over Bluetooth to a WiFi base station. There was also a lot of empty space inside the prototype. While it looked impressive, the empty space was really just a waste. A case redesign, coupled with a custom PCB (instead of a protoboard one-off) would allow the device to be a lot smaller.&lt;/p&gt;
&lt;p&gt;The web interface could also do with a security overhaul. I’m no security expert, and it likely shows in the code for the backend, which is obviously not a particularly good thing for a lock connected to the internet. Luckily for the prototype, it can only be actuated by devices on its own local network, which provides a good amount of intrinsic security to the system.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[TI ARM LaunchPad GPIO Input Tutorial]]></title><description><![CDATA[The TI Tiva Launchpad boards are an excellent way to get started working with ARM microcontrollers. With the Tivaware software suite, they…]]></description><link>https://gatsby-casper.netlify.com/2015/05/25/ti-launchpad-gpio-input/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/2015/05/25/ti-launchpad-gpio-input/</guid><pubDate>Mon, 25 May 2015 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;The TI Tiva Launchpad boards are an excellent way to get started working with ARM microcontrollers. With the Tivaware software suite, they’re not too much harder than an Arduino to program, either. I’ve found the tutorials from TI and elsewhere online to be very helpful. Unfortunately, the TI tutorials go over GPIO outputs, which are pretty simple, but they totally skip inputs! For someone totally unsure where to look for the correct documentation, I feel this is a major oversight. Fortunately, I’ve been able to figure it out with the help of some 3rd party tutorials. Here’s my take on how to use GPIO inputs, with references back to the TI material so you can get an idea of where to look for functionality in the main documentation.&lt;/p&gt;
&lt;p&gt;I’ll explain the setup and put the code at the end of this post, along with some links.&lt;/p&gt;
&lt;h2&gt;Setup&lt;/h2&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;stdbool.h&amp;gt;
#include &amp;quot;inc/hw_types.h&amp;quot;
#include &amp;quot;inc/hw_memmap.h&amp;quot;
#include &amp;quot;driverlib/sysctl.h&amp;quot;
#include &amp;quot;driverlib/gpio.h&amp;quot;
int main(void)
{
  SysCtlClockSet(SYSCTL_SYSDIV_4|SYSCTL_USE_PLL|SYSCTL_XTAL_16MHZ|SYSCTL_OSC_MAIN);	// set up the clock
  SysCtlPeripheralEnable(SYSCTL_PERIPH_GPIOF);	// enable port F
  GPIOPinTypeGPIOOutput(GPIO_PORTF_BASE, GPIO_PIN_1|GPIO_PIN_2|GPIO_PIN_3);	// enable outputs on the launchpad LED pins&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As usual, we need to include the appropriate headers for the board and set up the clock. We also need to enable port F. Then, we set up GPIO F1, F2 and F3 as outputs. This is where the LaunchPad’s red, green and blue LEDs are connected. Also note that some pins need to be unlocked with a code from the datasheet before you can use them. That’s because they’re normally used for one of the programming interfaces. There are examples of this in the Tiva tutorials from TI. Take a look at my tutorial on how to unlock GPIOs.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;GPIOPinTypeGPIOInput(GPIO_PORTF_BASE, GPIO_PIN_4);	// make F4 an input

GPIOPadConfigSet(GPIO_PORTF_BASE,GPIO_PIN_4,GPIO_STRENGTH_2MA,GPIO_PIN_TYPE_STD_WPU);	// enable F4&amp;#39;s pullup, the drive strength won&amp;#39;t affect the input&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here’s where we start getting to the input side of things. We need to enable port F4 as an input. Pretty simple, but it doesn’t end there. To make it work correctly, we’ll configure the pin to have an internal pullup resistor. WPU stands for ‘weak pullup resistor’ - you could change this to WPD for a pulldown. The details of this function can be found on page 264 here.&lt;/p&gt;
&lt;p&gt;By giving the pin an internal pullup, we know that when the button is pressed, the input will be grounded (from the LaunchPad datasheet). Otherwise, it’ll be pulled up to 3.3v. That’s the key to making inputs work, but let’s peek at the rest of the code.&lt;/p&gt;
&lt;h3&gt;Loop&lt;/h3&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;while(1)
  {
    uint32_t pinVal=0;	// variable to hold the pinRead
    pinVal= GPIOPinRead(GPIO_PORTF_BASE,GPIO_PIN_4);	// read F4&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Pretty standard microcontroller stuff, we’ve got a while(1) loop. This will run forever. Next, we create a 32-bit integer to take the value of GPIOPinRead. This function returns a 32 bit value, but we only need bits 1-8, which will be set if any of the pins on the port are high. GPIOPinRead takes the base port and the specific pin as arguments.&lt;/p&gt;
&lt;h3&gt;If&lt;/h3&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;if( (pinVal &amp;amp; GPIO_PIN_4)==0){	// AND to strip out anything but the value read from F4
      GPIOPinWrite(GPIO_PORTF_BASE,GPIO_PIN_1|GPIO_PIN_2|GPIO_PIN_3, 2);	// turn on one LED
    }
    
    else{
      GPIOPinWrite(GPIO_PORTF_BASE,GPIO_PIN_1|GPIO_PIN_2|GPIO_PIN_3, 4);	// turn on a different LED
    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next we have an if statement. It’s pretty easy to see what’s being done here. If the pin is high, we turn on GPIO F2 (that’s the else condition). Otherwise, our input is low (button pressed) and we’ll turn on pin F1.&lt;/p&gt;
&lt;p&gt;There’s a little bit going on in the if statement though. We’re taking the value from GPIOPinRead, which will have a 0 or a 1 in the position of any pins we read. We logical AND it with the GPIO&lt;em&gt;PIN&lt;/em&gt;4 variable, which will strip away anything except the value in Pin 4’s position. If pin 4 was high, we will get a result of 1. If pin 4 was low, we get a 0. This is because we AND the value on the input, in the input’s place, with a 1 in the input’s place.&lt;/p&gt;
&lt;h4&gt;What’s the delay for?&lt;/h4&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;//   SysCtlDelay(7000000); // uncomment me if you need debouncing

  }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There is an optional delay at the bottom of the code. This is for very simple debouncing of the button. Essentially, when you push a button, it doesn’t immediately connect one way or the other. It’ll actually bounce around between connected and disconnected. This is a physical phenomenon due to springiness. It’s very fast, but not too fast for a micro to keep up with. In some applications, like if you were making each button press increment a counter, you would likely see more than one increment of the counter for each button press, due to the button bouncing a little bit. If you’re just using a button to turn on an LED with no latching, button bounce isn’t something to worry about.&lt;/p&gt;
&lt;h3&gt;Button bounce&lt;/h3&gt;
&lt;p&gt;By waiting around for a few ms after reading the button, we physically give it time to settle into wherever it wants to be. Debouncing could be a whole series of blog posts, as you can deal with it in multiple ways through hardware or software. If you find you need it, busy wait delays are the most simple way to deal with it, though they’re definitely not the best.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/button-bounce-4a8d824615e0d25da0fe525be2899741.gif&quot; alt=&quot;bounce waveform&quot;&gt;
&lt;em&gt;Button bounce waveform&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;Complete code&lt;/h3&gt;
&lt;p&gt;Here’s the complete code for this tutorial. It’s all commented and should be easy to figure out. The project containing this code was actually the Lab 2 code from TI’s set of tutorials. The includes and build options are the same, you just need to put in a few lines to enable and work with the inputs.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;/* 
Tivaware input tutorial
*/

#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;stdbool.h&amp;gt;
#include &amp;quot;inc/hw_types.h&amp;quot;
#include &amp;quot;inc/hw_memmap.h&amp;quot;
#include &amp;quot;driverlib/sysctl.h&amp;quot;
#include &amp;quot;driverlib/gpio.h&amp;quot;
int main(void)
{
  SysCtlClockSet(SYSCTL_SYSDIV_4|SYSCTL_USE_PLL|SYSCTL_XTAL_16MHZ|SYSCTL_OSC_MAIN);	// set up the clock
  SysCtlPeripheralEnable(SYSCTL_PERIPH_GPIOF);	// enable port F
  GPIOPinTypeGPIOOutput(GPIO_PORTF_BASE, GPIO_PIN_1|GPIO_PIN_2|GPIO_PIN_3);	// enable outputs on the launchpad LED pins
  GPIOPinTypeGPIOInput(GPIO_PORTF_BASE, GPIO_PIN_4);	// make F4 an input

  GPIOPadConfigSet(GPIO_PORTF_BASE,GPIO_PIN_4,GPIO_STRENGTH_2MA,GPIO_PIN_TYPE_STD_WPU);	// enable F4&amp;#39;s pullup, the drive strength won&amp;#39;t affect the input
  while(1)
  {
    uint32_t pinVal=0;	// variable to hold the pinRead
    pinVal= GPIOPinRead(GPIO_PORTF_BASE,GPIO_PIN_4);	// read F4
    
    if( (pinVal &amp;amp; GPIO_PIN_4)==0){	// AND to strip out anything but the value read from F4
      GPIOPinWrite(GPIO_PORTF_BASE,GPIO_PIN_1|GPIO_PIN_2|GPIO_PIN_3, 2);	// turn on one LED
    }
    
    else{
      GPIOPinWrite(GPIO_PORTF_BASE,GPIO_PIN_1|GPIO_PIN_2|GPIO_PIN_3, 4);	// turn on a different LED
    }
        
    //   SysCtlDelay(7000000); // uncomment me if you need debouncing

  }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Resources&lt;/h3&gt;
&lt;p&gt;I’ll end off with some resources for learning about the ARM LaunchPad. There will definitely be more tutorials from me as well!&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://processors.wiki.ti.com/index.php/Tiva_C_Series_TM4C123G_LaunchPad&quot;&gt;TI LaunchPad resources&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.ti.com/lit/ug/spmu298a/spmu298a.pdf&quot;&gt;Tivaware Reference&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;%22http://processors.wiki.ti.com/index.php?title=Getting_Started_with_the_TIVA%E2%84%A2_C_Series_TM4C123G_LaunchPad&amp;#x26;DCMP=tivac&amp;#x26;HQS=TM4C123G-Launchpad-Workshop&quot;&gt;TI LaunchPad Workshop&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=qieNBhmWQbA&quot;&gt;AllaboutEE Input Tutorial (C++)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://sites.google.com/site/luiselectronicprojects/tutorials/tiva-tutorials/tiva-gpio/simple-digital-input&quot;&gt;Luis Electronic Projects Input Tutorial&lt;/a&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[TI ARM LaunchPad GPIO Output Tutorial]]></title><description><![CDATA[The GPIO functions in Tivaware take a little fiddling with to understand. For beginners, it may not be immediately obvious what’s going on…]]></description><link>https://gatsby-casper.netlify.com/2015/05/25/ti-launchpad-gpio-output/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/2015/05/25/ti-launchpad-gpio-output/</guid><pubDate>Mon, 25 May 2015 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;The GPIO functions in Tivaware take a little fiddling with to understand. For beginners, it may not be immediately obvious what’s going on in the output function, especially as there are multiple ways to do the same thing. Let’s take a look at an example of how to use the pins, and at the end we’ll set them up (that’s the boring part).&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;GPIOPinWrite(GPIO_PORTF_BASE,GPIO_PIN_1, GPIO_PIN_1);	// turn on one LED&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Tivaware includes the GPIOPinWrite function. As arguments, it takes the base port, the pin(s) and the value to write. So to write to PF1, we need to tell it that we’re in port F, we want pin 1, and then the value. The ‘value’ isn’t a 1 or a zero, however. It needs to be a 1 or a 0 in the position of the pin we want to control, that’s the key. GPIO&lt;em&gt;PIN&lt;/em&gt;1 is simply a variable equal to the position of pin 1 in registers, which is actually equal to 2 in decimal notation. You can see the number that these macros are referencing by hovering your mouse over them in Code Composer Studio. Pin 1 = 2, Pin 2 = 4, Pin 3 = 8, and so on.&lt;/p&gt;
&lt;p&gt;So we are telling the microcontroller to place a 1 in the 2’s place, which corresponds to pin 1 on port F. How confusing is that?! It’s not too bad, but it can take a little while to wrap your head around if you’re coming straight from Arduino. If you’ve dealt with 8-bit microcontroller programming, this won’t be too bad, since there are only 8 pins on a port here too.&lt;/p&gt;
&lt;h3&gt;Multiple pins at once&lt;/h3&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;GPIOPinWrite(GPIO_PORTF_BASE,GPIO_PIN_1|GPIO_PIN_2|GPIO_PIN_3, 4);	// turn on one LED&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To set multiple pins at the same time, we need to do two things. As before, we’re specifying that we’re on port F. First, we’ll OR the pins we need together. The pipe character ”|” means OR. So the micro is going to be able to work with any pins we specify here in a string of OR statements. In that case, it’s pins 1, 2, and 3. It’s not a big deal if we put a pin in here that we don’t end up setting.&lt;/p&gt;
&lt;p&gt;Next up, we set the value. Remember how each GPIO&lt;em&gt;PIN&lt;/em&gt;X is actually a number? Since we’ve placed a 4 here, that corresponds to pin F2. Since pin F2 was specified in our ORing earlier, F4 will go high. Instead of placing a 4, we could’ve also put GPIO&lt;em&gt;PIN&lt;/em&gt;2, like in the previous example, which is equal to 4.&lt;/p&gt;
&lt;p&gt;So how do we set multiple pins? First, they need to appear in your OR statement. Then, we set the port to equal the addresses of those pins, but added together. Since pin 1 = 2, pin 2 = 4, and pin 3 = 8, we could set the port to 6, 10, 12, or 14. These are all the combinations of adding 2, 4, and 8 to each other. This is how the GPIO bus works, there’s a unique number for any combination of pins being on. Tivaware handles this automatically, so we can just change the pins we want, and the others will keep their states. Awesome!&lt;/p&gt;
&lt;p&gt;This numbering system could get confusing since we won’t always remember which number corresponds to each pin. Luckily, we can use the OR statement again. In an application like this, OR is actually serving as addition. If we OR 00000010 with 00000100 (2 and 4 in binary), we get 00000110. See, from our two inputs, we’ve set any bit that input 1 OR input 2 have set. To do this with Tivaware, we can set the last argument of our function as GPIO&lt;em&gt;PIN&lt;/em&gt;2|GPIO&lt;em&gt;PIN&lt;/em&gt;3, for example. This will turn on pins 1 and 3. We could’ve even set it to 4|8, which is kind of weird, but is what the GPIO&lt;em&gt;PIN&lt;/em&gt;X variables represent. Here’s an example:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;GPIOPinWrite(GPIO_PORTF_BASE,GPIO_PIN_1|GPIO_PIN_2|GPIO_PIN_3, GPIO_PIN_2|GPIO_PIN_3);	// turn on two LEDs&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Turning pins off&lt;/h3&gt;
&lt;p&gt;To turn a pin off, simply put its address in the second argument of GPIOPinWrite and write a zero as the third argument. Actually, anything except the pin’s address will make turn it off. There is an example of this in the complete demo code at the end, where we turn off pin 1 only.&lt;/p&gt;
&lt;h3&gt;Setting up outputs&lt;/h3&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;SysCtlPeripheralEnable(SYSCTL_PERIPH_GPIOF);	// enable port F

GPIOPinTypeGPIOOutput(GPIO_PORTF_BASE, GPIO_PIN_1|GPIO_PIN_2|GPIO_PIN_3);	// enable outputs on the launchpad LED pins&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To set pins as outputs, we just need to enable the port and set some pins as outputs. Like we’ve gone through, we OR together the specific pins we’d like to mess with. There are also includes above this. They’re in the complete demo code below. This program will blink a few of the LEDs on the launchpad. It’s a good example of how to set single and multiple pins, and turn specific pins off.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;/*
GPIO Output Demo
*/

#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;stdbool.h&amp;gt;
#include &amp;quot;inc/hw_types.h&amp;quot;
#include &amp;quot;inc/hw_memmap.h&amp;quot;
#include &amp;quot;driverlib/sysctl.h&amp;quot;
#include &amp;quot;driverlib/gpio.h&amp;quot;
int main(void)
{
  SysCtlClockSet(SYSCTL_SYSDIV_4|SYSCTL_USE_PLL|SYSCTL_XTAL_16MHZ|SYSCTL_OSC_MAIN);	// set up the clock
  SysCtlPeripheralEnable(SYSCTL_PERIPH_GPIOF);	// enable port F
  GPIOPinTypeGPIOOutput(GPIO_PORTF_BASE, GPIO_PIN_1|GPIO_PIN_2|GPIO_PIN_3);	// enable outputs on the launchpad LED pins

  while(1)
  {

      GPIOPinWrite(GPIO_PORTF_BASE,GPIO_PIN_1, GPIO_PIN_1);	// turn on one LED
      SysCtlDelay(7000000); // wait a while
      GPIOPinWrite(GPIO_PORTF_BASE,GPIO_PIN_1|GPIO_PIN_2|GPIO_PIN_3, GPIO_PIN_1|GPIO_PIN_2);	// turn on two LEDs
      SysCtlDelay(7000000);
      GPIOPinWrite(GPIO_PORTF_BASE,GPIO_PIN_1, 0x00);	// turn pin 1 off
      SysCtlDelay(7000000);
  }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[TI ARM LaunchPad GPIO Unlock Tutorial]]></title><description><![CDATA[TI locks some GPIO pins because they’re required for programming interfaces like JTAG. SW2 on the LaunchPad is connected to PF0 ( page 33…]]></description><link>https://gatsby-casper.netlify.com/2015/05/25/ti-launchpad-gpio-unlock/</link><guid isPermaLink="false">https://gatsby-casper.netlify.com/2015/05/25/ti-launchpad-gpio-unlock/</guid><pubDate>Mon, 25 May 2015 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;TI locks some GPIO pins because they’re required for programming interfaces like JTAG. SW2 on the LaunchPad is connected to PF0 (&lt;a href=&quot;http://software-dl.ti.com/trainingTTO/trainingTTO_public_sw/GSW-TM4C123G-LaunchPad/TM4C123G_LaunchPad_Workshop_Workbook.pdf&quot;&gt;page 334&lt;/a&gt;), which is one of these locked up pins. We can’t use it as an input without unlocking it first. Here’s the code from my GPIO Input tutorial, but modified to use SW2. Let’s go over the changes from that tutorial’s code, then see the entire thing.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;Include hw_gpio.h

#include &amp;quot;inc/hw_gpio.h&amp;quot;	// We need to include this. It&amp;#39;s got the GPIO_LOCK_KEY macro, among others&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We need to include this header to get access to the appropriate macros to unlock pins. This wasn’t needed in the GPIO input tutorial, but it makes to include it in every project that’s going to need GPIO.&lt;/p&gt;
&lt;h3&gt;Unlock the pin&lt;/h3&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;HWREG(GPIO_PORTF_BASE + GPIO_O_LOCK) = GPIO_LOCK_KEY;	// unlock the GPIOCR register for port F
HWREG(GPIO_PORTF_BASE + GPIO_O_CR) = 0x01;		// Free up pin 0&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;GPIO&lt;em&gt;LOCK&lt;/em&gt;KEY is equal to 0x4C4F434B - this value can be found on page 684 of the TM4C123GH6PM datasheet, as well as details about what’s going on. Essentially, writing this value to the GPIO Lock register will unlock the GPIO Commit register, where we specify which pins we need opened up for tinkering with. So in the second line we’re opening up pin 0 (they’re 1-indexed here, which is why we’re writing a 1). Also, the key value won’t necessarily be the same between microcontrollers. Check the datasheet to be sure.&lt;/p&gt;
&lt;h3&gt;Ready to go!&lt;/h3&gt;
&lt;p&gt;That’s all you need to do to unlock GPIOs. Here’s the entire example code. It’s exactly the same as the GPIO input tutorial, but includes the code to unlock SW2 that we just went over.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;stdbool.h&amp;gt;
#include &amp;quot;inc/hw_gpio.h&amp;quot;	// We need to include this. It&amp;#39;s got the GPIO_LOCK_KEY macro, among others
#include &amp;quot;inc/hw_types.h&amp;quot;
#include &amp;quot;inc/hw_memmap.h&amp;quot;
#include &amp;quot;driverlib/sysctl.h&amp;quot;
#include &amp;quot;driverlib/gpio.h&amp;quot;
int main(void)
{
  SysCtlClockSet(SYSCTL_SYSDIV_4|SYSCTL_USE_PLL|SYSCTL_XTAL_16MHZ|SYSCTL_OSC_MAIN);	// set up the clock
  SysCtlPeripheralEnable(SYSCTL_PERIPH_GPIOF);	// enable port F

    HWREG(GPIO_PORTF_BASE + GPIO_O_LOCK) = GPIO_LOCK_KEY;	// unlock the GPIOCR register for port F
    HWREG(GPIO_PORTF_BASE + GPIO_O_CR) = 0x01;		// Free up pin 0

  GPIOPinTypeGPIOOutput(GPIO_PORTF_BASE, GPIO_PIN_1|GPIO_PIN_2|GPIO_PIN_3);	// enable outputs on the launchpad LED pins
  GPIOPinTypeGPIOInput(GPIO_PORTF_BASE, GPIO_PIN_0);	// make F4 an input

  GPIOPadConfigSet(GPIO_PORTF_BASE,GPIO_PIN_0,GPIO_STRENGTH_2MA,GPIO_PIN_TYPE_STD_WPU);	// enable F0&amp;#39;s pullup, the drive strength won&amp;#39;t affect the input
  while(1)
  {
    uint32_t pinVal=0;	// variable to hold the pinRead
    pinVal= GPIOPinRead(GPIO_PORTF_BASE,GPIO_PIN_0);	// read F0

    if( (pinVal &amp;amp; GPIO_PIN_0)==0){	// AND to strip out anything but the value read from F0
      GPIOPinWrite(GPIO_PORTF_BASE,GPIO_PIN_1|GPIO_PIN_2|GPIO_PIN_3, 2);	// turn on one LED
    }

    else{
      GPIOPinWrite(GPIO_PORTF_BASE,GPIO_PIN_1|GPIO_PIN_2|GPIO_PIN_3, 4);	// turn on a different LED
    }

    //   SysCtlDelay(7000000); // uncomment me if you need debouncing

  }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Other considerations&lt;/h3&gt;
&lt;p&gt;In the example I was using to figure this out, you’ll notice that they set the AFSL register. Below are lines 146-148 of the gpio&lt;em&gt;jtag example, which will be installed in the Tivaware C series examples folder for the launchpad board. If you followed all steps of TI’s installation tutorials, this project should exist somewhere for you. Here was the path for me: `C:TITivaWare&lt;/em&gt;C&lt;em&gt;Series-1.1examplesboardsek-tm4c123gxlgpio&lt;/em&gt;jtag`.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;HWREG(GPIO_PORTC_BASE + GPIO_O_LOCK) = GPIO_LOCK_KEY;
HWREG(GPIO_PORTC_BASE + GPIO_O_CR) = 0x01;
HWREG(GPIO_PORTC_BASE + GPIO_O_AFSEL) &amp;amp;= 0xfe;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is the GPIO alternate function select register. In the JTAG example, they need to set this since they’re switching the pins back and forth between GPIO and JTAG. Not something we needed to do in this tutorial, but it’s good to be aware of. Actually, I set this in the otherwise identical code for this tutorial, and GPIO wouldn’t work. Go figure. More info on this register can be found on page 671 of the TM4C123GH6PM datasheet, or you can take a look at the gpio_jtag example.&lt;/p&gt;
&lt;p&gt;There it is, a quick look on which registers to poke into when you need to unlock a GPIO using the Tivaware API. Thanks for reading!&lt;/p&gt;</content:encoded></item></channel></rss>
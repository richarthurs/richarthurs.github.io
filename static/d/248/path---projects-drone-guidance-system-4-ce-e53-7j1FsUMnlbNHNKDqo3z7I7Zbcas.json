{"data":{"logo":{"childImageSharp":{"fixed":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAC4jAAAuIwF4pT92AAAAf0lEQVQI12P49++f3v///xWBmBuIOYBYigEJQMXEobQ0kpg8EDMxoAOg4HQgzgbiBCB2AeJaIHYE4jAgjgbiFCD2BWI3IG6FymUCcQWUtoWqCwKpARkYBcReQJwF1egBZdcAXQ/ix0MtAmlMB4r5AGkHIA4BskGW5kMdZALESQDh3apPUyViLgAAAABJRU5ErkJggg==","width":400,"height":64,"src":"/static/1642a962a17c5982edb23d2f20e5a8e6/51380/logo.png","srcSet":"/static/1642a962a17c5982edb23d2f20e5a8e6/51380/logo.png 1x,\n/static/1642a962a17c5982edb23d2f20e5a8e6/240c8/logo.png 1.5x,\n/static/1642a962a17c5982edb23d2f20e5a8e6/f5cf3/logo.png 2x,\n/static/1642a962a17c5982edb23d2f20e5a8e6/01d7c/logo.png 3x"}}},"markdownRemark":{"html":"<p>For the past few years, I’ve been working on a guidance system for drones with <a href=\"teamguardian.ca\">SFU Team Guardian</a>. This system encompasses a simulator (APM SITL) or real drone support, path planning, mission creation, drone control, and a web-based ground control app. I started the project for the team to meet the requirements of the AUVSI competition, where a drone must complete objectives while avoiding stationary and moving objects. </p>\n<h2>Tech Stack</h2>\n<p>The guidance system is executed on a laptop computer in the field, and continuously sends velocity vectors and other commands over the telemetry radio connection. The drone itself is a multicopter, running stock APM firmware and sending back telemetry at roughly 10 Hz. Running the guidance system on a laptop provides flexibility of developing in a high-level language (Python) and facilitates much easier testing when the simulator is involved. For the task at hand (avoiding large obstacles), the communication latency and potential for dropped packets is not a significant concern. </p>\n<p>The DroneKit library provides an application layer that allows high-level commands to be sent to the drone via MAVProxy, and hides the details about the connection. During development, the APM SITL simulator is hooked up identically to a real drone by connecting to its provided telemetry stream. When we tune the real copter PID paramaters, we set them in the SITL drone as well, allowing the simulated drone to have similar flight characteristics to the real drone. This makes it easier to tune paramaters of the guidance system. </p>\n<h2>Control Loop</h2>\n<p>Control of drone movement is provided by the velocity vector commands exposed by DroneKit. You need to continuously feed velocity vectors to a drone running APM firmware otherwise it will quickly stop and hover. This turns out to be a <em>really</em> nice safety feature, and apparently wasn’t present in the earliest versions of APM. Yikes!</p>\n<p>The guidance system calculates a velocity vector at a user-settable frequency, usually 5-10 Hz. Velocities are specified in NED coordinates - North, East, Down, which makes navigation quite easy using standard equations for navigation on the Earth. To generate a velocity vector, the following things are considered:</p>\n<ul>\n<li>maximum velocity setting</li>\n<li>current and desired location, driven by the path planning algorithm and mission itself</li>\n<li>PID values from the navigation PID controller (internal to the guidance system, separate from the APM PID controllers)</li>\n<li>a few safety checks for altitude limits and overshoot detection</li>\n</ul>\n<p>Once the velocity vector is calculated, it is sent up to the drone. It turns out that packet loss is not a significant concern - most of the velocity commands make it up to the copter. The velocity vector needs to be recalculated continuously to account for dynamic effects such as wind, and so the drone won’t stop as mentioned before. </p>\n<h2>Mission Modules</h2>\n<p>Similar to how missions are planned on standard ground control apps like APM Planner, I introduced the concept of a mission module to the guidance system. Each mission module is a representation of a few things:</p>\n<ul>\n<li>a set of coordinates (multiple coordinates are used to define a search pattern, for example)</li>\n<li>a particular action to perform when the final coordinte is reached</li>\n<li>an altitude</li>\n</ul>\n<p>The simplest mission module is a waypoint - it contains a single set of coordinates, an altitude, and tells the drone to hover at the location for a few seconds. An example of an extension to the waypoint module is the drop location module, which sends a few servo commands to release something from the drone as it hovers over a particular location. There are also search pattern modules, where the corners of an area are defined by the user, as well as a swath width, allowing a set of coordinates to be generated in a lawnmower-style zigzag search. </p>\n<p>Initially, missions (a collection of mission modules) were defined in a .CSV file. In the future, users will be able to graphically create them using the GCS GUI. </p>\n<p>To execute a mission, the guidance system essentially loops through all of the locations in a mission module, one mission module at a time. </p>\n<h2>Path Planning</h2>\n<p>The path planning system uses the A* algorithm, which allows a route to be calculated between a particular location and the target location from the current mission module. Along the way, any “obstacles” will be avoided. A* operates on a grid representation of the flight area, and obstacles are simply nodes on the grid that the path is not allowed to use. In practice, I use a circle generation algorithm from computer graphics to find grid nodes around a central coordinate to mark off as the edges of an obstacle. </p>\n<p>The real-world resolution of the grid is customizable, and I usually use 1 metre. So, the flight area is broken up into a set of geographical coordinates along a 1m grid. A* operates on the indices of the geographical coordinates to calculate the path. In various places, a KD tree is used to quickly determine the closest grid coordinate to another coordinate (such as a mission module target location). Since the grid resolution is fine compared to the accuracy of the drone’s GPS navigation (3m roughly), this approximation doesn’t result in significant navigation issues in practice. </p>\n<p>Upon reaching a target location, A* is executed to find the path to the next location. </p>\n<h2>Navigation</h2>\n<p>Navigation is fairly straightforward, with a bearing to the next location along the A* planned path being repeatedly calculated, and the velocity components being derived from that. These components constitute the setpoint and are fed to a PID loop to determine the final velocity components to send to the drone. Some checking for velocity limits is also implemented, as are some special considerations for reaching targets accurately. </p>\n<p>Tuning the PID constants is accomplished in the simulator once a parameter file from the drone is applied to the simulated drone. This provides a reasonably accurate representation of real flight characteristics, and every mission is simulated before execution to ensure safety. </p>\n<h2>Ground Control</h2>\n<p>We decided to use a web-based stack for the ground control UI. The main driver for this was wanting a fully featured mapping library that would allow us to place components (icons, paths, etc.) on the map and have them be georeferenced correctly. GUI solutions like QT didn’t have mapping features advanced enough for our use. We also needed to provide our own map tiles as opposed to using Google Maps or something similar, since there is no internet out at the flightline at compeition. OpenLayers was chosen as the mapping library after experimenting with some alternatives. </p>\n<p><a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/dcbc2a430951a14cab9689f4be5ab1fe/be9be/gcs.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 1170px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 50.13477088948787%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAACZUlEQVQozy2SSVMTYRCG81es8mRZSEmBAbIRIDNJZjJbMllmMpOZyR5CADUsikuBIgfUAwfL8urN//jYUh66+uuu7rfffvtLqXWbQjVLvpIlVxZTM2TVLXlvkyv98/sUNEVqxJQCxdI2Bcnn/1uutElGbLO4wXphjdTy/SWLVxHJpEE4sugOLQYLX3I9klkTJ1QweiVs8Y2wgt1VxErUQ5Wqty/5Mq2oSifW8YcmKS8wcLs6tZaC3tyn3C6hBRptyXVjm2ZXihMTLzZp9mr4kUGYWHjiG36F9r9ar0KS2EwmLVKWX8XwyzjSaHpldE/FDDUCib22SkviUOIoqJJIba+r0ZW42auiyXBHcsnYJR44RMM6KTfQafoaDa9Kra1QcfdwoxqTocO0b0mhidnexXVy3G+t8lJNo/m72EGJcFxneT7i8sOc5ZspsfSkXAGzhbLTKUujgmrvUI9rDEY2M2mYT10CiesCelgvctA3GYnGX24vuL464fUyIegbjKctkgdA0coWdoaAacLO7Ci4spIvKwYixVC0Sh70ElkinelxwNnFhKubczwBNzp7WJ7C+NAnkrVTmd1N0tk1MoUXpHfW5ZtsoYs2yaxBf2AxFZZtYV9xdlCtPJYMjAd1jhahHKEpw8wHm8tBRokAPs+v8yS9wqOVxzzLPmW1sMKGsirXrHK86PDp7Zib8yEnBx129DQtuerH0zmzfptBYBOHNkFgEnVrJKFFaiNXYHF6xt3dHRVTEZZprm/e8ef3L5bHY8aJx4+vn7EN+YeehVZTaDYMvt9e8/P+G3tKkXwxw+JowmAQ8Bc/6ZPnT1G53wAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n    ></span>\n    <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"Ground Control\"\n        title=\"\"\n        src=\"/static/dcbc2a430951a14cab9689f4be5ab1fe/a66a3/gcs.png\"\n        srcset=\"/static/dcbc2a430951a14cab9689f4be5ab1fe/65e34/gcs.png 293w,\n/static/dcbc2a430951a14cab9689f4be5ab1fe/8d594/gcs.png 585w,\n/static/dcbc2a430951a14cab9689f4be5ab1fe/a66a3/gcs.png 1170w,\n/static/dcbc2a430951a14cab9689f4be5ab1fe/59785/gcs.png 1755w,\n/static/dcbc2a430951a14cab9689f4be5ab1fe/be9be/gcs.png 1855w\"\n        sizes=\"(max-width: 1170px) 100vw, 1170px\"\n      />\n  </span>\n  </a>\n<em>Early GCS prototype showing drone, obstacle, planned and real flight paths</em></p>\n<p>The initial prototype app was implemented in vanilla JavaScript, but is currently being transitioned to React + Redux. This will allow us to handle some of the more complex UI components we want to create in the future. </p>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"For the past few years, I’ve been working on a guidance system for drones with "},{"type":"element","tagName":"a","properties":{"href":"teamguardian.ca"},"children":[{"type":"text","value":"SFU Team Guardian"}]},{"type":"text","value":". This system encompasses a simulator (APM SITL) or real drone support, path planning, mission creation, drone control, and a web-based ground control app. I started the project for the team to meet the requirements of the AUVSI competition, where a drone must complete objectives while avoiding stationary and moving objects. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Tech Stack"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The guidance system is executed on a laptop computer in the field, and continuously sends velocity vectors and other commands over the telemetry radio connection. The drone itself is a multicopter, running stock APM firmware and sending back telemetry at roughly 10 Hz. Running the guidance system on a laptop provides flexibility of developing in a high-level language (Python) and facilitates much easier testing when the simulator is involved. For the task at hand (avoiding large obstacles), the communication latency and potential for dropped packets is not a significant concern. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The DroneKit library provides an application layer that allows high-level commands to be sent to the drone via MAVProxy, and hides the details about the connection. During development, the APM SITL simulator is hooked up identically to a real drone by connecting to its provided telemetry stream. When we tune the real copter PID paramaters, we set them in the SITL drone as well, allowing the simulated drone to have similar flight characteristics to the real drone. This makes it easier to tune paramaters of the guidance system. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Control Loop"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Control of drone movement is provided by the velocity vector commands exposed by DroneKit. You need to continuously feed velocity vectors to a drone running APM firmware otherwise it will quickly stop and hover. This turns out to be a "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"really"}]},{"type":"text","value":" nice safety feature, and apparently wasn’t present in the earliest versions of APM. Yikes!"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The guidance system calculates a velocity vector at a user-settable frequency, usually 5-10 Hz. Velocities are specified in NED coordinates - North, East, Down, which makes navigation quite easy using standard equations for navigation on the Earth. To generate a velocity vector, the following things are considered:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"maximum velocity setting"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"current and desired location, driven by the path planning algorithm and mission itself"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"PID values from the navigation PID controller (internal to the guidance system, separate from the APM PID controllers)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"a few safety checks for altitude limits and overshoot detection"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Once the velocity vector is calculated, it is sent up to the drone. It turns out that packet loss is not a significant concern - most of the velocity commands make it up to the copter. The velocity vector needs to be recalculated continuously to account for dynamic effects such as wind, and so the drone won’t stop as mentioned before. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Mission Modules"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Similar to how missions are planned on standard ground control apps like APM Planner, I introduced the concept of a mission module to the guidance system. Each mission module is a representation of a few things:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"a set of coordinates (multiple coordinates are used to define a search pattern, for example)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"a particular action to perform when the final coordinte is reached"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"an altitude"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The simplest mission module is a waypoint - it contains a single set of coordinates, an altitude, and tells the drone to hover at the location for a few seconds. An example of an extension to the waypoint module is the drop location module, which sends a few servo commands to release something from the drone as it hovers over a particular location. There are also search pattern modules, where the corners of an area are defined by the user, as well as a swath width, allowing a set of coordinates to be generated in a lawnmower-style zigzag search. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Initially, missions (a collection of mission modules) were defined in a .CSV file. In the future, users will be able to graphically create them using the GCS GUI. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"To execute a mission, the guidance system essentially loops through all of the locations in a mission module, one mission module at a time. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Path Planning"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The path planning system uses the A* algorithm, which allows a route to be calculated between a particular location and the target location from the current mission module. Along the way, any “obstacles” will be avoided. A* operates on a grid representation of the flight area, and obstacles are simply nodes on the grid that the path is not allowed to use. In practice, I use a circle generation algorithm from computer graphics to find grid nodes around a central coordinate to mark off as the edges of an obstacle. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The real-world resolution of the grid is customizable, and I usually use 1 metre. So, the flight area is broken up into a set of geographical coordinates along a 1m grid. A* operates on the indices of the geographical coordinates to calculate the path. In various places, a KD tree is used to quickly determine the closest grid coordinate to another coordinate (such as a mission module target location). Since the grid resolution is fine compared to the accuracy of the drone’s GPS navigation (3m roughly), this approximation doesn’t result in significant navigation issues in practice. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Upon reaching a target location, A* is executed to find the path to the next location. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Navigation"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Navigation is fairly straightforward, with a bearing to the next location along the A* planned path being repeatedly calculated, and the velocity components being derived from that. These components constitute the setpoint and are fed to a PID loop to determine the final velocity components to send to the drone. Some checking for velocity limits is also implemented, as are some special considerations for reaching targets accurately. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Tuning the PID constants is accomplished in the simulator once a parameter file from the drone is applied to the simulated drone. This provides a reasonably accurate representation of real flight characteristics, and every mission is simulated before execution to ensure safety. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Ground Control"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"We decided to use a web-based stack for the ground control UI. The main driver for this was wanting a fully featured mapping library that would allow us to place components (icons, paths, etc.) on the map and have them be georeferenced correctly. GUI solutions like QT didn’t have mapping features advanced enough for our use. We also needed to provide our own map tiles as opposed to using Google Maps or something similar, since there is no internet out at the flightline at compeition. OpenLayers was chosen as the mapping library after experimenting with some alternatives. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"a","properties":{"className":["gatsby-resp-image-link"],"href":"/static/dcbc2a430951a14cab9689f4be5ab1fe/be9be/gcs.png","style":"display: block","target":"_blank","rel":["noopener"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block;  max-width: 1170px; margin-left: auto; margin-right: auto;"},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 50.13477088948787%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAACZUlEQVQozy2SSVMTYRCG81es8mRZSEmBAbIRIDNJZjJbMllmMpOZyR5CADUsikuBIgfUAwfL8urN//jYUh66+uuu7rfffvtLqXWbQjVLvpIlVxZTM2TVLXlvkyv98/sUNEVqxJQCxdI2Bcnn/1uutElGbLO4wXphjdTy/SWLVxHJpEE4sugOLQYLX3I9klkTJ1QweiVs8Y2wgt1VxErUQ5Wqty/5Mq2oSifW8YcmKS8wcLs6tZaC3tyn3C6hBRptyXVjm2ZXihMTLzZp9mr4kUGYWHjiG36F9r9ar0KS2EwmLVKWX8XwyzjSaHpldE/FDDUCib22SkviUOIoqJJIba+r0ZW42auiyXBHcsnYJR44RMM6KTfQafoaDa9Kra1QcfdwoxqTocO0b0mhidnexXVy3G+t8lJNo/m72EGJcFxneT7i8sOc5ZspsfSkXAGzhbLTKUujgmrvUI9rDEY2M2mYT10CiesCelgvctA3GYnGX24vuL464fUyIegbjKctkgdA0coWdoaAacLO7Ci4spIvKwYixVC0Sh70ElkinelxwNnFhKubczwBNzp7WJ7C+NAnkrVTmd1N0tk1MoUXpHfW5ZtsoYs2yaxBf2AxFZZtYV9xdlCtPJYMjAd1jhahHKEpw8wHm8tBRokAPs+v8yS9wqOVxzzLPmW1sMKGsirXrHK86PDp7Zib8yEnBx129DQtuerH0zmzfptBYBOHNkFgEnVrJKFFaiNXYHF6xt3dHRVTEZZprm/e8ef3L5bHY8aJx4+vn7EN+YeehVZTaDYMvt9e8/P+G3tKkXwxw+JowmAQ8Bc/6ZPnT1G53wAAAABJRU5ErkJggg=='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n    "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;","alt":"Ground Control","title":"","src":"/static/dcbc2a430951a14cab9689f4be5ab1fe/a66a3/gcs.png","srcSet":["/static/dcbc2a430951a14cab9689f4be5ab1fe/65e34/gcs.png 293w","/static/dcbc2a430951a14cab9689f4be5ab1fe/8d594/gcs.png 585w","/static/dcbc2a430951a14cab9689f4be5ab1fe/a66a3/gcs.png 1170w","/static/dcbc2a430951a14cab9689f4be5ab1fe/59785/gcs.png 1755w","/static/dcbc2a430951a14cab9689f4be5ab1fe/be9be/gcs.png 1855w"],"sizes":["(max-width:","1170px)","100vw,","1170px"]},"children":[]},{"type":"text","value":"\n  "}]},{"type":"text","value":"\n  "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Early GCS prototype showing drone, obstacle, planned and real flight paths"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The initial prototype app was implemented in vanilla JavaScript, but is currently being transitioned to React + Redux. This will allow us to handle some of the more complex UI components we want to create in the future. "}]}],"data":{"quirksMode":false}},"excerpt":"For the past few years, I’ve been working on a guidance system for drones with  SFU Team Guardian . This system encompasses a simulator (APM…","timeToRead":5,"frontmatter":{"title":"Drone Guidance System","userDate":"3 January 2019","date":"2019-01-03T00:00:00.000Z","tags":["Drone","Projects"],"image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAECAwT/xAAVAQEBAAAAAAAAAAAAAAAAAAABAv/aAAwDAQACEAMQAAAByVQdSxA//8QAGRAAAwEBAQAAAAAAAAAAAAAAAAECMQMR/9oACAEBAAEFAudtq5SPDSW7p7//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAaEAACAgMAAAAAAAAAAAAAAAAAEQExECGB/9oACAEBAAY/AlrokWsREln/xAAbEAACAgMBAAAAAAAAAAAAAAAAAREhMUFRcf/aAAgBAQABPyGl3UZSyFve30b6j5w2Vpeji6UmSWZ//9oADAMBAAIAAwAAABCkz//EABYRAAMAAAAAAAAAAAAAAAAAABAhQf/aAAgBAwEBPxBQf//EABURAQEAAAAAAAAAAAAAAAAAABAh/9oACAECAQE/EKf/xAAcEAEAAwACAwAAAAAAAAAAAAABABEhMUFRsdH/2gAIAQEAAT8QfcClgPw8xdmZvgns2XS6jvXpFoChoDBcz+tENaO4VZJbVdn/2Q==","aspectRatio":1.5003750937734435,"src":"/static/49a3b65f81b137a9d696960fcefd89fa/11c05/guidance-sys-header.jpg","srcSet":"/static/49a3b65f81b137a9d696960fcefd89fa/d913c/guidance-sys-header.jpg 930w,\n/static/49a3b65f81b137a9d696960fcefd89fa/4be77/guidance-sys-header.jpg 1860w,\n/static/49a3b65f81b137a9d696960fcefd89fa/11c05/guidance-sys-header.jpg 2000w","sizes":"(max-width: 2000px) 100vw, 2000px"}}},"author":{"id":"Richard","bio":"Mechatronics Systems engineering student passionate about space, interested in high-reliability embedded systems and computer vision. Currently turning coffee into CubeSats and drones.","avatar":{"children":[{"__typename":"ImageSharp","fixed":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIDBAX/xAAVAQEBAAAAAAAAAAAAAAAAAAABAP/aAAwDAQACEAMQAAAB589OeKWwkKgbQn//xAAbEAACAwADAAAAAAAAAAAAAAABAgASIREiMf/aAAgBAQABBQKE9YzUFt5h1V0n3//EABURAQEAAAAAAAAAAAAAAAAAAAEQ/9oACAEDAQE/ASE//8QAFREBAQAAAAAAAAAAAAAAAAAAESD/2gAIAQIBAT8BY//EABoQAAICAwAAAAAAAAAAAAAAAAABESEQIDH/2gAIAQEABj8CFHcUrJ1//8QAGhABAAMBAQEAAAAAAAAAAAAAAQARIUExEP/aAAgBAQABPyG1c2E0Ipg9xPQFJ35HtxipKNj1P//aAAwDAQACAAMAAAAQkxCD/8QAGBEAAgMAAAAAAAAAAAAAAAAAABEBECH/2gAIAQMBAT8Q0xkK/8QAGBEAAgMAAAAAAAAAAAAAAAAAAAEQEUH/2gAIAQIBAT8Qs4WiP//EABwQAQADAAMBAQAAAAAAAAAAAAEAESExQXFhkf/aAAgBAQABPxCgAp6NYEcIGjV7i+0/kFpV61wTiYFlNYhBTUGAHzHlQFSFqER9qn//2Q==","width":400,"height":400,"src":"/static/a2b7322425489e49016cd6942dbb87ef/2e811/richard.jpg","srcSet":"/static/a2b7322425489e49016cd6942dbb87ef/2e811/richard.jpg 1x"}}]}}}},"relatedPosts":{"totalCount":1,"edges":[{"node":{"id":"f4ebe7ad-acf6-5ad9-8f98-3ab7a1cb141e","timeToRead":5,"excerpt":"For the past few years, I’ve been working on a guidance system for drones with  SFU Team Guardian . This system encompasses a simulator (APM…","frontmatter":{"title":"Drone Guidance System"},"fields":{"slug":"/projects/drone-guidance-system/"}}}]}},"pageContext":{"slug":"/projects/drone-guidance-system/","prev":{"excerpt":"Customizing IP RTL Now that we have an IP block that can be accessed from userspace, let’s customize it with a register that the user can…","timeToRead":4,"frontmatter":{"title":"Customizing AXI IP","tags":["FPGA","Zynq","Embedded","Linux","Blog-post"],"date":"2019-01-06T00:00:00.000Z","image":{"childImageSharp":{"fluid":{"aspectRatio":1.3218770654329148,"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIDBP/EABYBAQEBAAAAAAAAAAAAAAAAAAMCBP/aAAwDAQACEAMQAAABzyi2lYihT//EABsQAAMAAgMAAAAAAAAAAAAAAAACAwEEEBES/9oACAEBAAEFAsbFKDWY7Jv5GfDcf//EABcRAAMBAAAAAAAAAAAAAAAAAAABESH/2gAIAQMBAT8ByFZ//8QAFxEAAwEAAAAAAAAAAAAAAAAAAAEREv/aAAgBAgEBPwGRU2z/xAAcEAABBAMBAAAAAAAAAAAAAAABAAIQUREhgTL/2gAIAQEABj8CyQzoXlvBFiloR//EABsQAQACAgMAAAAAAAAAAAAAAAEAESFhEDFR/9oACAEBAAE/IUlSiLOzrRwv5NiKoB4TE//aAAwDAQACAAMAAAAQlD//xAAYEQACAwAAAAAAAAAAAAAAAAAAASExYf/aAAgBAwEBPxBJLSbH/8QAFhEBAQEAAAAAAAAAAAAAAAAAAEFh/9oACAECAQE/EKTR/8QAHxABAAIBAwUAAAAAAAAAAAAAAQARITFBUWFxgcHh/9oACAEBAAE/EBIFCij0mGzAv0Yp4jDVbbofIyF1BcG+d/MUNAvdn//Z","sizes":"(max-width: 2000px) 100vw, 2000px","src":"/static/9372cc92bbf5a88c049d7549f7f9443f/11c05/blinky-2.jpg","srcSet":"/static/9372cc92bbf5a88c049d7549f7f9443f/d913c/blinky-2.jpg 930w,\n/static/9372cc92bbf5a88c049d7549f7f9443f/4be77/blinky-2.jpg 1860w,\n/static/9372cc92bbf5a88c049d7549f7f9443f/11c05/blinky-2.jpg 2000w"}}},"author":{"id":"Richard","bio":"Mechatronics Systems engineering student passionate about space, interested in high-reliability embedded systems and computer vision. Currently turning coffee into CubeSats and drones.","avatar":{"children":[{"fixed":{"src":"/static/a2b7322425489e49016cd6942dbb87ef/2e811/richard.jpg"}}]}}},"fields":{"layout":"","slug":"/2019/01/06/cora-customizing-axi-ip/"}},"next":{"excerpt":"This post is a collection of a few tips and tricks for developing openCV applications on a Raspberry Pi (or any other embedded linux board…","timeToRead":3,"frontmatter":{"title":"Raspberry Pi OpenCV Setup","tags":["Image Sensor","Camera","Raspberry Pi","linux Blog-post"],"date":"2019-01-20T00:00:00.000Z","image":{"childImageSharp":{"fluid":{"aspectRatio":1.3218770654329148,"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIDBP/EABYBAQEBAAAAAAAAAAAAAAAAAAMCBP/aAAwDAQACEAMQAAABzyi2lYihT//EABsQAAMAAgMAAAAAAAAAAAAAAAACAwEEEBES/9oACAEBAAEFAsbFKDWY7Jv5GfDcf//EABcRAAMBAAAAAAAAAAAAAAAAAAABESH/2gAIAQMBAT8ByFZ//8QAFxEAAwEAAAAAAAAAAAAAAAAAAAEREv/aAAgBAgEBPwGRU2z/xAAcEAABBAMBAAAAAAAAAAAAAAABAAIQUREhgTL/2gAIAQEABj8CyQzoXlvBFiloR//EABsQAQACAgMAAAAAAAAAAAAAAAEAESFhEDFR/9oACAEBAAE/IUlSiLOzrRwv5NiKoB4TE//aAAwDAQACAAMAAAAQlD//xAAYEQACAwAAAAAAAAAAAAAAAAAAASExYf/aAAgBAwEBPxBJLSbH/8QAFhEBAQEAAAAAAAAAAAAAAAAAAEFh/9oACAECAQE/EKTR/8QAHxABAAIBAwUAAAAAAAAAAAAAAQARITFBUWFxgcHh/9oACAEBAAE/EBIFCij0mGzAv0Yp4jDVbbofIyF1BcG+d/MUNAvdn//Z","sizes":"(max-width: 2000px) 100vw, 2000px","src":"/static/9372cc92bbf5a88c049d7549f7f9443f/11c05/blinky-2.jpg","srcSet":"/static/9372cc92bbf5a88c049d7549f7f9443f/d913c/blinky-2.jpg 930w,\n/static/9372cc92bbf5a88c049d7549f7f9443f/4be77/blinky-2.jpg 1860w,\n/static/9372cc92bbf5a88c049d7549f7f9443f/11c05/blinky-2.jpg 2000w"}}},"author":{"id":"Richard","bio":"Mechatronics Systems engineering student passionate about space, interested in high-reliability embedded systems and computer vision. Currently turning coffee into CubeSats and drones.","avatar":{"children":[{"fixed":{"src":"/static/a2b7322425489e49016cd6942dbb87ef/2e811/richard.jpg"}}]}}},"fields":{"layout":"","slug":"/2019/01/20/raspberrypi-cv-setup/"}},"primaryTag":"Drone"}}